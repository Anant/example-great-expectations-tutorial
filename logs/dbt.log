2020-02-03 21:31:47,543135 (MainThread): Running with dbt=0.15.1
2020-02-03 21:31:47,586176 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 21:31:47,629927 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-03 21:31:47,630596 (MainThread): Tracking: tracking
2020-02-03 21:31:47,660765 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a50e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a50550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a50b10>]}
2020-02-03 21:31:47,910398 (MainThread): Partial parsing not enabled
2020-02-03 21:31:47,914714 (MainThread): Parsing macros/core.sql
2020-02-03 21:31:47,920627 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 21:31:47,927331 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 21:31:47,929374 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 21:31:47,945489 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 21:31:47,961357 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 21:31:47,976534 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 21:31:47,978336 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 21:31:47,985292 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 21:31:47,990643 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 21:31:47,995342 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 21:31:47,999762 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 21:31:48,3709 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 21:31:48,4791 (MainThread): Parsing macros/etc/query.sql
2020-02-03 21:31:48,5938 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 21:31:48,7491 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 21:31:48,9245 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 21:31:48,15040 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 21:31:48,16688 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 21:31:48,36854 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 21:31:48,37917 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 21:31:48,38827 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 21:31:48,39853 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 21:31:48,42249 (MainThread): Parsing macros/catalog.sql
2020-02-03 21:31:48,44508 (MainThread): Parsing macros/relations.sql
2020-02-03 21:31:48,46268 (MainThread): Parsing macros/adapters.sql
2020-02-03 21:31:48,53467 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 21:31:48,67968 (MainThread): Partial parsing not enabled
2020-02-03 21:31:48,79448 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 21:31:48,79608 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,93144 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 21:31:48,93311 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,125835 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 21:31:48,125975 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,136442 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 21:31:48,136672 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,145601 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 21:31:48,145749 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,151309 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 21:31:48,151403 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,197266 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 21:31:48,200947 (MainThread): 
2020-02-03 21:31:48,201286 (MainThread): Acquiring new postgres connection "master".
2020-02-03 21:31:48,201381 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:31:48,283526 (MainThread): Using postgres connection "master".
2020-02-03 21:31:48,283700 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 21:31:48,326805 (MainThread): SQL status: SELECT 6 in 0.04 seconds
2020-02-03 21:31:48,368308 (MainThread): Using postgres connection "master".
2020-02-03 21:31:48,368472 (MainThread): On master: BEGIN
2020-02-03 21:31:48,369343 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:31:48,369529 (MainThread): Using postgres connection "master".
2020-02-03 21:31:48,369626 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 21:31:48,386531 (MainThread): SQL status: SELECT 0 in 0.02 seconds
2020-02-03 21:31:48,424163 (MainThread): Using postgres connection "master".
2020-02-03 21:31:48,424316 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 21:31:48,433877 (MainThread): SQL status: SELECT 0 in 0.01 seconds
2020-02-03 21:31:48,434842 (MainThread): On master: ROLLBACK
2020-02-03 21:31:48,435073 (MainThread): Using postgres connection "master".
2020-02-03 21:31:48,435184 (MainThread): On master: BEGIN
2020-02-03 21:31:48,435459 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:31:48,435575 (MainThread): On master: COMMIT
2020-02-03 21:31:48,435666 (MainThread): Using postgres connection "master".
2020-02-03 21:31:48,435744 (MainThread): On master: COMMIT
2020-02-03 21:31:48,435912 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:31:48,436210 (MainThread): 16:31:48 | Concurrency: 1 threads (target='dev')
2020-02-03 21:31:48,436341 (MainThread): 16:31:48 | 
2020-02-03 21:31:48,439256 (Thread-1): Began running node seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:31:48,439485 (Thread-1): 16:31:48 | 1 of 3 START seed file public.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY [RUN]
2020-02-03 21:31:48,439801 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:31:48,439897 (Thread-1): Opening a new connection, currently in state init
2020-02-03 21:31:48,440007 (Thread-1): finished collecting timing info
2020-02-03 21:31:48,498370 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-03 21:31:48,498765 (Thread-1): Using postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:31:48,498851 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-03 21:31:48,501962 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:31:48,502071 (Thread-1): Using postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:31:48,502139 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY"} */

    create table "demo_db"."public"."CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE SPECIALTY CODE text,MEDICARE PROVIDER/SUPPLIER TYPE DESCRIPTION text,PROVIDER TAXONOMY CODE text,PROVIDER TAXONOMY DESCRIPTION text)
  
2020-02-03 21:31:48,502410 (Thread-1): Postgres error: syntax error at or near "CODE"
LINE 3: ...HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE SPECIALTY CODE text,...
                                                             ^

2020-02-03 21:31:48,502498 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: ROLLBACK
2020-02-03 21:31:48,502695 (Thread-1): finished collecting timing info
2020-02-03 21:31:48,503112 (Thread-1): Database Error in seed CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY (data/CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY.csv)
  syntax error at or near "CODE"
  LINE 3: ...HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE SPECIALTY CODE text,...
                                                               ^
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: syntax error at or near "CODE"
LINE 3: ...HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE SPECIALTY CODE text,...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 412, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 25, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 102, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 120, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in seed CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY (data/CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY.csv)
  syntax error at or near "CODE"
  LINE 3: ...HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE SPECIALTY CODE text,...
                                                               ^
2020-02-03 21:31:48,511621 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cde43c5-da98-4fe0-add8-b453fd8f799b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d88750>]}
2020-02-03 21:31:48,645475 (Thread-1): 16:31:48 | 1 of 3 ERROR loading seed file public.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY [ERROR in 0.07s]
2020-02-03 21:31:48,645700 (Thread-1): Finished running node seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:31:48,645868 (Thread-1): Began running node seed.demo_pipeline.npidata_pfile_20190909-20190915
2020-02-03 21:31:48,646390 (Thread-1): 16:31:48 | 2 of 3 START seed file public.npidata_pfile_20190909-20190915........ [RUN]
2020-02-03 21:31:48,646830 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npidata_pfile_20190909-20190915".
2020-02-03 21:31:48,646987 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-03 21:31:48,647140 (Thread-1): finished collecting timing info
2020-02-03 21:31:49,48246 (Thread-1): finished collecting timing info
2020-02-03 21:31:49,48724 (Thread-1): Unhandled error while executing seed.demo_pipeline.npidata_pfile_20190909-20190915
's'
2020-02-03 21:31:49,48820 (Thread-1): 
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 379, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/context/common.py", line 189, in load_agate_table
    table = dbt.clients.agate_helper.from_csv(path)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/agate_helper.py", line 68, in from_csv
    return agate.Table.from_csv(fp, column_types=DEFAULT_TYPE_TESTER)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/table/from_csv.py", line 88, in from_csv
    return Table(rows, column_names, column_types, row_names=row_names)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/table/__init__.py", line 109, in __init__
    self._column_types = column_types.run(rows, self._column_names)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/type_tester.py", line 110, in run
    if len(row) > i and not column_type.test(row[i]):
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/data_types/base.py", line 29, in test
    self.cast(d)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/data_types/date.py", line 76, in cast
    (value, ctx, _, _, matched_text), = self.parser.nlp(d, sourceTime=ZERO_DT)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 2190, in nlp
    version)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 1844, in parse
    retS, retTime, matched = parseMeth(s, sourceTime)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 1408, in _partialParseQUnits
    sourceTime = self._evalQUnits(parseStr, sourceTime)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 1100, in _evalQUnits
    sourceTime = self._buildTime(sourceTime, quantity, modifier, units)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 389, in _buildTime
    ctx.updateAccuracy(realunit)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/context.py", line 137, in updateAccuracy
    acc = self._ACCURACY_REVERSE_MAPPING[acc]
KeyError: 's'
2020-02-03 21:31:49,111899 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cde43c5-da98-4fe0-add8-b453fd8f799b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d90990>]}
2020-02-03 21:31:49,244562 (Thread-1): 16:31:49 | 2 of 3 ERROR loading seed file public.npidata_pfile_20190909-20190915 [ERROR in 0.47s]
2020-02-03 21:31:49,244929 (Thread-1): Finished running node seed.demo_pipeline.npidata_pfile_20190909-20190915
2020-02-03 21:31:49,245195 (Thread-1): Began running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:31:49,245458 (Thread-1): 16:31:49 | 3 of 3 START seed file public.state_crosswalk........................ [RUN]
2020-02-03 21:31:49,246114 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:31:49,246250 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.npidata_pfile_20190909-20190915).
2020-02-03 21:31:49,246387 (Thread-1): finished collecting timing info
2020-02-03 21:31:49,252821 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:31:49,253033 (Thread-1): On seed.demo_pipeline.state_crosswalk: BEGIN
2020-02-03 21:31:49,253540 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:31:49,253667 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:31:49,253762 (Thread-1): On seed.demo_pipeline.state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.state_crosswalk"} */

    create table "demo_db"."public"."state_crosswalk" (State text,Abbrev text,Code text)
  
2020-02-03 21:31:49,279268 (Thread-1): SQL status: CREATE TABLE in 0.03 seconds
2020-02-03 21:31:49,282104 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:31:49,282217 (Thread-1): On seed.demo_pipeline.state_crosswalk: 
            insert into "demo_db"."public"."state_crosswalk" (State, Abbrev, Code) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%...
2020-02-03 21:31:49,283097 (Thread-1): SQL status: INSERT 0 51 in 0.00 seconds
2020-02-03 21:31:49,283436 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.state_crosswalk"
2020-02-03 21:31:49,284968 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:31:49,285109 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:31:49,285204 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:31:49,289071 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:31:49,294789 (Thread-1): finished collecting timing info
2020-02-03 21:31:49,295602 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cde43c5-da98-4fe0-add8-b453fd8f799b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120bd1110>]}
2020-02-03 21:31:49,439270 (Thread-1): 16:31:49 | 3 of 3 OK loaded seed file public.state_crosswalk.................... [INSERT 51 in 0.05s]
2020-02-03 21:31:49,439538 (Thread-1): Finished running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:31:49,518253 (MainThread): Using postgres connection "master".
2020-02-03 21:31:49,518632 (MainThread): On master: BEGIN
2020-02-03 21:31:49,519246 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:31:49,519544 (MainThread): On master: COMMIT
2020-02-03 21:31:49,519775 (MainThread): Using postgres connection "master".
2020-02-03 21:31:49,519988 (MainThread): On master: COMMIT
2020-02-03 21:31:49,520419 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:31:49,520897 (MainThread): 16:31:49 | 
2020-02-03 21:31:49,521126 (MainThread): 16:31:49 | Finished running 3 seeds in 1.32s.
2020-02-03 21:31:49,521300 (MainThread): Connection 'master' was left open.
2020-02-03 21:31:49,521407 (MainThread): On master: Close
2020-02-03 21:31:49,521536 (MainThread): Connection 'seed.demo_pipeline.state_crosswalk' was left open.
2020-02-03 21:31:49,521638 (MainThread): On seed.demo_pipeline.state_crosswalk: Close
2020-02-03 21:31:49,530566 (MainThread): 
2020-02-03 21:31:49,530762 (MainThread): Completed with 2 errors and 0 warnings:
2020-02-03 21:31:49,530889 (MainThread): 
2020-02-03 21:31:49,531007 (MainThread): Database Error in seed CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY (data/CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY.csv)
2020-02-03 21:31:49,531114 (MainThread):   syntax error at or near "CODE"
2020-02-03 21:31:49,531212 (MainThread):   LINE 3: ...HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE SPECIALTY CODE text,...
2020-02-03 21:31:49,531306 (MainThread):                                                                ^
2020-02-03 21:31:49,531404 (MainThread): 
2020-02-03 21:31:49,531509 (MainThread): 's'
2020-02-03 21:31:49,531619 (MainThread): 
Done. PASS=1 WARN=0 ERROR=2 SKIP=0 TOTAL=3
2020-02-03 21:31:49,531812 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121dad390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d90450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d90150>]}
2020-02-03 21:31:49,683854 (MainThread): Flushing usage events
2020-02-03 21:34:16,956149 (MainThread): Running with dbt=0.15.1
2020-02-03 21:34:16,985467 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 21:34:17,14612 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-03 21:34:17,15175 (MainThread): Tracking: tracking
2020-02-03 21:34:17,28480 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1252dbd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1252dbb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1252dba50>]}
2020-02-03 21:34:17,248290 (MainThread): Partial parsing not enabled
2020-02-03 21:34:17,250160 (MainThread): Parsing macros/core.sql
2020-02-03 21:34:17,253537 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 21:34:17,258715 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 21:34:17,259963 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 21:34:17,272153 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 21:34:17,284930 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 21:34:17,296461 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 21:34:17,298034 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 21:34:17,302871 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 21:34:17,307597 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 21:34:17,311527 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 21:34:17,315826 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 21:34:17,319008 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 21:34:17,319662 (MainThread): Parsing macros/etc/query.sql
2020-02-03 21:34:17,320416 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 21:34:17,321539 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 21:34:17,322860 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 21:34:17,329560 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 21:34:17,331061 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 21:34:17,349412 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 21:34:17,350371 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 21:34:17,351095 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 21:34:17,351851 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 21:34:17,353315 (MainThread): Parsing macros/catalog.sql
2020-02-03 21:34:17,354456 (MainThread): Parsing macros/relations.sql
2020-02-03 21:34:17,355494 (MainThread): Parsing macros/adapters.sql
2020-02-03 21:34:17,361925 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 21:34:17,376359 (MainThread): Partial parsing not enabled
2020-02-03 21:34:17,386994 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 21:34:17,387123 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,399059 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 21:34:17,399173 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,427233 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 21:34:17,427358 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,435348 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 21:34:17,435438 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,442528 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 21:34:17,442602 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,447499 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 21:34:17,447579 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,489475 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 21:34:17,494389 (MainThread): 
2020-02-03 21:34:17,494800 (MainThread): Acquiring new postgres connection "master".
2020-02-03 21:34:17,494888 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:34:17,572250 (MainThread): Using postgres connection "master".
2020-02-03 21:34:17,572409 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 21:34:17,576613 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 21:34:17,607732 (MainThread): Using postgres connection "master".
2020-02-03 21:34:17,607847 (MainThread): On master: BEGIN
2020-02-03 21:34:17,608131 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:34:17,608209 (MainThread): Using postgres connection "master".
2020-02-03 21:34:17,608270 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 21:34:17,610078 (MainThread): SQL status: SELECT 1 in 0.00 seconds
2020-02-03 21:34:17,637064 (MainThread): Using postgres connection "master".
2020-02-03 21:34:17,637183 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 21:34:17,639239 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-03 21:34:17,640002 (MainThread): On master: ROLLBACK
2020-02-03 21:34:17,640303 (MainThread): Using postgres connection "master".
2020-02-03 21:34:17,640435 (MainThread): On master: BEGIN
2020-02-03 21:34:17,640760 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:34:17,640849 (MainThread): On master: COMMIT
2020-02-03 21:34:17,640917 (MainThread): Using postgres connection "master".
2020-02-03 21:34:17,640975 (MainThread): On master: COMMIT
2020-02-03 21:34:17,641174 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:34:17,641378 (MainThread): 16:34:17 | Concurrency: 1 threads (target='dev')
2020-02-03 21:34:17,641491 (MainThread): 16:34:17 | 
2020-02-03 21:34:17,643198 (Thread-1): Began running node seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:34:17,643341 (Thread-1): 16:34:17 | 1 of 3 START seed file public.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY [RUN]
2020-02-03 21:34:17,643578 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:34:17,643653 (Thread-1): Opening a new connection, currently in state init
2020-02-03 21:34:17,643744 (Thread-1): finished collecting timing info
2020-02-03 21:34:17,690236 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-03 21:34:17,690609 (Thread-1): Using postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:34:17,690711 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-03 21:34:17,694161 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:34:17,694292 (Thread-1): Using postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:34:17,694365 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY"} */

    create table "demo_db"."public"."CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE text,MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION text,PROVIDER_TAXONOMY_CODE text,PROVIDER_TAXONOMY_DESCRIPTION text)
  
2020-02-03 21:34:17,697759 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-03 21:34:17,708911 (Thread-1): Using postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:34:17,709027 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),...
2020-02-03 21:34:17,713638 (Thread-1): SQL status: INSERT 0 521 in 0.00 seconds
2020-02-03 21:34:17,713944 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-03 21:34:17,714837 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:34:17,714922 (Thread-1): Using postgres connection "seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:34:17,714990 (Thread-1): On seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:34:17,718910 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:34:17,721888 (Thread-1): finished collecting timing info
2020-02-03 21:34:17,722459 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963e6639-a638-413c-9fbb-25059122ac90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12640fc90>]}
2020-02-03 21:34:17,841502 (Thread-1): 16:34:17 | 1 of 3 OK loaded seed file public.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY [INSERT 521 in 0.08s]
2020-02-03 21:34:17,841830 (Thread-1): Finished running node seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:34:17,842077 (Thread-1): Began running node seed.demo_pipeline.npidata_pfile_20190909-20190915
2020-02-03 21:34:17,842328 (Thread-1): 16:34:17 | 2 of 3 START seed file public.npidata_pfile_20190909-20190915........ [RUN]
2020-02-03 21:34:17,842960 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npidata_pfile_20190909-20190915".
2020-02-03 21:34:17,843105 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.CROSSWALK_MEDICARE_PROVIDER_SUPPLIER_to_HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-03 21:34:17,843244 (Thread-1): finished collecting timing info
2020-02-03 21:34:18,243487 (Thread-1): finished collecting timing info
2020-02-03 21:34:18,243969 (Thread-1): Unhandled error while executing seed.demo_pipeline.npidata_pfile_20190909-20190915
's'
2020-02-03 21:34:18,244066 (Thread-1): 
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 379, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/context/common.py", line 189, in load_agate_table
    table = dbt.clients.agate_helper.from_csv(path)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/agate_helper.py", line 68, in from_csv
    return agate.Table.from_csv(fp, column_types=DEFAULT_TYPE_TESTER)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/table/from_csv.py", line 88, in from_csv
    return Table(rows, column_names, column_types, row_names=row_names)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/table/__init__.py", line 109, in __init__
    self._column_types = column_types.run(rows, self._column_names)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/type_tester.py", line 110, in run
    if len(row) > i and not column_type.test(row[i]):
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/data_types/base.py", line 29, in test
    self.cast(d)
  File "/opt/miniconda3/lib/python3.7/site-packages/agate/data_types/date.py", line 76, in cast
    (value, ctx, _, _, matched_text), = self.parser.nlp(d, sourceTime=ZERO_DT)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 2190, in nlp
    version)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 1844, in parse
    retS, retTime, matched = parseMeth(s, sourceTime)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 1408, in _partialParseQUnits
    sourceTime = self._evalQUnits(parseStr, sourceTime)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 1100, in _evalQUnits
    sourceTime = self._buildTime(sourceTime, quantity, modifier, units)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/__init__.py", line 389, in _buildTime
    ctx.updateAccuracy(realunit)
  File "/opt/miniconda3/lib/python3.7/site-packages/parsedatetime/context.py", line 137, in updateAccuracy
    acc = self._ACCURACY_REVERSE_MAPPING[acc]
KeyError: 's'
2020-02-03 21:34:18,308873 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963e6639-a638-413c-9fbb-25059122ac90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126610390>]}
2020-02-03 21:34:18,437856 (Thread-1): 16:34:18 | 2 of 3 ERROR loading seed file public.npidata_pfile_20190909-20190915 [ERROR in 0.47s]
2020-02-03 21:34:18,438175 (Thread-1): Finished running node seed.demo_pipeline.npidata_pfile_20190909-20190915
2020-02-03 21:34:18,438440 (Thread-1): Began running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:34:18,438918 (Thread-1): 16:34:18 | 3 of 3 START seed file public.state_crosswalk........................ [RUN]
2020-02-03 21:34:18,439466 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:34:18,439591 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.npidata_pfile_20190909-20190915).
2020-02-03 21:34:18,439725 (Thread-1): finished collecting timing info
2020-02-03 21:34:18,449645 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:34:18,449920 (Thread-1): On seed.demo_pipeline.state_crosswalk: BEGIN
2020-02-03 21:34:18,450476 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:34:18,450633 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:34:18,450752 (Thread-1): On seed.demo_pipeline.state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.state_crosswalk"} */
truncate table "demo_db"."public"."state_crosswalk"
2020-02-03 21:34:18,452357 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:34:18,455982 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:34:18,456106 (Thread-1): On seed.demo_pipeline.state_crosswalk: 
            insert into "demo_db"."public"."state_crosswalk" (State, Abbrev, Code) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%...
2020-02-03 21:34:18,457303 (Thread-1): SQL status: INSERT 0 51 in 0.00 seconds
2020-02-03 21:34:18,457682 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.state_crosswalk"
2020-02-03 21:34:18,459816 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:34:18,460003 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:34:18,460107 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:34:18,464647 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:34:18,467977 (Thread-1): finished collecting timing info
2020-02-03 21:34:18,468629 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '963e6639-a638-413c-9fbb-25059122ac90', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x131713c50>]}
2020-02-03 21:34:18,614109 (Thread-1): 16:34:18 | 3 of 3 OK loaded seed file public.state_crosswalk.................... [INSERT 51 in 0.03s]
2020-02-03 21:34:18,614437 (Thread-1): Finished running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:34:18,617775 (MainThread): Using postgres connection "master".
2020-02-03 21:34:18,618017 (MainThread): On master: BEGIN
2020-02-03 21:34:18,618397 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:34:18,618569 (MainThread): On master: COMMIT
2020-02-03 21:34:18,618692 (MainThread): Using postgres connection "master".
2020-02-03 21:34:18,618800 (MainThread): On master: COMMIT
2020-02-03 21:34:18,619071 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:34:18,619437 (MainThread): 16:34:18 | 
2020-02-03 21:34:18,619610 (MainThread): 16:34:18 | Finished running 3 seeds in 1.12s.
2020-02-03 21:34:18,619752 (MainThread): Connection 'master' was left open.
2020-02-03 21:34:18,619861 (MainThread): On master: Close
2020-02-03 21:34:18,620009 (MainThread): Connection 'seed.demo_pipeline.state_crosswalk' was left open.
2020-02-03 21:34:18,620118 (MainThread): On seed.demo_pipeline.state_crosswalk: Close
2020-02-03 21:34:18,629002 (MainThread): 
2020-02-03 21:34:18,629213 (MainThread): Completed with 1 error and 0 warnings:
2020-02-03 21:34:18,629345 (MainThread): 
2020-02-03 21:34:18,629465 (MainThread): 's'
2020-02-03 21:34:18,629609 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2020-02-03 21:34:18,629821 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13167b150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13167b910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x13167b0d0>]}
2020-02-03 21:34:18,735985 (MainThread): Flushing usage events
2020-02-03 21:41:41,864741 (MainThread): Running with dbt=0.15.1
2020-02-03 21:41:41,892207 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 21:41:41,921891 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-03 21:41:41,922379 (MainThread): Tracking: tracking
2020-02-03 21:41:41,939651 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e588490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce55110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e588550>]}
2020-02-03 21:41:42,166813 (MainThread): Partial parsing not enabled
2020-02-03 21:41:42,168585 (MainThread): Parsing macros/core.sql
2020-02-03 21:41:42,172106 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 21:41:42,177235 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 21:41:42,179169 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 21:41:42,190348 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 21:41:42,202861 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 21:41:42,214497 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 21:41:42,215824 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 21:41:42,220142 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 21:41:42,224462 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 21:41:42,228344 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 21:41:42,232171 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 21:41:42,235342 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 21:41:42,235998 (MainThread): Parsing macros/etc/query.sql
2020-02-03 21:41:42,236765 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 21:41:42,237944 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 21:41:42,239312 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 21:41:42,244602 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 21:41:42,245899 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 21:41:42,264247 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 21:41:42,265125 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 21:41:42,265842 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 21:41:42,266652 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 21:41:42,268160 (MainThread): Parsing macros/catalog.sql
2020-02-03 21:41:42,269363 (MainThread): Parsing macros/relations.sql
2020-02-03 21:41:42,270448 (MainThread): Parsing macros/adapters.sql
2020-02-03 21:41:42,277155 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 21:41:42,291239 (MainThread): Partial parsing not enabled
2020-02-03 21:41:42,301483 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 21:41:42,301571 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,313282 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 21:41:42,313383 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,341287 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 21:41:42,341405 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,350929 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 21:41:42,351077 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,358413 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 21:41:42,358498 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,363751 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 21:41:42,363855 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,406603 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 21:41:42,411450 (MainThread): 
2020-02-03 21:41:42,412040 (MainThread): Acquiring new postgres connection "master".
2020-02-03 21:41:42,412148 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:41:42,484341 (MainThread): Using postgres connection "master".
2020-02-03 21:41:42,484479 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 21:41:42,488608 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 21:41:42,520406 (MainThread): Using postgres connection "master".
2020-02-03 21:41:42,520560 (MainThread): On master: BEGIN
2020-02-03 21:41:42,522065 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:41:42,522276 (MainThread): Using postgres connection "master".
2020-02-03 21:41:42,522376 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 21:41:42,524483 (MainThread): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 21:41:42,553695 (MainThread): Using postgres connection "master".
2020-02-03 21:41:42,553854 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 21:41:42,564605 (MainThread): SQL status: SELECT 0 in 0.01 seconds
2020-02-03 21:41:42,565790 (MainThread): On master: ROLLBACK
2020-02-03 21:41:42,566049 (MainThread): Using postgres connection "master".
2020-02-03 21:41:42,566144 (MainThread): On master: BEGIN
2020-02-03 21:41:42,566405 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:41:42,566519 (MainThread): On master: COMMIT
2020-02-03 21:41:42,566609 (MainThread): Using postgres connection "master".
2020-02-03 21:41:42,566688 (MainThread): On master: COMMIT
2020-02-03 21:41:42,566837 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:41:42,567125 (MainThread): 16:41:42 | Concurrency: 1 threads (target='dev')
2020-02-03 21:41:42,567302 (MainThread): 16:41:42 | 
2020-02-03 21:41:42,569303 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:41:42,569461 (Thread-1): 16:41:42 | 1 of 3 START seed file public.HEALTHCARE_PROVIDER_TAXONOMY........... [RUN]
2020-02-03 21:41:42,569703 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:41:42,569782 (Thread-1): Opening a new connection, currently in state init
2020-02-03 21:41:42,569876 (Thread-1): finished collecting timing info
2020-02-03 21:41:42,619046 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-03 21:41:42,619461 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:41:42,619546 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-03 21:41:42,622939 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:41:42,623049 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:41:42,623124 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"} */

    create table "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE text,MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION text,PROVIDER_TAXONOMY_CODE text,PROVIDER_TAXONOMY_DESCRIPTION text)
  
2020-02-03 21:41:42,626660 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-03 21:41:42,638784 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:41:42,638957 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s...
2020-02-03 21:41:42,644175 (Thread-1): SQL status: INSERT 0 521 in 0.01 seconds
2020-02-03 21:41:42,644570 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-03 21:41:42,645495 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:41:42,645578 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:41:42,645644 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:41:42,650206 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:41:42,653245 (Thread-1): finished collecting timing info
2020-02-03 21:41:42,653929 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b5499b8-c9c0-4b95-a2df-55b396febd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f6c6850>]}
2020-02-03 21:41:42,805963 (Thread-1): 16:41:42 | 1 of 3 OK loaded seed file public.HEALTHCARE_PROVIDER_TAXONOMY....... [INSERT 521 in 0.08s]
2020-02-03 21:41:42,806284 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:41:42,806540 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-03 21:41:42,806802 (Thread-1): 16:41:42 | 2 of 3 START seed file public.npi_small_2019......................... [RUN]
2020-02-03 21:41:42,807390 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:41:42,807534 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-03 21:41:42,807674 (Thread-1): finished collecting timing info
2020-02-03 21:41:43,277934 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:41:43,278120 (Thread-1): On seed.demo_pipeline.npi_small_2019: BEGIN
2020-02-03 21:41:43,278573 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:41:43,278657 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:41:43,278720 (Thread-1): On seed.demo_pipeline.npi_small_2019: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.npi_small_2019"} */

    create table "demo_db"."public"."npi_small_2019" (NPI integer,Entity Type Code integer,Organization Name text,Last Name text,Provider First Name text,State text,Taxonomy Code text)
  
2020-02-03 21:41:43,279042 (Thread-1): Postgres error: syntax error at or near "Code"
LINE 3: ...public"."npi_small_2019" (NPI integer,Entity Type Code integ...
                                                             ^

2020-02-03 21:41:43,279135 (Thread-1): On seed.demo_pipeline.npi_small_2019: ROLLBACK
2020-02-03 21:41:43,279393 (Thread-1): finished collecting timing info
2020-02-03 21:41:43,279781 (Thread-1): Database Error in seed npi_small_2019 (data/npi_small_2019.csv)
  syntax error at or near "Code"
  LINE 3: ...public"."npi_small_2019" (NPI integer,Entity Type Code integ...
                                                               ^
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: syntax error at or near "Code"
LINE 3: ...public"."npi_small_2019" (NPI integer,Entity Type Code integ...
                                                             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 412, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 25, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 102, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 120, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in seed npi_small_2019 (data/npi_small_2019.csv)
  syntax error at or near "Code"
  LINE 3: ...public"."npi_small_2019" (NPI integer,Entity Type Code integ...
                                                               ^
2020-02-03 21:41:43,295346 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b5499b8-c9c0-4b95-a2df-55b396febd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f8f3d50>]}
2020-02-03 21:41:43,439438 (Thread-1): 16:41:43 | 2 of 3 ERROR loading seed file public.npi_small_2019................. [ERROR in 0.49s]
2020-02-03 21:41:43,439758 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-03 21:41:43,440093 (Thread-1): Began running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:41:43,440603 (Thread-1): 16:41:43 | 3 of 3 START seed file public.state_crosswalk........................ [RUN]
2020-02-03 21:41:43,441181 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:41:43,441380 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.npi_small_2019).
2020-02-03 21:41:43,441554 (Thread-1): finished collecting timing info
2020-02-03 21:41:43,448293 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:41:43,448464 (Thread-1): On seed.demo_pipeline.state_crosswalk: BEGIN
2020-02-03 21:41:43,448814 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:41:43,448947 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:41:43,449046 (Thread-1): On seed.demo_pipeline.state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.state_crosswalk"} */
truncate table "demo_db"."public"."state_crosswalk"
2020-02-03 21:41:43,450497 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:41:43,453183 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:41:43,453299 (Thread-1): On seed.demo_pipeline.state_crosswalk: 
            insert into "demo_db"."public"."state_crosswalk" (State, Abbrev, Code) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%...
2020-02-03 21:41:43,453961 (Thread-1): SQL status: INSERT 0 51 in 0.00 seconds
2020-02-03 21:41:43,454269 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.state_crosswalk"
2020-02-03 21:41:43,455409 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:41:43,455520 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:41:43,455609 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:41:43,460602 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:41:43,464433 (Thread-1): finished collecting timing info
2020-02-03 21:41:43,465143 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0b5499b8-c9c0-4b95-a2df-55b396febd50', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f8c73d0>]}
2020-02-03 21:41:43,616315 (Thread-1): 16:41:43 | 3 of 3 OK loaded seed file public.state_crosswalk.................... [INSERT 51 in 0.02s]
2020-02-03 21:41:43,616634 (Thread-1): Finished running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:41:43,716798 (MainThread): Using postgres connection "master".
2020-02-03 21:41:43,717182 (MainThread): On master: BEGIN
2020-02-03 21:41:43,717847 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:41:43,718190 (MainThread): On master: COMMIT
2020-02-03 21:41:43,718440 (MainThread): Using postgres connection "master".
2020-02-03 21:41:43,718661 (MainThread): On master: COMMIT
2020-02-03 21:41:43,719246 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:41:43,719974 (MainThread): 16:41:43 | 
2020-02-03 21:41:43,720320 (MainThread): 16:41:43 | Finished running 3 seeds in 1.31s.
2020-02-03 21:41:43,720605 (MainThread): Connection 'master' was left open.
2020-02-03 21:41:43,720837 (MainThread): On master: Close
2020-02-03 21:41:43,721107 (MainThread): Connection 'seed.demo_pipeline.state_crosswalk' was left open.
2020-02-03 21:41:43,721319 (MainThread): On seed.demo_pipeline.state_crosswalk: Close
2020-02-03 21:41:43,731763 (MainThread): 
2020-02-03 21:41:43,732039 (MainThread): Completed with 1 error and 0 warnings:
2020-02-03 21:41:43,732233 (MainThread): 
2020-02-03 21:41:43,732364 (MainThread): Database Error in seed npi_small_2019 (data/npi_small_2019.csv)
2020-02-03 21:41:43,732475 (MainThread):   syntax error at or near "Code"
2020-02-03 21:41:43,732574 (MainThread):   LINE 3: ...public"."npi_small_2019" (NPI integer,Entity Type Code integ...
2020-02-03 21:41:43,732668 (MainThread):                                                                ^
2020-02-03 21:41:43,732769 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2020-02-03 21:41:43,732961 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fb86690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fb89e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fb83990>]}
2020-02-03 21:41:43,877530 (MainThread): Flushing usage events
2020-02-03 21:53:16,482148 (MainThread): Running with dbt=0.15.1
2020-02-03 21:53:16,516323 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 21:53:16,552102 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-03 21:53:16,553045 (MainThread): Tracking: tracking
2020-02-03 21:53:16,572034 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d248dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d248a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d248910>]}
2020-02-03 21:53:16,839732 (MainThread): Partial parsing not enabled
2020-02-03 21:53:16,842047 (MainThread): Parsing macros/core.sql
2020-02-03 21:53:16,845717 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 21:53:16,851539 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 21:53:16,854193 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 21:53:16,866723 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 21:53:16,879916 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 21:53:16,891603 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 21:53:16,893206 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 21:53:16,897868 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 21:53:16,902851 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 21:53:16,907155 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 21:53:16,911168 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 21:53:16,914417 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 21:53:16,915362 (MainThread): Parsing macros/etc/query.sql
2020-02-03 21:53:16,916590 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 21:53:16,918184 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 21:53:16,919748 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 21:53:16,925024 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 21:53:16,926497 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 21:53:16,945301 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 21:53:16,947958 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 21:53:16,949938 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 21:53:16,951859 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 21:53:16,954896 (MainThread): Parsing macros/catalog.sql
2020-02-03 21:53:16,956980 (MainThread): Parsing macros/relations.sql
2020-02-03 21:53:16,958919 (MainThread): Parsing macros/adapters.sql
2020-02-03 21:53:16,967577 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 21:53:16,982966 (MainThread): Partial parsing not enabled
2020-02-03 21:53:17,938 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 21:53:17,1140 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,17149 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 21:53:17,17350 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,51244 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 21:53:17,51410 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,60138 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 21:53:17,60265 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,68478 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 21:53:17,68604 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,73864 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 21:53:17,73952 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,117546 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 21:53:17,121840 (MainThread): 
2020-02-03 21:53:17,122324 (MainThread): Acquiring new postgres connection "master".
2020-02-03 21:53:17,122462 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:53:17,190364 (MainThread): Using postgres connection "master".
2020-02-03 21:53:17,190534 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 21:53:17,200957 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-03 21:53:17,232338 (MainThread): Using postgres connection "master".
2020-02-03 21:53:17,232508 (MainThread): On master: BEGIN
2020-02-03 21:53:17,233532 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:53:17,233882 (MainThread): Using postgres connection "master".
2020-02-03 21:53:17,234088 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 21:53:17,238352 (MainThread): SQL status: SELECT 3 in 0.00 seconds
2020-02-03 21:53:17,271927 (MainThread): Using postgres connection "master".
2020-02-03 21:53:17,272092 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 21:53:17,275082 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-03 21:53:17,276443 (MainThread): On master: ROLLBACK
2020-02-03 21:53:17,276654 (MainThread): Using postgres connection "master".
2020-02-03 21:53:17,276750 (MainThread): On master: BEGIN
2020-02-03 21:53:17,276978 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:53:17,277073 (MainThread): On master: COMMIT
2020-02-03 21:53:17,277149 (MainThread): Using postgres connection "master".
2020-02-03 21:53:17,277215 (MainThread): On master: COMMIT
2020-02-03 21:53:17,277387 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:53:17,277615 (MainThread): 16:53:17 | Concurrency: 1 threads (target='dev')
2020-02-03 21:53:17,277724 (MainThread): 16:53:17 | 
2020-02-03 21:53:17,279541 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:53:17,279763 (Thread-1): 16:53:17 | 1 of 3 START seed file public.HEALTHCARE_PROVIDER_TAXONOMY........... [RUN]
2020-02-03 21:53:17,280028 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:53:17,280106 (Thread-1): Opening a new connection, currently in state init
2020-02-03 21:53:17,280200 (Thread-1): finished collecting timing info
2020-02-03 21:53:17,327981 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:53:17,328154 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-03 21:53:17,331284 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:53:17,331402 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:53:17,331475 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"} */
truncate table "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-03 21:53:17,332913 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:53:17,334129 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-03 21:53:17,345813 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:53:17,345977 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s...
2020-02-03 21:53:17,350847 (Thread-1): SQL status: INSERT 0 521 in 0.00 seconds
2020-02-03 21:53:17,351450 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-03 21:53:17,352560 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:53:17,352654 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:53:17,352722 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:53:17,357753 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:53:17,360465 (Thread-1): finished collecting timing info
2020-02-03 21:53:17,361074 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a852b3e5-4799-42a2-a067-74c60fef00d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e590a90>]}
2020-02-03 21:53:17,558265 (Thread-1): 16:53:17 | 1 of 3 OK loaded seed file public.HEALTHCARE_PROVIDER_TAXONOMY....... [INSERT 521 in 0.08s]
2020-02-03 21:53:17,558593 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:53:17,558937 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-03 21:53:17,559534 (Thread-1): 16:53:17 | 2 of 3 START seed file public.npi_small_2019......................... [RUN]
2020-02-03 21:53:17,560147 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:53:17,560319 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-03 21:53:17,560586 (Thread-1): finished collecting timing info
2020-02-03 21:53:18,23499 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:53:18,23686 (Thread-1): On seed.demo_pipeline.npi_small_2019: BEGIN
2020-02-03 21:53:18,24127 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:53:18,24213 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:53:18,24278 (Thread-1): On seed.demo_pipeline.npi_small_2019: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.npi_small_2019"} */

    create table "demo_db"."public"."npi_small_2019" (NPI integer,Entity_Type_Code integer,Organization_Name text,Last_Name text,First_Name text,State text,Taxonomy_Code text)
  
2020-02-03 21:53:18,28342 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-03 21:53:18,277675 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:53:18,277852 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-03 21:53:18,405391 (Thread-1): SQL status: INSERT 0 10000 in 0.13 seconds
2020-02-03 21:53:18,655205 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:53:18,655377 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-03 21:53:18,753878 (Thread-1): SQL status: INSERT 0 8649 in 0.10 seconds
2020-02-03 21:53:18,755732 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.npi_small_2019"
2020-02-03 21:53:18,757065 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-03 21:53:18,757175 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:53:18,757259 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-03 21:53:18,761788 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:53:18,765299 (Thread-1): finished collecting timing info
2020-02-03 21:53:18,766149 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a852b3e5-4799-42a2-a067-74c60fef00d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e463d50>]}
2020-02-03 21:53:18,890481 (Thread-1): 16:53:18 | 2 of 3 OK loaded seed file public.npi_small_2019..................... [INSERT 18649 in 1.21s]
2020-02-03 21:53:18,890825 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-03 21:53:18,891182 (Thread-1): Began running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:53:18,891922 (Thread-1): 16:53:18 | 3 of 3 START seed file public.state_crosswalk........................ [RUN]
2020-02-03 21:53:18,892727 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:53:18,892971 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.npi_small_2019).
2020-02-03 21:53:18,893225 (Thread-1): finished collecting timing info
2020-02-03 21:53:18,900428 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:53:18,900603 (Thread-1): On seed.demo_pipeline.state_crosswalk: BEGIN
2020-02-03 21:53:18,901069 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:53:18,901196 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:53:18,901305 (Thread-1): On seed.demo_pipeline.state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.state_crosswalk"} */
truncate table "demo_db"."public"."state_crosswalk"
2020-02-03 21:53:18,902468 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:53:18,904961 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:53:18,905068 (Thread-1): On seed.demo_pipeline.state_crosswalk: 
            insert into "demo_db"."public"."state_crosswalk" (State, Abbrev, Code) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%...
2020-02-03 21:53:18,905655 (Thread-1): SQL status: INSERT 0 51 in 0.00 seconds
2020-02-03 21:53:18,905937 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.state_crosswalk"
2020-02-03 21:53:18,906938 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:53:18,907041 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:53:18,907126 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:53:18,911500 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:53:18,914979 (Thread-1): finished collecting timing info
2020-02-03 21:53:18,915883 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a852b3e5-4799-42a2-a067-74c60fef00d5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e61c290>]}
2020-02-03 21:53:19,86618 (Thread-1): 16:53:19 | 3 of 3 OK loaded seed file public.state_crosswalk.................... [INSERT 51 in 0.02s]
2020-02-03 21:53:19,86955 (Thread-1): Finished running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:53:19,102446 (MainThread): Using postgres connection "master".
2020-02-03 21:53:19,102856 (MainThread): On master: BEGIN
2020-02-03 21:53:19,103554 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:53:19,103899 (MainThread): On master: COMMIT
2020-02-03 21:53:19,104161 (MainThread): Using postgres connection "master".
2020-02-03 21:53:19,104395 (MainThread): On master: COMMIT
2020-02-03 21:53:19,105051 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:53:19,105571 (MainThread): 16:53:19 | 
2020-02-03 21:53:19,105809 (MainThread): 16:53:19 | Finished running 3 seeds in 1.98s.
2020-02-03 21:53:19,106002 (MainThread): Connection 'master' was left open.
2020-02-03 21:53:19,106154 (MainThread): On master: Close
2020-02-03 21:53:19,106488 (MainThread): Connection 'seed.demo_pipeline.state_crosswalk' was left open.
2020-02-03 21:53:19,106695 (MainThread): On seed.demo_pipeline.state_crosswalk: Close
2020-02-03 21:53:19,116495 (MainThread): 
2020-02-03 21:53:19,116701 (MainThread): Completed successfully
2020-02-03 21:53:19,116840 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-02-03 21:53:19,117063 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e853d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e631f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e851150>]}
2020-02-03 21:53:19,253131 (MainThread): Flushing usage events
2020-02-03 21:53:59,686409 (MainThread): Running with dbt=0.15.1
2020-02-03 21:53:59,715117 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 21:53:59,745431 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=True, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-03 21:53:59,745921 (MainThread): Tracking: tracking
2020-02-03 21:53:59,759832 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f185cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f177dd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f185950>]}
2020-02-03 21:53:59,973964 (MainThread): Partial parsing not enabled
2020-02-03 21:53:59,975702 (MainThread): Parsing macros/core.sql
2020-02-03 21:53:59,978891 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 21:53:59,983924 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 21:53:59,985178 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 21:53:59,996156 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 21:54:00,9112 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 21:54:00,21915 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 21:54:00,23342 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 21:54:00,27736 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 21:54:00,32837 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 21:54:00,37047 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 21:54:00,41278 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 21:54:00,44507 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 21:54:00,45191 (MainThread): Parsing macros/etc/query.sql
2020-02-03 21:54:00,45987 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 21:54:00,47178 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 21:54:00,49233 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 21:54:00,54491 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 21:54:00,55861 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 21:54:00,73428 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 21:54:00,74242 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 21:54:00,74904 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 21:54:00,75658 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 21:54:00,77117 (MainThread): Parsing macros/catalog.sql
2020-02-03 21:54:00,78268 (MainThread): Parsing macros/relations.sql
2020-02-03 21:54:00,79428 (MainThread): Parsing macros/adapters.sql
2020-02-03 21:54:00,86047 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 21:54:00,99384 (MainThread): Partial parsing not enabled
2020-02-03 21:54:00,108802 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 21:54:00,108890 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,120085 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 21:54:00,120171 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,147846 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 21:54:00,147965 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,155569 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 21:54:00,155652 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,162709 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 21:54:00,162786 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,167561 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 21:54:00,167657 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,213539 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 21:54:00,218972 (MainThread): 
2020-02-03 21:54:00,219310 (MainThread): Acquiring new postgres connection "master".
2020-02-03 21:54:00,219398 (MainThread): Opening a new connection, currently in state init
2020-02-03 21:54:00,289269 (MainThread): Using postgres connection "master".
2020-02-03 21:54:00,289434 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 21:54:00,293872 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 21:54:00,324076 (MainThread): Using postgres connection "master".
2020-02-03 21:54:00,324212 (MainThread): On master: BEGIN
2020-02-03 21:54:00,324529 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:54:00,324603 (MainThread): Using postgres connection "master".
2020-02-03 21:54:00,324661 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 21:54:00,326631 (MainThread): SQL status: SELECT 4 in 0.00 seconds
2020-02-03 21:54:00,356850 (MainThread): Using postgres connection "master".
2020-02-03 21:54:00,357001 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 21:54:00,361598 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-03 21:54:00,362604 (MainThread): On master: ROLLBACK
2020-02-03 21:54:00,362799 (MainThread): Using postgres connection "master".
2020-02-03 21:54:00,362879 (MainThread): On master: BEGIN
2020-02-03 21:54:00,363139 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:54:00,363241 (MainThread): On master: COMMIT
2020-02-03 21:54:00,363322 (MainThread): Using postgres connection "master".
2020-02-03 21:54:00,363392 (MainThread): On master: COMMIT
2020-02-03 21:54:00,363636 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:54:00,363897 (MainThread): 16:54:00 | Concurrency: 1 threads (target='dev')
2020-02-03 21:54:00,364011 (MainThread): 16:54:00 | 
2020-02-03 21:54:00,365514 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:54:00,365706 (Thread-1): 16:54:00 | 1 of 3 START seed file public.HEALTHCARE_PROVIDER_TAXONOMY........... [RUN]
2020-02-03 21:54:00,366007 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:54:00,366091 (Thread-1): Opening a new connection, currently in state init
2020-02-03 21:54:00,366212 (Thread-1): finished collecting timing info
2020-02-03 21:54:00,416587 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:54:00,416745 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-03 21:54:00,419981 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:54:00,420107 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:54:00,420197 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"} */
truncate table "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-03 21:54:00,422169 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:54:00,423558 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-03 21:54:00,434747 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:54:00,434922 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s...
2020-02-03 21:54:00,439386 (Thread-1): SQL status: INSERT 0 521 in 0.00 seconds
2020-02-03 21:54:00,439796 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-03 21:54:00,440835 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:54:00,440927 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-03 21:54:00,440997 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-03 21:54:00,445826 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:54:00,448896 (Thread-1): finished collecting timing info
2020-02-03 21:54:00,449456 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d916846-0a7d-4db2-a793-1755e2bfc39e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1204bfbd0>]}
2020-02-03 21:54:00,575242 (Thread-1): 16:54:00 | 1 of 3 OK loaded seed file public.HEALTHCARE_PROVIDER_TAXONOMY....... [INSERT 521 in 0.08s]
2020-02-03 21:54:00,575582 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:54:00,575841 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-03 21:54:00,576106 (Thread-1): 16:54:00 | 2 of 3 START seed file public.npi_small_2019......................... [RUN]
2020-02-03 21:54:00,576585 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:54:00,576723 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-03 21:54:00,576863 (Thread-1): finished collecting timing info
2020-02-03 21:54:00,996596 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:54:00,996756 (Thread-1): On seed.demo_pipeline.npi_small_2019: BEGIN
2020-02-03 21:54:00,997094 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:54:00,997176 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:54:00,997241 (Thread-1): On seed.demo_pipeline.npi_small_2019: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.npi_small_2019"} */
truncate table "demo_db"."public"."npi_small_2019"
2020-02-03 21:54:00,998242 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:54:01,245025 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:54:01,245203 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-03 21:54:01,366049 (Thread-1): SQL status: INSERT 0 10000 in 0.12 seconds
2020-02-03 21:54:01,589180 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:54:01,589871 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-03 21:54:01,700323 (Thread-1): SQL status: INSERT 0 8649 in 0.11 seconds
2020-02-03 21:54:01,701918 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.npi_small_2019"
2020-02-03 21:54:01,703274 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-03 21:54:01,703401 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-03 21:54:01,703495 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-03 21:54:01,708186 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:54:01,711583 (Thread-1): finished collecting timing info
2020-02-03 21:54:01,712191 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d916846-0a7d-4db2-a793-1755e2bfc39e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12055a510>]}
2020-02-03 21:54:01,856968 (Thread-1): 16:54:01 | 2 of 3 OK loaded seed file public.npi_small_2019..................... [INSERT 18649 in 1.14s]
2020-02-03 21:54:01,857210 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-03 21:54:01,857518 (Thread-1): Began running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:54:01,858166 (Thread-1): 16:54:01 | 3 of 3 START seed file public.state_crosswalk........................ [RUN]
2020-02-03 21:54:01,858890 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:54:01,859151 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.npi_small_2019).
2020-02-03 21:54:01,859480 (Thread-1): finished collecting timing info
2020-02-03 21:54:01,866789 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:54:01,866969 (Thread-1): On seed.demo_pipeline.state_crosswalk: BEGIN
2020-02-03 21:54:01,867436 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:54:01,867555 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:54:01,867648 (Thread-1): On seed.demo_pipeline.state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.state_crosswalk"} */
truncate table "demo_db"."public"."state_crosswalk"
2020-02-03 21:54:01,868694 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-03 21:54:01,871402 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:54:01,871514 (Thread-1): On seed.demo_pipeline.state_crosswalk: 
            insert into "demo_db"."public"."state_crosswalk" (State, Abbrev, Code) values
            (%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%s,%s,%s),(%...
2020-02-03 21:54:01,872147 (Thread-1): SQL status: INSERT 0 51 in 0.00 seconds
2020-02-03 21:54:01,872434 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.state_crosswalk"
2020-02-03 21:54:01,873468 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:54:01,873576 (Thread-1): Using postgres connection "seed.demo_pipeline.state_crosswalk".
2020-02-03 21:54:01,873663 (Thread-1): On seed.demo_pipeline.state_crosswalk: COMMIT
2020-02-03 21:54:01,878482 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:54:01,881774 (Thread-1): finished collecting timing info
2020-02-03 21:54:01,882449 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2d916846-0a7d-4db2-a793-1755e2bfc39e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120571950>]}
2020-02-03 21:54:02,48451 (Thread-1): 16:54:02 | 3 of 3 OK loaded seed file public.state_crosswalk.................... [INSERT 51 in 0.02s]
2020-02-03 21:54:02,48793 (Thread-1): Finished running node seed.demo_pipeline.state_crosswalk
2020-02-03 21:54:02,143303 (MainThread): Using postgres connection "master".
2020-02-03 21:54:02,143699 (MainThread): On master: BEGIN
2020-02-03 21:54:02,144342 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 21:54:02,144692 (MainThread): On master: COMMIT
2020-02-03 21:54:02,144950 (MainThread): Using postgres connection "master".
2020-02-03 21:54:02,145181 (MainThread): On master: COMMIT
2020-02-03 21:54:02,145776 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 21:54:02,146516 (MainThread): 16:54:02 | 
2020-02-03 21:54:02,146874 (MainThread): 16:54:02 | Finished running 3 seeds in 1.93s.
2020-02-03 21:54:02,147174 (MainThread): Connection 'master' was left open.
2020-02-03 21:54:02,147408 (MainThread): On master: Close
2020-02-03 21:54:02,147685 (MainThread): Connection 'seed.demo_pipeline.state_crosswalk' was left open.
2020-02-03 21:54:02,147911 (MainThread): On seed.demo_pipeline.state_crosswalk: Close
2020-02-03 21:54:02,160907 (MainThread): 
2020-02-03 21:54:02,161113 (MainThread): Random sample of table: public.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-03 21:54:02,161233 (MainThread): -----------------------------------------------------------
2020-02-03 21:54:02,161507 (MainThread): 
2020-02-03 21:54:02,180203 (MainThread): 
2020-02-03 21:54:02,180447 (MainThread): Random sample of table: public.npi_small_2019
2020-02-03 21:54:02,180616 (MainThread): ---------------------------------------------
2020-02-03 21:54:02,241683 (MainThread): 
2020-02-03 21:54:02,242248 (MainThread): 
2020-02-03 21:54:02,242374 (MainThread): Random sample of table: public.state_crosswalk
2020-02-03 21:54:02,242472 (MainThread): ----------------------------------------------
2020-02-03 21:54:02,242674 (MainThread): 
2020-02-03 21:54:02,242802 (MainThread): 
2020-02-03 21:54:02,242912 (MainThread): Completed successfully
2020-02-03 21:54:02,243018 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-02-03 21:54:02,243203 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120796790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12079d950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120798810>]}
2020-02-03 21:54:02,414550 (MainThread): Flushing usage events
2020-02-03 22:20:37,869108 (MainThread): Running with dbt=0.15.1
2020-02-03 22:20:37,902885 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 22:20:37,940152 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 22:20:37,941240 (MainThread): Tracking: tracking
2020-02-03 22:20:37,957710 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e99fed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e99fdd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e99fb90>]}
2020-02-03 22:20:38,170984 (MainThread): Partial parsing not enabled
2020-02-03 22:20:38,173388 (MainThread): Parsing macros/core.sql
2020-02-03 22:20:38,178500 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 22:20:38,188499 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 22:20:38,191255 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 22:20:38,204990 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 22:20:38,218002 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 22:20:38,237266 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 22:20:38,241040 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 22:20:38,249109 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 22:20:38,255600 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 22:20:38,260436 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 22:20:38,264878 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 22:20:38,268321 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 22:20:38,269251 (MainThread): Parsing macros/etc/query.sql
2020-02-03 22:20:38,270368 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 22:20:38,271886 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 22:20:38,273453 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 22:20:38,278640 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 22:20:38,280259 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 22:20:38,298663 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 22:20:38,299748 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 22:20:38,300688 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 22:20:38,301864 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 22:20:38,304033 (MainThread): Parsing macros/catalog.sql
2020-02-03 22:20:38,305449 (MainThread): Parsing macros/relations.sql
2020-02-03 22:20:38,306770 (MainThread): Parsing macros/adapters.sql
2020-02-03 22:20:38,320038 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 22:20:38,340100 (MainThread): Partial parsing not enabled
2020-02-03 22:20:38,352032 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:20:38,352196 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:20:38,368205 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:20:38,368361 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:20:38,402564 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 22:20:38,402733 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:20:38,412539 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 22:20:38,412705 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:20:38,421139 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 22:20:38,421265 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:20:38,426621 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 22:20:38,426719 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:20:38,435399 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fa83650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fad1510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fb37910>]}
2020-02-03 22:20:38,571175 (MainThread): Flushing usage events
2020-02-03 22:20:38,571523 (MainThread): Connection 'test.demo_pipeline.not_null_my_second_dbt_model_id' was properly closed.
2020-02-03 22:20:38,571759 (MainThread): Encountered an error:
2020-02-03 22:20:38,571997 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Model 'model.demo_pipeline.my_first_dbt_model' depends on model 'country_codes' which was not found or is disabled
2020-02-03 22:20:38,578553 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 300, in run
    self._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 81, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 54, in _runtime_initialize
    self.load_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 46, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 441, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 331, in load_all
    manifest = loader.create_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 312, in create_manifest
    manifest, self.root_project.project_name
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 224, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 206, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/utils.py", line 411, in invalid_ref_fail_unless_test
    target_model_package)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 479, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 357, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Model 'model.demo_pipeline.my_first_dbt_model' depends on model 'country_codes' which was not found or is disabled

2020-02-03 22:23:50,447913 (MainThread): Running with dbt=0.15.1
2020-02-03 22:23:50,485585 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 22:23:50,528643 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 22:23:50,529573 (MainThread): Tracking: tracking
2020-02-03 22:23:50,547327 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227bbb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f89e190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1227bba10>]}
2020-02-03 22:23:50,827303 (MainThread): Partial parsing not enabled
2020-02-03 22:23:50,829945 (MainThread): Parsing macros/core.sql
2020-02-03 22:23:50,833880 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 22:23:50,840013 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 22:23:50,844508 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 22:23:50,860742 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 22:23:50,874384 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 22:23:50,886784 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 22:23:50,888783 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 22:23:50,894231 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 22:23:50,899562 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 22:23:50,904027 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 22:23:50,908509 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 22:23:50,912083 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 22:23:50,912960 (MainThread): Parsing macros/etc/query.sql
2020-02-03 22:23:50,913882 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 22:23:50,915252 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 22:23:50,916817 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 22:23:50,922174 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 22:23:50,923721 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 22:23:50,941424 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 22:23:50,942558 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 22:23:50,943511 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 22:23:50,944659 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 22:23:50,946781 (MainThread): Parsing macros/catalog.sql
2020-02-03 22:23:50,948390 (MainThread): Parsing macros/relations.sql
2020-02-03 22:23:50,949859 (MainThread): Parsing macros/adapters.sql
2020-02-03 22:23:50,957191 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 22:23:50,971606 (MainThread): Partial parsing not enabled
2020-02-03 22:23:50,984098 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:23:50,984249 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:23:50,999203 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:23:50,999372 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:23:51,31890 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 22:23:51,32046 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:23:51,40868 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 22:23:51,41061 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:23:51,49281 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 22:23:51,49390 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:23:51,54670 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 22:23:51,54757 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:23:51,63327 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12291e150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1228af850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1228af610>]}
2020-02-03 22:23:51,208977 (MainThread): Flushing usage events
2020-02-03 22:23:51,209296 (MainThread): Connection 'test.demo_pipeline.not_null_my_second_dbt_model_id' was properly closed.
2020-02-03 22:23:51,209520 (MainThread): Encountered an error:
2020-02-03 22:23:51,209752 (MainThread): Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Model 'model.demo_pipeline.my_first_dbt_model' depends on model 'country_codes' which was not found or is disabled
2020-02-03 22:23:51,215840 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 300, in run
    self._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 81, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 54, in _runtime_initialize
    self.load_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 46, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 441, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 331, in load_all
    manifest = loader.create_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 312, in create_manifest
    manifest, self.root_project.project_name
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 224, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 206, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/utils.py", line 411, in invalid_ref_fail_unless_test
    target_model_package)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 479, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 357, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model my_first_dbt_model (models/example/my_first_dbt_model.sql)
  Model 'model.demo_pipeline.my_first_dbt_model' depends on model 'country_codes' which was not found or is disabled

2020-02-03 22:24:09,395458 (MainThread): Running with dbt=0.15.1
2020-02-03 22:24:09,424445 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 22:24:09,454556 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 22:24:09,455039 (MainThread): Tracking: tracking
2020-02-03 22:24:09,468121 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a28a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fe68d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120a28890>]}
2020-02-03 22:24:09,657453 (MainThread): Partial parsing not enabled
2020-02-03 22:24:09,659213 (MainThread): Parsing macros/core.sql
2020-02-03 22:24:09,662688 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 22:24:09,667657 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 22:24:09,668852 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 22:24:09,679576 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 22:24:09,691963 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 22:24:09,703564 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 22:24:09,704889 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 22:24:09,708951 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 22:24:09,713357 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 22:24:09,717018 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 22:24:09,720640 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 22:24:09,723738 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 22:24:09,724406 (MainThread): Parsing macros/etc/query.sql
2020-02-03 22:24:09,725192 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 22:24:09,726358 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 22:24:09,727743 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 22:24:09,733124 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 22:24:09,734469 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 22:24:09,752509 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 22:24:09,753394 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 22:24:09,754087 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 22:24:09,754883 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 22:24:09,756383 (MainThread): Parsing macros/catalog.sql
2020-02-03 22:24:09,757570 (MainThread): Parsing macros/relations.sql
2020-02-03 22:24:09,758653 (MainThread): Parsing macros/adapters.sql
2020-02-03 22:24:09,765503 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 22:24:09,778733 (MainThread): Partial parsing not enabled
2020-02-03 22:24:09,788294 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:09,788380 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,799765 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:09,799856 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,833915 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 22:24:09,834061 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,843001 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 22:24:09,843098 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,850238 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 22:24:09,850320 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,855007 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 22:24:09,855084 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,899974 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 22:24:09,904173 (MainThread): 
2020-02-03 22:24:09,904559 (MainThread): Acquiring new postgres connection "master".
2020-02-03 22:24:09,904655 (MainThread): Opening a new connection, currently in state init
2020-02-03 22:24:09,974626 (MainThread): Using postgres connection "master".
2020-02-03 22:24:09,974789 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 22:24:09,979328 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 22:24:10,10866 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,11091 (MainThread): On master: BEGIN
2020-02-03 22:24:10,12400 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 22:24:10,12523 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,12608 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 22:24:10,14799 (MainThread): SQL status: SELECT 4 in 0.00 seconds
2020-02-03 22:24:10,44890 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,45039 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 22:24:10,48547 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-03 22:24:10,49471 (MainThread): On master: ROLLBACK
2020-02-03 22:24:10,49666 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,49745 (MainThread): On master: BEGIN
2020-02-03 22:24:10,49950 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 22:24:10,50035 (MainThread): On master: COMMIT
2020-02-03 22:24:10,50106 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,50169 (MainThread): On master: COMMIT
2020-02-03 22:24:10,50293 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 22:24:10,50528 (MainThread): 17:24:10 | Concurrency: 1 threads (target='dev')
2020-02-03 22:24:10,50635 (MainThread): 17:24:10 | 
2020-02-03 22:24:10,52838 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 22:24:10,53086 (Thread-1): 17:24:10 | 1 of 2 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 22:24:10,53409 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,53494 (Thread-1): Opening a new connection, currently in state init
2020-02-03 22:24:10,53585 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 22:24:10,65784 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 22:24:10,66355 (Thread-1): finished collecting timing info
2020-02-03 22:24:10,81634 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,81797 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 22:24:10,85763 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 22:24:10,88218 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,88309 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 22:24:10,88556 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 22:24:10,101148 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 22:24:10,101640 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,101727 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 22:24:10,102022 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 22:24:10,102102 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,102167 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 22:24:10,103723 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 22:24:10,105679 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,105767 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 22:24:10,106165 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 22:24:10,106884 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 22:24:10,106969 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,107037 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 22:24:10,107523 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 22:24:10,108940 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 22:24:10,109037 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 22:24:10,109225 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 22:24:10,111167 (Thread-1): finished collecting timing info
2020-02-03 22:24:10,111698 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '408d2414-b816-4bd2-bcae-a31a78d3e86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120b6e2d0>]}
2020-02-03 22:24:10,259563 (Thread-1): 17:24:10 | 1 of 2 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.06s]
2020-02-03 22:24:10,259905 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 22:24:10,260598 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 22:24:10,260834 (Thread-1): 17:24:10 | 2 of 2 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 22:24:10,261239 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,261371 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 22:24:10,261497 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 22:24:10,269633 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 22:24:10,270081 (Thread-1): finished collecting timing info
2020-02-03 22:24:10,289323 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,289478 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 22:24:10,289846 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 22:24:10,291676 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,291767 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 22:24:10,292009 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 22:24:10,293174 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 22:24:10,293530 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,293657 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 22:24:10,293822 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 22:24:10,293906 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,293977 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 22:24:10,301731 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-02-03 22:24:10,304660 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,304775 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 22:24:10,305112 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 22:24:10,305885 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 22:24:10,306002 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,306083 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 22:24:10,306567 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 22:24:10,308652 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 22:24:10,308758 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 22:24:10,308995 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 22:24:10,311207 (Thread-1): finished collecting timing info
2020-02-03 22:24:10,311760 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '408d2414-b816-4bd2-bcae-a31a78d3e86f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121da4650>]}
2020-02-03 22:24:10,433350 (Thread-1): 17:24:10 | 2 of 2 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.05s]
2020-02-03 22:24:10,433689 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 22:24:10,462819 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,463256 (MainThread): On master: BEGIN
2020-02-03 22:24:10,463903 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 22:24:10,464167 (MainThread): On master: COMMIT
2020-02-03 22:24:10,464345 (MainThread): Using postgres connection "master".
2020-02-03 22:24:10,464497 (MainThread): On master: COMMIT
2020-02-03 22:24:10,464809 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 22:24:10,465303 (MainThread): 17:24:10 | 
2020-02-03 22:24:10,465534 (MainThread): 17:24:10 | Finished running 1 table model, 1 view model in 0.56s.
2020-02-03 22:24:10,465733 (MainThread): Connection 'master' was left open.
2020-02-03 22:24:10,465901 (MainThread): On master: Close
2020-02-03 22:24:10,466085 (MainThread): Connection 'model.demo_pipeline.my_second_dbt_model' was left open.
2020-02-03 22:24:10,466230 (MainThread): On model.demo_pipeline.my_second_dbt_model: Close
2020-02-03 22:24:10,472373 (MainThread): 
2020-02-03 22:24:10,472538 (MainThread): Completed successfully
2020-02-03 22:24:10,472680 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-02-03 22:24:10,472903 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121da4b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121c53d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d97250>]}
2020-02-03 22:24:10,588249 (MainThread): Flushing usage events
2020-02-03 23:31:57,588123 (MainThread): Running with dbt=0.15.1
2020-02-03 23:31:57,625599 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:31:57,667892 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:31:57,669170 (MainThread): Tracking: tracking
2020-02-03 23:31:57,702126 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa2ab50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa2a6d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11aa2a910>]}
2020-02-03 23:31:58,121587 (MainThread): Partial parsing not enabled
2020-02-03 23:31:58,125400 (MainThread): Parsing macros/core.sql
2020-02-03 23:31:58,129672 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:31:58,136639 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:31:58,139220 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:31:58,152405 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:31:58,165571 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:31:58,177453 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:31:58,179391 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:31:58,184638 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:31:58,190576 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:31:58,195530 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:31:58,200001 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:31:58,203914 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:31:58,205031 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:31:58,206399 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:31:58,208421 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:31:58,210293 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:31:58,216641 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:31:58,218456 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:31:58,238736 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:31:58,239861 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:31:58,240808 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:31:58,241953 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:31:58,243910 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:31:58,245386 (MainThread): Parsing macros/relations.sql
2020-02-03 23:31:58,246749 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:31:58,254221 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:31:58,269895 (MainThread): Partial parsing not enabled
2020-02-03 23:31:58,283283 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,283434 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,298019 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,298166 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,331521 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:31:58,331682 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,341712 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:31:58,341876 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,349775 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:31:58,349874 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,355212 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:31:58,355337 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,426745 (MainThread): Found 2 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:31:58,433203 (MainThread): 
2020-02-03 23:31:58,434042 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:31:58,434198 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:31:58,529890 (MainThread): Using postgres connection "master".
2020-02-03 23:31:58,530033 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:31:58,535148 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-03 23:31:58,569022 (MainThread): Using postgres connection "master".
2020-02-03 23:31:58,569162 (MainThread): On master: BEGIN
2020-02-03 23:31:58,569912 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:31:58,570010 (MainThread): Using postgres connection "master".
2020-02-03 23:31:58,570149 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:31:58,574113 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:31:58,610945 (MainThread): Using postgres connection "master".
2020-02-03 23:31:58,611201 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:31:58,618163 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-02-03 23:31:58,620315 (MainThread): On master: ROLLBACK
2020-02-03 23:31:58,620734 (MainThread): Using postgres connection "master".
2020-02-03 23:31:58,620884 (MainThread): On master: BEGIN
2020-02-03 23:31:58,621198 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:31:58,621315 (MainThread): On master: COMMIT
2020-02-03 23:31:58,621447 (MainThread): Using postgres connection "master".
2020-02-03 23:31:58,621610 (MainThread): On master: COMMIT
2020-02-03 23:31:58,621811 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:31:58,622120 (MainThread): 18:31:58 | Concurrency: 1 threads (target='dev')
2020-02-03 23:31:58,622255 (MainThread): 18:31:58 | 
2020-02-03 23:31:58,625349 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:31:58,625614 (Thread-1): 18:31:58 | 1 of 2 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:31:58,626218 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,626357 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:31:58,626533 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:31:58,644569 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:31:58,646252 (Thread-1): finished collecting timing info
2020-02-03 23:31:58,665019 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,665168 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:31:58,668627 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:31:58,670755 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,670859 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:31:58,671055 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:31:58,684480 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:31:58,685108 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,685320 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:31:58,685649 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:31:58,685732 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,685799 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:31:58,691942 (Thread-1): SQL status: SELECT 2 in 0.01 seconds
2020-02-03 23:31:58,695076 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,695161 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:31:58,695534 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:31:58,697340 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,697428 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:31:58,698452 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:31:58,699569 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:31:58,699681 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,699751 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:31:58,700533 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:31:58,702016 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:31:58,702127 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:31:58,711052 (Thread-1): SQL status: DROP TABLE in 0.01 seconds
2020-02-03 23:31:58,713152 (Thread-1): finished collecting timing info
2020-02-03 23:31:58,713690 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d51905d-403a-4e2d-a875-3fae28a9e80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab1ef10>]}
2020-02-03 23:31:58,880960 (Thread-1): 18:31:58 | 1 of 2 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.09s]
2020-02-03 23:31:58,881308 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:31:58,881909 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:31:58,882164 (Thread-1): 18:31:58 | 2 of 2 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:31:58,882569 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,882703 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:31:58,882832 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:31:58,892426 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:31:58,892941 (Thread-1): finished collecting timing info
2020-02-03 23:31:58,915654 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,915894 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:31:58,916412 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:31:58,919330 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,919498 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:31:58,919818 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:31:58,921308 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:31:58,921746 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,921849 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:31:58,922024 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:31:58,922123 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,922206 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:31:58,927271 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:31:58,929902 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,930038 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:31:58,930406 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:31:58,931229 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:31:58,931341 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,931430 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:31:58,931931 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:31:58,934243 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:31:58,934515 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:31:58,934926 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:31:58,937670 (Thread-1): finished collecting timing info
2020-02-03 23:31:58,938332 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8d51905d-403a-4e2d-a875-3fae28a9e80f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd4c490>]}
2020-02-03 23:31:59,84546 (Thread-1): 18:31:59 | 2 of 2 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.06s]
2020-02-03 23:31:59,84908 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:31:59,135540 (MainThread): Using postgres connection "master".
2020-02-03 23:31:59,135746 (MainThread): On master: BEGIN
2020-02-03 23:31:59,136083 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:31:59,136227 (MainThread): On master: COMMIT
2020-02-03 23:31:59,136331 (MainThread): Using postgres connection "master".
2020-02-03 23:31:59,136425 (MainThread): On master: COMMIT
2020-02-03 23:31:59,136726 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:31:59,137135 (MainThread): 18:31:59 | 
2020-02-03 23:31:59,137330 (MainThread): 18:31:59 | Finished running 1 table model, 1 view model in 0.70s.
2020-02-03 23:31:59,137510 (MainThread): Connection 'master' was left open.
2020-02-03 23:31:59,137657 (MainThread): On master: Close
2020-02-03 23:31:59,137834 (MainThread): Connection 'model.demo_pipeline.my_second_dbt_model' was left open.
2020-02-03 23:31:59,137974 (MainThread): On model.demo_pipeline.my_second_dbt_model: Close
2020-02-03 23:31:59,146424 (MainThread): 
2020-02-03 23:31:59,146889 (MainThread): Completed successfully
2020-02-03 23:31:59,147052 (MainThread): 
Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
2020-02-03 23:31:59,147393 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bc4e710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bc4ed10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bd9ff50>]}
2020-02-03 23:31:59,340768 (MainThread): Flushing usage events
2020-02-03 23:32:19,834012 (MainThread): Running with dbt=0.15.1
2020-02-03 23:32:19,863943 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:32:19,894568 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:32:19,895053 (MainThread): Tracking: tracking
2020-02-03 23:32:19,909432 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128628d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12826e090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128628ad0>]}
2020-02-03 23:32:20,172484 (MainThread): Partial parsing not enabled
2020-02-03 23:32:20,174277 (MainThread): Parsing macros/core.sql
2020-02-03 23:32:20,177595 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:32:20,182774 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:32:20,184001 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:32:20,195001 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:32:20,208344 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:32:20,220252 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:32:20,221658 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:32:20,225990 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:32:20,230915 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:32:20,235031 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:32:20,239011 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:32:20,242061 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:32:20,242814 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:32:20,243988 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:32:20,245886 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:32:20,247415 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:32:20,252976 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:32:20,254529 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:32:20,274016 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:32:20,275002 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:32:20,275722 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:32:20,276536 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:32:20,278132 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:32:20,279400 (MainThread): Parsing macros/relations.sql
2020-02-03 23:32:20,280553 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:32:20,287596 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:32:20,304304 (MainThread): Partial parsing not enabled
2020-02-03 23:32:20,317023 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:32:20,317182 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,332353 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:32:20,332524 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,338363 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:32:20,338541 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,343249 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,343338 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,348118 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:20,348385 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,382569 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:32:20,382719 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,393645 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:32:20,393817 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,405909 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:32:20,406050 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,412330 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:32:20,412506 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,466463 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:32:20,474232 (MainThread): 
2020-02-03 23:32:20,474619 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:32:20,474722 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:32:20,552864 (MainThread): Using postgres connection "master".
2020-02-03 23:32:20,553016 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:32:20,556748 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:32:20,595658 (MainThread): Using postgres connection "master".
2020-02-03 23:32:20,595820 (MainThread): On master: BEGIN
2020-02-03 23:32:20,596425 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:20,596552 (MainThread): Using postgres connection "master".
2020-02-03 23:32:20,596672 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:32:20,599611 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:32:20,638308 (MainThread): Using postgres connection "master".
2020-02-03 23:32:20,638468 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:32:20,643688 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-02-03 23:32:20,645387 (MainThread): On master: ROLLBACK
2020-02-03 23:32:20,645694 (MainThread): Using postgres connection "master".
2020-02-03 23:32:20,645788 (MainThread): On master: BEGIN
2020-02-03 23:32:20,646079 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:20,646188 (MainThread): On master: COMMIT
2020-02-03 23:32:20,646268 (MainThread): Using postgres connection "master".
2020-02-03 23:32:20,646334 (MainThread): On master: COMMIT
2020-02-03 23:32:20,646482 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:32:20,646751 (MainThread): 18:32:20 | Concurrency: 1 threads (target='dev')
2020-02-03 23:32:20,646863 (MainThread): 18:32:20 | 
2020-02-03 23:32:20,648379 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:32:20,648546 (Thread-1): 18:32:20 | 1 of 5 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:32:20,648804 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,648883 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:32:20,648969 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:32:20,660221 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:32:20,660694 (Thread-1): finished collecting timing info
2020-02-03 23:32:20,678815 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,678979 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:32:20,682340 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:32:20,684395 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,684509 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:32:20,684792 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:32:20,697950 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:32:20,698455 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,698557 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:32:20,698878 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:20,698974 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,699046 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:32:20,700633 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 23:32:20,704291 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,704382 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:32:20,704729 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:32:20,706478 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,706569 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:32:20,706905 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:32:20,707560 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:32:20,707644 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,707712 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:32:20,708342 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:32:20,710045 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:32:20,710150 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:32:20,711770 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:32:20,713874 (Thread-1): finished collecting timing info
2020-02-03 23:32:20,714444 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2af17d1c-0f53-4b6c-befe-34863e117ce8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1298670d0>]}
2020-02-03 23:32:20,884054 (Thread-1): 18:32:20 | 1 of 5 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.07s]
2020-02-03 23:32:20,884396 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:32:20,884599 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:32:20,884800 (Thread-1): 18:32:20 | 2 of 5 START view model public.stg_npi............................... [RUN]
2020-02-03 23:32:20,885443 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:32:20,885592 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:32:20,885723 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:32:20,893413 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:32:20,894005 (Thread-1): finished collecting timing info
2020-02-03 23:32:20,919822 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:32:20,920060 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:32:20,920490 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:20,923631 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:32:20,923820 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:32:20,924095 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:20,926939 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:32:20,929004 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:32:20,929230 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:32:20,929538 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:20,929679 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:32:20,929779 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    # No modifications to the npi file needed

select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:32:20,930190 (Thread-1): Postgres error: syntax error at or near "#"
LINE 5:     # No modifications to the npi file needed
            ^

2020-02-03 23:32:20,930331 (Thread-1): On model.demo_pipeline.stg_npi: ROLLBACK
2020-02-03 23:32:20,930589 (Thread-1): finished collecting timing info
2020-02-03 23:32:20,931092 (Thread-1): Database Error in model stg_npi (models/staging/stg_npi.sql)
  syntax error at or near "#"
  LINE 5:     # No modifications to the npi file needed
              ^
  compiled SQL at target/run/demo_pipeline/staging/stg_npi.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: syntax error at or near "#"
LINE 5:     # No modifications to the npi file needed
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_npi (models/staging/stg_npi.sql)
  syntax error at or near "#"
  LINE 5:     # No modifications to the npi file needed
              ^
  compiled SQL at target/run/demo_pipeline/staging/stg_npi.sql
2020-02-03 23:32:20,939582 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2af17d1c-0f53-4b6c-befe-34863e117ce8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1299dfd90>]}
2020-02-03 23:32:21,85418 (Thread-1): 18:32:21 | 2 of 5 ERROR creating view model public.stg_npi...................... [ERROR in 0.05s]
2020-02-03 23:32:21,85750 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:32:21,86073 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:32:21,86380 (Thread-1): 18:32:21 | 3 of 5 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:32:21,87067 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:32:21,87187 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:32:21,87294 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:32:21,100087 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:32:21,100710 (Thread-1): finished collecting timing info
2020-02-03 23:32:21,110441 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:32:21,110640 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:32:21,111263 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,118506 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:32:21,118834 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:32:21,119380 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,121334 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:32:21,121849 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:32:21,121965 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:32:21,122246 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:21,122378 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:32:21,122534 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    # No modifications to the state crosswalk needed

select 
	State as state, 
	"Code" as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:32:21,123094 (Thread-1): Postgres error: syntax error at or near "#"
LINE 5:     # No modifications to the state crosswalk needed
            ^

2020-02-03 23:32:21,123275 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: ROLLBACK
2020-02-03 23:32:21,123616 (Thread-1): finished collecting timing info
2020-02-03 23:32:21,124145 (Thread-1): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  syntax error at or near "#"
  LINE 5:     # No modifications to the state crosswalk needed
              ^
  compiled SQL at target/run/demo_pipeline/staging/stg_state_crosswalk.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: syntax error at or near "#"
LINE 5:     # No modifications to the state crosswalk needed
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  syntax error at or near "#"
  LINE 5:     # No modifications to the state crosswalk needed
              ^
  compiled SQL at target/run/demo_pipeline/staging/stg_state_crosswalk.sql
2020-02-03 23:32:21,125340 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2af17d1c-0f53-4b6c-befe-34863e117ce8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129955210>]}
2020-02-03 23:32:21,353186 (Thread-1): 18:32:21 | 3 of 5 ERROR creating view model public.stg_state_crosswalk.......... [ERROR in 0.04s]
2020-02-03 23:32:21,353506 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:32:21,353752 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:32:21,353952 (Thread-1): 18:32:21 | 4 of 5 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:32:21,354634 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:32:21,354778 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:32:21,354907 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:32:21,362455 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:32:21,362934 (Thread-1): finished collecting timing info
2020-02-03 23:32:21,369797 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:32:21,369929 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:32:21,370326 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,373444 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:32:21,373663 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:32:21,374108 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,375843 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:32:21,376309 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:32:21,376430 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:32:21,376716 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:21,376843 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:32:21,376935 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    # No modifications to the state crosswalk needed

select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:32:21,377174 (Thread-1): Postgres error: syntax error at or near "#"
LINE 5:     # No modifications to the state crosswalk needed
            ^

2020-02-03 23:32:21,377282 (Thread-1): On model.demo_pipeline.stg_taxonomy: ROLLBACK
2020-02-03 23:32:21,377550 (Thread-1): finished collecting timing info
2020-02-03 23:32:21,377990 (Thread-1): Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
  syntax error at or near "#"
  LINE 5:     # No modifications to the state crosswalk needed
              ^
  compiled SQL at target/run/demo_pipeline/staging/stg_taxonomy.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: syntax error at or near "#"
LINE 5:     # No modifications to the state crosswalk needed
            ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
  syntax error at or near "#"
  LINE 5:     # No modifications to the state crosswalk needed
              ^
  compiled SQL at target/run/demo_pipeline/staging/stg_taxonomy.sql
2020-02-03 23:32:21,378614 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2af17d1c-0f53-4b6c-befe-34863e117ce8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1299a9910>]}
2020-02-03 23:32:21,565782 (Thread-1): 18:32:21 | 4 of 5 ERROR creating view model public.stg_taxonomy................. [ERROR in 0.02s]
2020-02-03 23:32:21,566116 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:32:21,566372 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:32:21,566938 (Thread-1): 18:32:21 | 5 of 5 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:32:21,567475 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,567618 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:32:21,567750 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:32:21,575997 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:32:21,576459 (Thread-1): finished collecting timing info
2020-02-03 23:32:21,583204 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,583334 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:32:21,583788 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,586018 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,586124 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:32:21,586338 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,589889 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:32:21,590927 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,591160 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:32:21,591559 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:21,591705 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,591930 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:32:21,597228 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-02-03 23:32:21,600695 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,600957 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:32:21,601531 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:32:21,603239 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:32:21,603397 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,603500 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:32:21,603979 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:32:21,606064 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:32:21,606214 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:32:21,606522 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:32:21,609076 (Thread-1): finished collecting timing info
2020-02-03 23:32:21,609759 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2af17d1c-0f53-4b6c-befe-34863e117ce8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1299e6550>]}
2020-02-03 23:32:21,840667 (Thread-1): 18:32:21 | 5 of 5 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-03 23:32:21,840990 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:32:21,871087 (MainThread): Using postgres connection "master".
2020-02-03 23:32:21,871276 (MainThread): On master: BEGIN
2020-02-03 23:32:21,871574 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:32:21,871716 (MainThread): On master: COMMIT
2020-02-03 23:32:21,871819 (MainThread): Using postgres connection "master".
2020-02-03 23:32:21,871910 (MainThread): On master: COMMIT
2020-02-03 23:32:21,872132 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:32:21,872453 (MainThread): 18:32:21 | 
2020-02-03 23:32:21,872599 (MainThread): 18:32:21 | Finished running 1 table model, 4 view models in 1.40s.
2020-02-03 23:32:21,872722 (MainThread): Connection 'master' was left open.
2020-02-03 23:32:21,872812 (MainThread): On master: Close
2020-02-03 23:32:21,872922 (MainThread): Connection 'model.demo_pipeline.my_second_dbt_model' was left open.
2020-02-03 23:32:21,873012 (MainThread): On model.demo_pipeline.my_second_dbt_model: Close
2020-02-03 23:32:21,885798 (MainThread): 
2020-02-03 23:32:21,886131 (MainThread): Completed with 3 errors and 0 warnings:
2020-02-03 23:32:21,886335 (MainThread): 
2020-02-03 23:32:21,886535 (MainThread): Database Error in model stg_npi (models/staging/stg_npi.sql)
2020-02-03 23:32:21,886721 (MainThread):   syntax error at or near "#"
2020-02-03 23:32:21,886895 (MainThread):   LINE 5:     # No modifications to the npi file needed
2020-02-03 23:32:21,887149 (MainThread):               ^
2020-02-03 23:32:21,887401 (MainThread):   compiled SQL at target/run/demo_pipeline/staging/stg_npi.sql
2020-02-03 23:32:21,887669 (MainThread): 
2020-02-03 23:32:21,887884 (MainThread): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
2020-02-03 23:32:21,888261 (MainThread):   syntax error at or near "#"
2020-02-03 23:32:21,888599 (MainThread):   LINE 5:     # No modifications to the state crosswalk needed
2020-02-03 23:32:21,888906 (MainThread):               ^
2020-02-03 23:32:21,889188 (MainThread):   compiled SQL at target/run/demo_pipeline/staging/stg_state_crosswalk.sql
2020-02-03 23:32:21,889505 (MainThread): 
2020-02-03 23:32:21,889861 (MainThread): Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
2020-02-03 23:32:21,890102 (MainThread):   syntax error at or near "#"
2020-02-03 23:32:21,890326 (MainThread):   LINE 5:     # No modifications to the state crosswalk needed
2020-02-03 23:32:21,890575 (MainThread):               ^
2020-02-03 23:32:21,890762 (MainThread):   compiled SQL at target/run/demo_pipeline/staging/stg_taxonomy.sql
2020-02-03 23:32:21,891034 (MainThread): 
Done. PASS=2 WARN=0 ERROR=3 SKIP=0 TOTAL=5
2020-02-03 23:32:21,891380 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112c34d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1299e2cd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128631e50>]}
2020-02-03 23:32:22,104923 (MainThread): Flushing usage events
2020-02-03 23:33:06,423113 (MainThread): Running with dbt=0.15.1
2020-02-03 23:33:06,452397 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:33:06,481230 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:33:06,481697 (MainThread): Tracking: tracking
2020-02-03 23:33:06,495268 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119da5450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119a917d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x119da5c50>]}
2020-02-03 23:33:06,702683 (MainThread): Partial parsing not enabled
2020-02-03 23:33:06,704425 (MainThread): Parsing macros/core.sql
2020-02-03 23:33:06,707512 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:33:06,712262 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:33:06,713407 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:33:06,724708 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:33:06,739323 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:33:06,751984 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:33:06,753385 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:33:06,757755 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:33:06,762542 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:33:06,766660 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:33:06,770636 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:33:06,773717 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:33:06,774569 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:33:06,775323 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:33:06,776445 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:33:06,777751 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:33:06,782811 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:33:06,784026 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:33:06,803269 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:33:06,804186 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:33:06,804841 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:33:06,805589 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:33:06,807042 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:33:06,808422 (MainThread): Parsing macros/relations.sql
2020-02-03 23:33:06,809474 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:33:06,815717 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:33:06,829489 (MainThread): Partial parsing not enabled
2020-02-03 23:33:06,839940 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:06,840038 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,853827 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:06,853972 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,858150 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:06,858238 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,862807 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:06,862900 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,866501 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:06,866577 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,896960 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:33:06,897135 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,905846 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:33:06,905939 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,914364 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:33:06,914511 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,920010 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:33:06,920098 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:06,971919 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:33:06,978624 (MainThread): 
2020-02-03 23:33:06,979079 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:33:06,979182 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:07,54550 (MainThread): Using postgres connection "master".
2020-02-03 23:33:07,54699 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:33:07,59005 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:33:07,97511 (MainThread): Using postgres connection "master".
2020-02-03 23:33:07,97670 (MainThread): On master: BEGIN
2020-02-03 23:33:07,98004 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,98080 (MainThread): Using postgres connection "master".
2020-02-03 23:33:07,98140 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:33:07,100022 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:33:07,136770 (MainThread): Using postgres connection "master".
2020-02-03 23:33:07,136926 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:33:07,143274 (MainThread): SQL status: SELECT 1 in 0.01 seconds
2020-02-03 23:33:07,145171 (MainThread): On master: ROLLBACK
2020-02-03 23:33:07,145427 (MainThread): Using postgres connection "master".
2020-02-03 23:33:07,145506 (MainThread): On master: BEGIN
2020-02-03 23:33:07,145736 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,145832 (MainThread): On master: COMMIT
2020-02-03 23:33:07,145908 (MainThread): Using postgres connection "master".
2020-02-03 23:33:07,145973 (MainThread): On master: COMMIT
2020-02-03 23:33:07,146112 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:07,146366 (MainThread): 18:33:07 | Concurrency: 1 threads (target='dev')
2020-02-03 23:33:07,146475 (MainThread): 18:33:07 | 
2020-02-03 23:33:07,147790 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:33:07,147941 (Thread-1): 18:33:07 | 1 of 5 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:33:07,148175 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,148253 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:33:07,148340 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:33:07,160538 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:33:07,160984 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,177245 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,177835 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:33:07,182763 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:33:07,185167 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,185293 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:33:07,185593 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:33:07,198833 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:33:07,199274 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,199359 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:33:07,199652 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,199731 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,199796 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:33:07,201302 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 23:33:07,205522 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,205633 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:33:07,205970 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:07,207997 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,208095 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:33:07,208453 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:07,209141 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:33:07,209232 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,209305 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:33:07,209944 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:07,211548 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:07,211645 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:33:07,214745 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:33:07,217369 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,218008 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f0e5543-215e-4b1c-aa51-5d1278acbdfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afd77d0>]}
2020-02-03 23:33:07,352542 (Thread-1): 18:33:07 | 1 of 5 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.07s]
2020-02-03 23:33:07,352831 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:33:07,353030 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:33:07,353236 (Thread-1): 18:33:07 | 2 of 5 START view model public.stg_npi............................... [RUN]
2020-02-03 23:33:07,353640 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,353775 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:33:07,353909 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:33:07,361494 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:33:07,362154 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,382212 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,382406 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:33:07,382741 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,384916 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,385025 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:33:07,385327 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,386591 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:33:07,387056 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,387232 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:33:07,387569 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,387678 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,387763 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:33:07,388720 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:07,391014 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,391161 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:33:07,391749 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:07,392614 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:33:07,392717 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,392796 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:33:07,393294 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:07,394870 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:07,394974 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:33:07,395187 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,397232 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,397782 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f0e5543-215e-4b1c-aa51-5d1278acbdfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afdf110>]}
2020-02-03 23:33:07,525207 (Thread-1): 18:33:07 | 2 of 5 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.04s]
2020-02-03 23:33:07,525544 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:33:07,525802 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:33:07,526210 (Thread-1): 18:33:07 | 3 of 5 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:33:07,526632 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:07,526756 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:33:07,526880 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:33:07,534293 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:33:07,534733 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,541730 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:07,541908 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:33:07,542269 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,545482 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:07,545705 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:33:07,546163 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,547774 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:33:07,548252 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:07,548365 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:33:07,548565 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,548674 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:07,548764 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	"Code" as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:33:07,549151 (Thread-1): Postgres error: column "Code" does not exist
LINE 7:  "Code" as state_abbrev
         ^
HINT:  Perhaps you meant to reference the column "state_crosswalk.code".

2020-02-03 23:33:07,549262 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: ROLLBACK
2020-02-03 23:33:07,549490 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,549952 (Thread-1): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  column "Code" does not exist
  LINE 7:  "Code" as state_abbrev
           ^
  HINT:  Perhaps you meant to reference the column "state_crosswalk.code".
  compiled SQL at target/run/demo_pipeline/staging/stg_state_crosswalk.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: column "Code" does not exist
LINE 7:  "Code" as state_abbrev
         ^
HINT:  Perhaps you meant to reference the column "state_crosswalk.code".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  column "Code" does not exist
  LINE 7:  "Code" as state_abbrev
           ^
  HINT:  Perhaps you meant to reference the column "state_crosswalk.code".
  compiled SQL at target/run/demo_pipeline/staging/stg_state_crosswalk.sql
2020-02-03 23:33:07,551822 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f0e5543-215e-4b1c-aa51-5d1278acbdfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b3871d0>]}
2020-02-03 23:33:07,688846 (Thread-1): 18:33:07 | 3 of 5 ERROR creating view model public.stg_state_crosswalk.......... [ERROR in 0.03s]
2020-02-03 23:33:07,689193 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:33:07,689462 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:33:07,690023 (Thread-1): 18:33:07 | 4 of 5 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:33:07,690805 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,691047 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:33:07,691232 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:33:07,701486 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:33:07,701996 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,708897 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,709089 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:33:07,709534 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,712053 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,712182 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:33:07,712429 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,714263 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:33:07,715129 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,715531 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:33:07,716020 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,716173 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,716276 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:33:07,717167 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:07,720894 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,721084 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:33:07,721544 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:07,722595 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:33:07,722722 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,722818 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:33:07,723275 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:07,726305 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:07,726456 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:33:07,726755 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,729238 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,729866 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f0e5543-215e-4b1c-aa51-5d1278acbdfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afedcd0>]}
2020-02-03 23:33:07,852991 (Thread-1): 18:33:07 | 4 of 5 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:33:07,853316 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:33:07,853570 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:33:07,853823 (Thread-1): 18:33:07 | 5 of 5 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:33:07,854327 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,854495 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:33:07,854661 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:33:07,863710 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:33:07,864276 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,871333 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,871509 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:33:07,871857 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,874465 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,874625 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:33:07,874939 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,876501 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:33:07,876955 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,877083 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:33:07,877307 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:07,877413 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,877526 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:33:07,878408 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:07,880794 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,880928 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:33:07,881322 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:07,882476 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:33:07,882600 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,882685 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:33:07,883138 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:07,884954 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:07,885065 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:33:07,885338 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:07,887999 (Thread-1): finished collecting timing info
2020-02-03 23:33:07,888590 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8f0e5543-215e-4b1c-aa51-5d1278acbdfd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b12aad0>]}
2020-02-03 23:33:08,7080 (Thread-1): 18:33:08 | 5 of 5 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.03s]
2020-02-03 23:33:08,7426 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:33:08,70686 (MainThread): Using postgres connection "master".
2020-02-03 23:33:08,71069 (MainThread): On master: BEGIN
2020-02-03 23:33:08,71724 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:08,72060 (MainThread): On master: COMMIT
2020-02-03 23:33:08,72306 (MainThread): Using postgres connection "master".
2020-02-03 23:33:08,72523 (MainThread): On master: COMMIT
2020-02-03 23:33:08,73106 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:08,73914 (MainThread): 18:33:08 | 
2020-02-03 23:33:08,74232 (MainThread): 18:33:08 | Finished running 1 table model, 4 view models in 1.09s.
2020-02-03 23:33:08,74428 (MainThread): Connection 'master' was left open.
2020-02-03 23:33:08,74574 (MainThread): On master: Close
2020-02-03 23:33:08,74752 (MainThread): Connection 'model.demo_pipeline.my_second_dbt_model' was left open.
2020-02-03 23:33:08,74893 (MainThread): On model.demo_pipeline.my_second_dbt_model: Close
2020-02-03 23:33:08,89062 (MainThread): 
2020-02-03 23:33:08,89273 (MainThread): Completed with 1 error and 0 warnings:
2020-02-03 23:33:08,89404 (MainThread): 
2020-02-03 23:33:08,89559 (MainThread): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
2020-02-03 23:33:08,89691 (MainThread):   column "Code" does not exist
2020-02-03 23:33:08,89808 (MainThread):   LINE 7:  "Code" as state_abbrev
2020-02-03 23:33:08,89926 (MainThread):            ^
2020-02-03 23:33:08,90067 (MainThread):   HINT:  Perhaps you meant to reference the column "state_crosswalk.code".
2020-02-03 23:33:08,90232 (MainThread):   compiled SQL at target/run/demo_pipeline/staging/stg_state_crosswalk.sql
2020-02-03 23:33:08,90397 (MainThread): 
Done. PASS=4 WARN=0 ERROR=1 SKIP=0 TOTAL=5
2020-02-03 23:33:08,90701 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afdac50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b168310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afd6390>]}
2020-02-03 23:33:08,244035 (MainThread): Flushing usage events
2020-02-03 23:33:25,992601 (MainThread): Running with dbt=0.15.1
2020-02-03 23:33:26,21419 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:33:26,54084 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:33:26,54565 (MainThread): Tracking: tracking
2020-02-03 23:33:26,70972 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126483550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f10dfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1260fb150>]}
2020-02-03 23:33:26,342706 (MainThread): Partial parsing not enabled
2020-02-03 23:33:26,344649 (MainThread): Parsing macros/core.sql
2020-02-03 23:33:26,349051 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:33:26,354622 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:33:26,356179 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:33:26,368481 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:33:26,381854 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:33:26,394828 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:33:26,396354 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:33:26,400747 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:33:26,405634 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:33:26,409741 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:33:26,414050 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:33:26,417433 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:33:26,418140 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:33:26,418960 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:33:26,420184 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:33:26,421618 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:33:26,428294 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:33:26,430139 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:33:26,450772 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:33:26,451765 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:33:26,452494 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:33:26,453313 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:33:26,454917 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:33:26,456177 (MainThread): Parsing macros/relations.sql
2020-02-03 23:33:26,457318 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:33:26,464645 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:33:26,479814 (MainThread): Partial parsing not enabled
2020-02-03 23:33:26,491166 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:26,491329 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,505236 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:26,505382 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,509693 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:26,509787 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,514856 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,514988 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,518805 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:26,518898 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,551135 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:33:26,551294 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,560420 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:33:26,560570 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,568682 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:33:26,568790 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,574657 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:33:26,574765 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,626746 (MainThread): Found 5 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:33:26,632079 (MainThread): 
2020-02-03 23:33:26,632560 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:33:26,632797 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:33:26,707377 (MainThread): Using postgres connection "master".
2020-02-03 23:33:26,707531 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:33:26,712016 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:33:26,753794 (MainThread): Using postgres connection "master".
2020-02-03 23:33:26,754015 (MainThread): On master: BEGIN
2020-02-03 23:33:26,755121 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:26,755226 (MainThread): Using postgres connection "master".
2020-02-03 23:33:26,755294 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:33:26,757390 (MainThread): SQL status: SELECT 8 in 0.00 seconds
2020-02-03 23:33:26,796531 (MainThread): Using postgres connection "master".
2020-02-03 23:33:26,796684 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:33:26,805379 (MainThread): SQL status: SELECT 3 in 0.01 seconds
2020-02-03 23:33:26,809137 (MainThread): On master: ROLLBACK
2020-02-03 23:33:26,809345 (MainThread): Using postgres connection "master".
2020-02-03 23:33:26,809428 (MainThread): On master: BEGIN
2020-02-03 23:33:26,809697 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:26,809811 (MainThread): On master: COMMIT
2020-02-03 23:33:26,809898 (MainThread): Using postgres connection "master".
2020-02-03 23:33:26,809967 (MainThread): On master: COMMIT
2020-02-03 23:33:26,810127 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:26,810425 (MainThread): 18:33:26 | Concurrency: 1 threads (target='dev')
2020-02-03 23:33:26,810593 (MainThread): 18:33:26 | 
2020-02-03 23:33:26,812033 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:33:26,812191 (Thread-1): 18:33:26 | 1 of 5 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:33:26,812454 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,812535 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:33:26,812624 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:33:26,823844 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:33:26,824212 (Thread-1): finished collecting timing info
2020-02-03 23:33:26,843830 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,844121 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:33:26,847862 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:33:26,850151 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,850325 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:33:26,850610 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:33:26,862976 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:33:26,863415 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,863515 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:33:26,863814 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:26,863895 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,863959 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:33:26,869767 (Thread-1): SQL status: SELECT 2 in 0.01 seconds
2020-02-03 23:33:26,874299 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,874413 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:33:26,874765 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:26,876576 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,876664 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:33:26,877074 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:26,877949 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:33:26,878074 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,878152 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:33:26,878705 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:26,880239 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:33:26,880328 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:33:26,881814 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:33:26,883728 (Thread-1): finished collecting timing info
2020-02-03 23:33:26,884220 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43d6e987-53f4-4746-afbe-7f156488c2e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1276d6290>]}
2020-02-03 23:33:27,15255 (Thread-1): 18:33:27 | 1 of 5 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.07s]
2020-02-03 23:33:27,15585 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:33:27,15783 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:33:27,15995 (Thread-1): 18:33:27 | 2 of 5 START view model public.stg_npi............................... [RUN]
2020-02-03 23:33:27,16717 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,16864 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:33:27,16997 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:33:27,24524 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:33:27,24975 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,45732 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,45898 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:33:27,46218 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,48256 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,48352 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:33:27,48552 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,49849 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:33:27,50218 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,50315 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:33:27,50468 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:27,50556 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,50630 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:33:27,51463 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:27,54692 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,54786 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-03 23:33:27,55125 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:27,58023 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,58128 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:33:27,58491 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:27,59174 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:33:27,59260 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,59330 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:33:27,60814 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:27,62723 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:33:27,62840 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:33:27,63726 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,66044 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,66662 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43d6e987-53f4-4746-afbe-7f156488c2e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1276d96d0>]}
2020-02-03 23:33:27,200550 (Thread-1): 18:33:27 | 2 of 5 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.05s]
2020-02-03 23:33:27,200824 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:33:27,201019 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:33:27,201445 (Thread-1): 18:33:27 | 3 of 5 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:33:27,202145 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,202388 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:33:27,202581 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:33:27,210144 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:33:27,210656 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,217582 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,217729 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:33:27,218075 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,220401 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,220516 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:33:27,220905 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,222394 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:33:27,222850 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,223000 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:33:27,223229 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:27,223363 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,223454 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	Code as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:33:27,224117 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:27,226420 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,226525 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-03 23:33:27,226843 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:27,227633 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:33:27,227748 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,227832 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:33:27,228308 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:27,229903 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:33:27,230008 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:33:27,230270 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,232617 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,233206 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43d6e987-53f4-4746-afbe-7f156488c2e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12769eb50>]}
2020-02-03 23:33:27,357905 (Thread-1): 18:33:27 | 3 of 5 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.03s]
2020-02-03 23:33:27,358241 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:33:27,358495 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:33:27,358764 (Thread-1): 18:33:27 | 4 of 5 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:33:27,359274 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,359416 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:33:27,359548 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:33:27,367103 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:33:27,367512 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,376264 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,376439 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:33:27,376802 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,379669 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,379852 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:33:27,380159 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,381718 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:33:27,382215 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,382331 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:33:27,382575 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:27,382674 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,382754 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:33:27,383427 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:27,387418 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,387563 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-03 23:33:27,388008 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:27,390273 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,390459 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:33:27,390859 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:27,391684 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:33:27,391782 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,391874 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:33:27,392294 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:27,394050 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:33:27,394193 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:33:27,395035 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,397480 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,398119 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43d6e987-53f4-4746-afbe-7f156488c2e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127871ed0>]}
2020-02-03 23:33:27,542847 (Thread-1): 18:33:27 | 4 of 5 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:33:27,543209 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:33:27,543438 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:33:27,543647 (Thread-1): 18:33:27 | 5 of 5 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:33:27,544188 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,544334 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:33:27,544465 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:33:27,552795 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:33:27,553250 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,560442 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,560603 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:33:27,560948 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,563794 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,563991 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:33:27,564388 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,567841 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:33:27,568362 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,568481 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:33:27,568747 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:27,568858 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,568948 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:33:27,569722 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:33:27,572234 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,572364 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:33:27,572984 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:33:27,574004 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:33:27,574132 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,574227 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:33:27,574712 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:27,576543 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:33:27,576654 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:33:27,576915 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:33:27,579460 (Thread-1): finished collecting timing info
2020-02-03 23:33:27,580278 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '43d6e987-53f4-4746-afbe-7f156488c2e4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1277e5950>]}
2020-02-03 23:33:27,719727 (Thread-1): 18:33:27 | 5 of 5 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-03 23:33:27,720061 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:33:27,732779 (MainThread): Using postgres connection "master".
2020-02-03 23:33:27,733028 (MainThread): On master: BEGIN
2020-02-03 23:33:27,733403 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:33:27,733578 (MainThread): On master: COMMIT
2020-02-03 23:33:27,733707 (MainThread): Using postgres connection "master".
2020-02-03 23:33:27,733819 (MainThread): On master: COMMIT
2020-02-03 23:33:27,734124 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:33:27,734528 (MainThread): 18:33:27 | 
2020-02-03 23:33:27,734707 (MainThread): 18:33:27 | Finished running 1 table model, 4 view models in 1.10s.
2020-02-03 23:33:27,734857 (MainThread): Connection 'master' was left open.
2020-02-03 23:33:27,734971 (MainThread): On master: Close
2020-02-03 23:33:27,735110 (MainThread): Connection 'model.demo_pipeline.my_second_dbt_model' was left open.
2020-02-03 23:33:27,735217 (MainThread): On model.demo_pipeline.my_second_dbt_model: Close
2020-02-03 23:33:27,750512 (MainThread): 
2020-02-03 23:33:27,750779 (MainThread): Completed successfully
2020-02-03 23:33:27,750929 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-02-03 23:33:27,751187 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127a96290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127a91510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127a91d10>]}
2020-02-03 23:33:27,869830 (MainThread): Flushing usage events
2020-02-03 23:44:29,277994 (MainThread): Running with dbt=0.15.1
2020-02-03 23:44:29,317984 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:44:29,356263 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:44:29,357414 (MainThread): Tracking: tracking
2020-02-03 23:44:29,373641 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b78150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b78d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125b78ad0>]}
2020-02-03 23:44:29,629068 (MainThread): Partial parsing not enabled
2020-02-03 23:44:29,633481 (MainThread): Parsing macros/core.sql
2020-02-03 23:44:29,637698 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:44:29,643932 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:44:29,646262 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:44:29,658612 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:44:29,671473 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:44:29,690510 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:44:29,694177 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:44:29,702133 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:44:29,708526 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:44:29,713370 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:44:29,717758 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:44:29,721099 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:44:29,721995 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:44:29,723094 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:44:29,724619 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:44:29,726208 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:44:29,731529 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:44:29,733130 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:44:29,750792 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:44:29,752551 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:44:29,753806 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:44:29,755208 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:44:29,758159 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:44:29,760664 (MainThread): Parsing macros/relations.sql
2020-02-03 23:44:29,762677 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:44:29,770519 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:44:29,785579 (MainThread): Partial parsing not enabled
2020-02-03 23:44:29,798707 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:44:29,798875 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,815717 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:29,815891 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,821703 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:29,821885 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,827716 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:29,827813 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,833268 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:29,833437 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,838471 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:29,838649 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,873257 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:44:29,873398 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,882033 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:44:29,882145 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,889719 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:44:29,889811 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,895123 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:44:29,895201 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:29,946454 (MainThread): Found 6 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:44:29,952609 (MainThread): 
2020-02-03 23:44:29,953030 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:44:29,953136 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:44:30,27888 (MainThread): Using postgres connection "master".
2020-02-03 23:44:30,28040 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:44:30,38652 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-03 23:44:30,80208 (MainThread): Using postgres connection "master".
2020-02-03 23:44:30,80377 (MainThread): On master: BEGIN
2020-02-03 23:44:30,81533 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,81799 (MainThread): Using postgres connection "master".
2020-02-03 23:44:30,81882 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:44:30,83784 (MainThread): SQL status: SELECT 9 in 0.00 seconds
2020-02-03 23:44:30,124362 (MainThread): Using postgres connection "master".
2020-02-03 23:44:30,124515 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:44:30,135063 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-03 23:44:30,139795 (MainThread): On master: ROLLBACK
2020-02-03 23:44:30,140071 (MainThread): Using postgres connection "master".
2020-02-03 23:44:30,140157 (MainThread): On master: BEGIN
2020-02-03 23:44:30,140489 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,140595 (MainThread): On master: COMMIT
2020-02-03 23:44:30,140676 (MainThread): Using postgres connection "master".
2020-02-03 23:44:30,140745 (MainThread): On master: COMMIT
2020-02-03 23:44:30,140892 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:30,141159 (MainThread): 18:44:30 | Concurrency: 1 threads (target='dev')
2020-02-03 23:44:30,141267 (MainThread): 18:44:30 | 
2020-02-03 23:44:30,143719 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:44:30,143927 (Thread-1): 18:44:30 | 1 of 6 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:44:30,144200 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,144278 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:44:30,144363 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:44:30,155282 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:44:30,159738 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,176280 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,176430 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:44:30,179430 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:44:30,181858 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,181955 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:44:30,182239 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:44:30,195727 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:44:30,197280 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,197437 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:44:30,197790 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,197919 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,198002 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:44:30,204560 (Thread-1): SQL status: SELECT 2 in 0.01 seconds
2020-02-03 23:44:30,208389 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,208500 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:44:30,208840 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,210851 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,210943 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:44:30,212075 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,213024 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:44:30,213142 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,213215 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:44:30,214800 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:30,216615 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:44:30,216765 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:44:30,219683 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:44:30,221991 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,222580 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf590f05-92ee-40a6-b752-dd7110cbc6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126dd8690>]}
2020-02-03 23:44:30,370969 (Thread-1): 18:44:30 | 1 of 6 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.08s]
2020-02-03 23:44:30,371310 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:44:30,371583 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:44:30,372135 (Thread-1): 18:44:30 | 2 of 6 START view model public.stg_npi............................... [RUN]
2020-02-03 23:44:30,372971 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,373181 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:44:30,373354 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:44:30,381187 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:44:30,382788 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,403219 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,403387 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:44:30,403709 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,405767 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,405868 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:44:30,406171 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,407485 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:44:30,407871 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,407969 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:44:30,408170 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,408260 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,408334 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:44:30,409229 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:44:30,413009 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,413102 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-03 23:44:30,413447 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,415333 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,415430 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:44:30,415709 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,416419 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:44:30,416511 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,416587 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:44:30,417013 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:30,418877 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:44:30,419008 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:44:30,419783 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,422110 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,422754 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf590f05-92ee-40a6-b752-dd7110cbc6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f14210>]}
2020-02-03 23:44:30,561135 (Thread-1): 18:44:30 | 2 of 6 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.05s]
2020-02-03 23:44:30,561474 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:44:30,561734 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:44:30,562020 (Thread-1): 18:44:30 | 3 of 6 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:44:30,562540 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,562682 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:44:30,562814 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:44:30,570315 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:44:30,570790 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,577347 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,577461 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:44:30,577797 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,579968 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,580075 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:44:30,580417 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,582099 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:44:30,582652 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,582762 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:44:30,582977 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,583077 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,583159 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	Code as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:44:30,587710 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:44:30,591373 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,591494 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-03 23:44:30,591838 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,594052 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,594171 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-03 23:44:30,594550 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,595443 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:44:30,595535 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,595610 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:44:30,596149 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:30,598557 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:44:30,598652 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:44:30,599321 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,601367 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,601937 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf590f05-92ee-40a6-b752-dd7110cbc6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126cedd50>]}
2020-02-03 23:44:30,743878 (Thread-1): 18:44:30 | 3 of 6 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-03 23:44:30,744210 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:44:30,744456 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:44:30,744716 (Thread-1): 18:44:30 | 4 of 6 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:44:30,745328 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,745468 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:44:30,745595 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:44:30,753398 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:44:30,753890 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,760642 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,760760 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:44:30,761134 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,763473 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,763602 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:44:30,763936 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,765757 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:44:30,766310 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,766459 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:44:30,766709 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,766829 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,766919 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:44:30,767592 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:44:30,771508 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,771656 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-03 23:44:30,772071 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,774299 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,774400 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:44:30,774702 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,775561 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:44:30,775661 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,775783 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:44:30,776212 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:30,777817 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:44:30,777916 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:44:30,778675 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,780801 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,781348 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf590f05-92ee-40a6-b752-dd7110cbc6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ebfd90>]}
2020-02-03 23:44:30,946701 (Thread-1): 18:44:30 | 4 of 6 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:44:30,947036 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:44:30,947283 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:44:30,947546 (Thread-1): 18:44:30 | 5 of 6 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:44:30,948121 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,948449 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:44:30,948779 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:44:30,958244 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:44:30,958760 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,967006 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,967233 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:44:30,967591 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,970221 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,970417 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:44:30,970749 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,972493 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:44:30,973017 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,973140 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:44:30,973359 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:30,973456 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,973533 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:44:30,974348 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:44:30,977909 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,978067 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:44:30,978465 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:44:30,979307 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:44:30,979408 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,979488 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:44:30,979932 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:30,981846 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:44:30,982010 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:44:30,982325 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:30,984953 (Thread-1): finished collecting timing info
2020-02-03 23:44:30,985726 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf590f05-92ee-40a6-b752-dd7110cbc6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f12b10>]}
2020-02-03 23:44:31,132874 (Thread-1): 18:44:31 | 5 of 6 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-03 23:44:31,133204 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:44:31,133471 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:44:31,133753 (Thread-1): 18:44:31 | 6 of 6 START view model public.npi_with_crosswalks................... [RUN]
2020-02-03 23:44:31,134277 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:44:31,134408 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-03 23:44:31,134534 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:44:31,144654 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:44:31,145128 (Thread-1): finished collecting timing info
2020-02-03 23:44:31,152056 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:44:31,152237 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-03 23:44:31,152585 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:31,154931 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:44:31,155036 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:44:31,155257 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:44:31,156745 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:44:31,157840 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:44:31,157987 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-03 23:44:31,158228 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:31,158328 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:44:31,158406 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-03 23:44:31,158954 (Thread-1): Postgres error: column "state" specified more than once

2020-02-03 23:44:31,159071 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: ROLLBACK
2020-02-03 23:44:31,159308 (Thread-1): finished collecting timing info
2020-02-03 23:44:31,159747 (Thread-1): Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
  column "state" specified more than once
  compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: column "state" specified more than once


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
  column "state" specified more than once
  compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
2020-02-03 23:44:31,172718 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bf590f05-92ee-40a6-b752-dd7110cbc6d2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126ecf890>]}
2020-02-03 23:44:31,293119 (Thread-1): 18:44:31 | 6 of 6 ERROR creating view model public.npi_with_crosswalks.......... [ERROR in 0.04s]
2020-02-03 23:44:31,293461 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:44:31,381780 (MainThread): Using postgres connection "master".
2020-02-03 23:44:31,382163 (MainThread): On master: BEGIN
2020-02-03 23:44:31,382854 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:44:31,383207 (MainThread): On master: COMMIT
2020-02-03 23:44:31,383458 (MainThread): Using postgres connection "master".
2020-02-03 23:44:31,383677 (MainThread): On master: COMMIT
2020-02-03 23:44:31,384256 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:44:31,385004 (MainThread): 18:44:31 | 
2020-02-03 23:44:31,385351 (MainThread): 18:44:31 | Finished running 1 table model, 5 view models in 1.43s.
2020-02-03 23:44:31,385652 (MainThread): Connection 'master' was left open.
2020-02-03 23:44:31,385877 (MainThread): On master: Close
2020-02-03 23:44:31,386154 (MainThread): Connection 'model.demo_pipeline.npi_with_crosswalks' was left open.
2020-02-03 23:44:31,386294 (MainThread): On model.demo_pipeline.npi_with_crosswalks: Close
2020-02-03 23:44:31,404201 (MainThread): 
2020-02-03 23:44:31,404483 (MainThread): Completed with 1 error and 0 warnings:
2020-02-03 23:44:31,404639 (MainThread): 
2020-02-03 23:44:31,404757 (MainThread): Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
2020-02-03 23:44:31,404862 (MainThread):   column "state" specified more than once
2020-02-03 23:44:31,404956 (MainThread):   compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
2020-02-03 23:44:31,405061 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2020-02-03 23:44:31,405271 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271922d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126dccd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f0e190>]}
2020-02-03 23:44:31,548003 (MainThread): Flushing usage events
2020-02-03 23:45:00,763171 (MainThread): Running with dbt=0.15.1
2020-02-03 23:45:00,807085 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:45:00,845582 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:45:00,846456 (MainThread): Tracking: tracking
2020-02-03 23:45:00,862336 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125572e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1255727d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125572b50>]}
2020-02-03 23:45:01,46558 (MainThread): Partial parsing not enabled
2020-02-03 23:45:01,50782 (MainThread): Parsing macros/core.sql
2020-02-03 23:45:01,56291 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:45:01,62962 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:45:01,65365 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:45:01,77926 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:45:01,90941 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:45:01,102751 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:45:01,104297 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:45:01,108925 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:45:01,113619 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:45:01,117897 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:45:01,121782 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:45:01,125216 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:45:01,126119 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:45:01,127229 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:45:01,128809 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:45:01,132036 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:45:01,139100 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:45:01,141059 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:45:01,165793 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:45:01,166860 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:45:01,167802 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:45:01,168884 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:45:01,170706 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:45:01,172093 (MainThread): Parsing macros/relations.sql
2020-02-03 23:45:01,173446 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:45:01,180406 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:45:01,193967 (MainThread): Partial parsing not enabled
2020-02-03 23:45:01,203841 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:01,203936 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,218901 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,219061 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,228068 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,228339 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,237355 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:01,237558 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,244221 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,244403 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,249456 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:01,249556 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,281143 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:45:01,281278 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,290106 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:45:01,290221 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,298023 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:45:01,298122 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,303640 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:45:01,303723 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,354778 (MainThread): Found 6 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:45:01,360940 (MainThread): 
2020-02-03 23:45:01,361295 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:45:01,361384 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:01,434487 (MainThread): Using postgres connection "master".
2020-02-03 23:45:01,434639 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:45:01,444697 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-03 23:45:01,488163 (MainThread): Using postgres connection "master".
2020-02-03 23:45:01,488333 (MainThread): On master: BEGIN
2020-02-03 23:45:01,489237 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:01,489423 (MainThread): Using postgres connection "master".
2020-02-03 23:45:01,489511 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:45:01,491626 (MainThread): SQL status: SELECT 9 in 0.00 seconds
2020-02-03 23:45:01,534205 (MainThread): Using postgres connection "master".
2020-02-03 23:45:01,534392 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:45:01,544854 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-03 23:45:01,550118 (MainThread): On master: ROLLBACK
2020-02-03 23:45:01,550474 (MainThread): Using postgres connection "master".
2020-02-03 23:45:01,550658 (MainThread): On master: BEGIN
2020-02-03 23:45:01,551005 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:01,551134 (MainThread): On master: COMMIT
2020-02-03 23:45:01,551230 (MainThread): Using postgres connection "master".
2020-02-03 23:45:01,551312 (MainThread): On master: COMMIT
2020-02-03 23:45:01,551478 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:01,551776 (MainThread): 18:45:01 | Concurrency: 1 threads (target='dev')
2020-02-03 23:45:01,551907 (MainThread): 18:45:01 | 
2020-02-03 23:45:01,554657 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:45:01,554918 (Thread-1): 18:45:01 | 1 of 6 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:45:01,555273 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,555370 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:45:01,555472 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:45:01,567545 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:45:01,567914 (Thread-1): finished collecting timing info
2020-02-03 23:45:01,583281 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,583428 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:45:01,587386 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:45:01,590342 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,590508 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:45:01,590859 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:45:01,602788 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:45:01,603230 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,603314 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:45:01,603588 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:01,603668 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,603733 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:45:01,605484 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 23:45:01,608582 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,608692 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:45:01,608995 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:01,610902 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,610985 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:45:01,611316 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:01,611938 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:45:01,612022 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,612090 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:45:01,613356 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:01,615054 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:01,615185 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:45:01,617007 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:45:01,618937 (Thread-1): finished collecting timing info
2020-02-03 23:45:01,619437 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68ae6a41-0942-41a1-a1d1-e37c428c5ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1267d4a50>]}
2020-02-03 23:45:01,740378 (Thread-1): 18:45:01 | 1 of 6 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.06s]
2020-02-03 23:45:01,740733 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:45:01,741004 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:45:01,741273 (Thread-1): 18:45:01 | 2 of 6 START view model public.stg_npi............................... [RUN]
2020-02-03 23:45:01,741739 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,741876 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:45:01,742007 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:45:01,749719 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:45:01,750387 (Thread-1): finished collecting timing info
2020-02-03 23:45:01,770062 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,770253 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:45:01,770611 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:01,772674 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,772769 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:45:01,773112 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:01,774390 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:45:01,774780 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,774879 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:45:01,775094 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:01,775198 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,775280 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:45:01,776249 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:01,780133 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,780242 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-03 23:45:01,780649 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:01,782554 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,782643 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:45:01,782903 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:01,783575 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:45:01,783665 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,783752 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:45:01,784162 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:01,785554 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:01,785690 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:45:01,786315 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:01,788565 (Thread-1): finished collecting timing info
2020-02-03 23:45:01,789250 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68ae6a41-0942-41a1-a1d1-e37c428c5ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126936410>]}
2020-02-03 23:45:01,931700 (Thread-1): 18:45:01 | 2 of 6 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.05s]
2020-02-03 23:45:01,932049 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:45:01,932453 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:45:01,932980 (Thread-1): 18:45:01 | 3 of 6 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:45:01,933844 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,934002 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:45:01,934145 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:45:01,942251 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:45:01,942766 (Thread-1): finished collecting timing info
2020-02-03 23:45:01,953418 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,953696 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:45:01,954065 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:01,956565 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,956685 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:45:01,956908 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:01,958456 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:45:01,958909 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,959036 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:45:01,959233 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:01,959365 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,959464 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	Code as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:45:01,960097 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:01,963850 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,963981 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-03 23:45:01,964447 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:01,966895 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,967021 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-03 23:45:01,967408 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:01,968331 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:45:01,968439 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,968527 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:45:01,968998 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:01,971653 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:01,971767 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:45:01,972501 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:01,974746 (Thread-1): finished collecting timing info
2020-02-03 23:45:01,975357 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68ae6a41-0942-41a1-a1d1-e37c428c5ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1267ca350>]}
2020-02-03 23:45:02,127269 (Thread-1): 18:45:02 | 3 of 6 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-03 23:45:02,127619 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:45:02,127871 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:45:02,128124 (Thread-1): 18:45:02 | 4 of 6 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:45:02,128602 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,128729 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:45:02,128857 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:45:02,137184 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:45:02,137812 (Thread-1): finished collecting timing info
2020-02-03 23:45:02,145541 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,145745 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:45:02,146188 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,149025 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,149207 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:45:02,149553 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,151345 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:45:02,151961 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,152097 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:45:02,152407 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:02,152545 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,152648 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:45:02,153573 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:02,158568 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,158734 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-03 23:45:02,159177 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:02,161687 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,161928 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:45:02,163470 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:02,164714 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:45:02,164844 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,164946 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:45:02,165418 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:02,167205 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:02,167318 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:45:02,168060 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,170539 (Thread-1): finished collecting timing info
2020-02-03 23:45:02,171174 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68ae6a41-0942-41a1-a1d1-e37c428c5ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1268cdf90>]}
2020-02-03 23:45:02,332423 (Thread-1): 18:45:02 | 4 of 6 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:45:02,332768 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:45:02,333025 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:45:02,333285 (Thread-1): 18:45:02 | 5 of 6 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:45:02,333775 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,333909 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:45:02,334040 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:45:02,342297 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:45:02,342869 (Thread-1): finished collecting timing info
2020-02-03 23:45:02,350813 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,350966 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:45:02,351324 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,353714 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,353883 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:45:02,354224 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,356310 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:45:02,356855 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,357046 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:45:02,357449 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:02,357625 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,357767 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:45:02,358747 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:02,362727 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,363002 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:45:02,363781 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:02,365285 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:45:02,365494 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,365636 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:45:02,366133 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:02,368365 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:02,368538 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:45:02,368885 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,372552 (Thread-1): finished collecting timing info
2020-02-03 23:45:02,373197 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68ae6a41-0942-41a1-a1d1-e37c428c5ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126915ed0>]}
2020-02-03 23:45:02,543297 (Thread-1): 18:45:02 | 5 of 6 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-03 23:45:02,543648 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:45:02,543904 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:45:02,544676 (Thread-1): 18:45:02 | 6 of 6 START view model public.npi_with_crosswalks................... [RUN]
2020-02-03 23:45:02,545214 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:02,545352 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-03 23:45:02,545483 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:45:02,555790 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:45:02,556282 (Thread-1): finished collecting timing info
2020-02-03 23:45:02,563177 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:02,563336 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-03 23:45:02,563730 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,566755 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:02,567035 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:45:02,567438 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:02,570220 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:45:02,570793 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:02,570916 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-03 23:45:02,571180 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:02,571316 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:02,571414 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-03 23:45:02,572040 (Thread-1): Postgres error: column "state" specified more than once

2020-02-03 23:45:02,572178 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: ROLLBACK
2020-02-03 23:45:02,572433 (Thread-1): finished collecting timing info
2020-02-03 23:45:02,572951 (Thread-1): Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
  column "state" specified more than once
  compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: column "state" specified more than once


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
  column "state" specified more than once
  compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
2020-02-03 23:45:02,580861 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '68ae6a41-0942-41a1-a1d1-e37c428c5ea8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1268c7e10>]}
2020-02-03 23:45:02,722341 (Thread-1): 18:45:02 | 6 of 6 ERROR creating view model public.npi_with_crosswalks.......... [ERROR in 0.04s]
2020-02-03 23:45:02,722681 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:45:02,791475 (MainThread): Using postgres connection "master".
2020-02-03 23:45:02,791873 (MainThread): On master: BEGIN
2020-02-03 23:45:02,792585 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:02,792935 (MainThread): On master: COMMIT
2020-02-03 23:45:02,793208 (MainThread): Using postgres connection "master".
2020-02-03 23:45:02,793454 (MainThread): On master: COMMIT
2020-02-03 23:45:02,794074 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:02,794878 (MainThread): 18:45:02 | 
2020-02-03 23:45:02,795242 (MainThread): 18:45:02 | Finished running 1 table model, 5 view models in 1.43s.
2020-02-03 23:45:02,795556 (MainThread): Connection 'master' was left open.
2020-02-03 23:45:02,795829 (MainThread): On master: Close
2020-02-03 23:45:02,796172 (MainThread): Connection 'model.demo_pipeline.npi_with_crosswalks' was left open.
2020-02-03 23:45:02,796409 (MainThread): On model.demo_pipeline.npi_with_crosswalks: Close
2020-02-03 23:45:02,814336 (MainThread): 
2020-02-03 23:45:02,814556 (MainThread): Completed with 1 error and 0 warnings:
2020-02-03 23:45:02,814684 (MainThread): 
2020-02-03 23:45:02,814802 (MainThread): Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
2020-02-03 23:45:02,814907 (MainThread):   column "state" specified more than once
2020-02-03 23:45:02,815001 (MainThread):   compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
2020-02-03 23:45:02,815105 (MainThread): 
Done. PASS=5 WARN=0 ERROR=1 SKIP=0 TOTAL=6
2020-02-03 23:45:02,815304 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126758e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1268ceed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1267ecd90>]}
2020-02-03 23:45:02,931063 (MainThread): Flushing usage events
2020-02-03 23:45:26,799317 (MainThread): Running with dbt=0.15.1
2020-02-03 23:45:26,828134 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:45:26,859199 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:45:26,859663 (MainThread): Tracking: tracking
2020-02-03 23:45:26,872936 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ca0310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ca0750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ca0990>]}
2020-02-03 23:45:27,123240 (MainThread): Partial parsing not enabled
2020-02-03 23:45:27,124897 (MainThread): Parsing macros/core.sql
2020-02-03 23:45:27,128041 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:45:27,132862 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:45:27,134101 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:45:27,145288 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:45:27,160043 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:45:27,171664 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:45:27,173006 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:45:27,177411 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:45:27,181992 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:45:27,185983 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:45:27,189580 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:45:27,192658 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:45:27,193286 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:45:27,194018 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:45:27,195119 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:45:27,196408 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:45:27,201336 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:45:27,202691 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:45:27,219875 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:45:27,220711 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:45:27,221390 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:45:27,222153 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:45:27,223645 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:45:27,224769 (MainThread): Parsing macros/relations.sql
2020-02-03 23:45:27,225844 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:45:27,232164 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:45:27,246128 (MainThread): Partial parsing not enabled
2020-02-03 23:45:27,257287 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:27,257436 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,271809 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,271909 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,275590 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:27,275665 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,279560 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:27,279635 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,283495 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,283574 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,287108 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:27,287187 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,316176 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:45:27,316346 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,325310 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:45:27,325450 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,332649 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:45:27,332749 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,338622 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:45:27,338716 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,389111 (MainThread): Found 6 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:45:27,395594 (MainThread): 
2020-02-03 23:45:27,395937 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:45:27,396023 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:45:27,466631 (MainThread): Using postgres connection "master".
2020-02-03 23:45:27,466788 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:45:27,471530 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-03 23:45:27,512390 (MainThread): Using postgres connection "master".
2020-02-03 23:45:27,512551 (MainThread): On master: BEGIN
2020-02-03 23:45:27,512887 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:27,512961 (MainThread): Using postgres connection "master".
2020-02-03 23:45:27,513019 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:45:27,514944 (MainThread): SQL status: SELECT 9 in 0.00 seconds
2020-02-03 23:45:27,555192 (MainThread): Using postgres connection "master".
2020-02-03 23:45:27,555347 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:45:27,563654 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-03 23:45:27,568426 (MainThread): On master: ROLLBACK
2020-02-03 23:45:27,568680 (MainThread): Using postgres connection "master".
2020-02-03 23:45:27,568769 (MainThread): On master: BEGIN
2020-02-03 23:45:27,568984 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:27,569074 (MainThread): On master: COMMIT
2020-02-03 23:45:27,569149 (MainThread): Using postgres connection "master".
2020-02-03 23:45:27,569219 (MainThread): On master: COMMIT
2020-02-03 23:45:27,569348 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:27,569592 (MainThread): 18:45:27 | Concurrency: 1 threads (target='dev')
2020-02-03 23:45:27,569702 (MainThread): 18:45:27 | 
2020-02-03 23:45:27,571054 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:45:27,571208 (Thread-1): 18:45:27 | 1 of 6 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:45:27,571452 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,571536 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:45:27,571630 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:45:27,581796 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:45:27,582117 (Thread-1): finished collecting timing info
2020-02-03 23:45:27,597517 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,597747 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:45:27,601065 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:45:27,603637 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,603740 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:45:27,603986 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:45:27,616046 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:45:27,616678 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,616771 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:45:27,617198 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:27,617307 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,617390 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:45:27,619236 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 23:45:27,622772 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,622887 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:45:27,623240 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:27,625208 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,625299 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:45:27,625598 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:27,626273 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:45:27,626363 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,626437 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:45:27,626811 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:27,628159 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:45:27,628251 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:45:27,629965 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:45:27,632257 (Thread-1): finished collecting timing info
2020-02-03 23:45:27,632826 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84e5be17-1790-466c-b4e0-44aa99f0c0ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e43d90>]}
2020-02-03 23:45:27,782813 (Thread-1): 18:45:27 | 1 of 6 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.06s]
2020-02-03 23:45:27,783149 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:45:27,783415 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:45:27,783680 (Thread-1): 18:45:27 | 2 of 6 START view model public.stg_npi............................... [RUN]
2020-02-03 23:45:27,784422 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,784574 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:45:27,784709 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:45:27,792403 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:45:27,792879 (Thread-1): finished collecting timing info
2020-02-03 23:45:27,813416 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,813602 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:45:27,813994 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:27,816446 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,816595 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:45:27,816923 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:27,818367 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:45:27,818774 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,818876 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:45:27,819077 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:27,819186 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,819269 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:45:27,820285 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:27,824392 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,824492 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-03 23:45:27,824827 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:27,826700 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,826791 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:45:27,827055 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:27,827778 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:45:27,827871 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,827948 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:45:27,828454 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:27,831306 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:45:27,831418 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:45:27,832214 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:27,834908 (Thread-1): finished collecting timing info
2020-02-03 23:45:27,835491 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84e5be17-1790-466c-b4e0-44aa99f0c0ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122019450>]}
2020-02-03 23:45:27,970785 (Thread-1): 18:45:27 | 2 of 6 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.05s]
2020-02-03 23:45:27,971128 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:45:27,971442 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:45:27,971787 (Thread-1): 18:45:27 | 3 of 6 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:45:27,972864 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:27,973115 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:45:27,973305 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:45:27,981191 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:45:27,981710 (Thread-1): finished collecting timing info
2020-02-03 23:45:27,988847 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:27,989035 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:45:27,989481 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:27,992765 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:27,992970 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:45:27,993346 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:27,995174 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:45:27,995682 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:27,995805 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:45:27,996058 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:27,996172 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:27,996266 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	Code as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:45:27,996981 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:28,1156 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:28,1333 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-03 23:45:28,1858 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:28,4683 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:28,4849 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-03 23:45:28,5401 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:28,6421 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:45:28,6591 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:28,6699 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:45:28,7226 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:28,9853 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:45:28,9958 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:45:28,10612 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,13149 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,13855 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84e5be17-1790-466c-b4e0-44aa99f0c0ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121fddc50>]}
2020-02-03 23:45:28,157526 (Thread-1): 18:45:28 | 3 of 6 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-03 23:45:28,157786 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:45:28,158087 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:45:28,158418 (Thread-1): 18:45:28 | 4 of 6 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:45:28,158870 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,159017 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:45:28,159147 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:45:28,166428 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:45:28,166932 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,173747 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,173867 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:45:28,174244 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,176542 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,176672 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:45:28,177309 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,180050 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:45:28,180581 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,180710 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:45:28,180965 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:28,181076 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,181167 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:45:28,181883 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:28,186127 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,186311 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-03 23:45:28,186862 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:28,189253 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,189374 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:45:28,189777 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:28,190711 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:45:28,190819 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,190908 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:45:28,191309 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:28,192878 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:45:28,192980 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:45:28,193690 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,196068 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,196700 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84e5be17-1790-466c-b4e0-44aa99f0c0ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122032e90>]}
2020-02-03 23:45:28,323287 (Thread-1): 18:45:28 | 4 of 6 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:45:28,323564 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:45:28,323762 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:45:28,323960 (Thread-1): 18:45:28 | 5 of 6 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:45:28,324602 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,324748 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:45:28,324878 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:45:28,333844 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:45:28,334350 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,342755 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,342945 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:45:28,343295 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,346373 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,346625 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:45:28,347081 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,349079 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:45:28,349726 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,349869 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:45:28,350209 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:28,350373 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,350491 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:45:28,351336 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:28,353913 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,354040 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:45:28,354500 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:28,355461 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:45:28,355583 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,355679 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:45:28,356116 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:28,358010 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:45:28,358147 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:45:28,358415 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,360837 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,361453 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84e5be17-1790-466c-b4e0-44aa99f0c0ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220321d0>]}
2020-02-03 23:45:28,481941 (Thread-1): 18:45:28 | 5 of 6 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-03 23:45:28,482272 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:45:28,482527 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:45:28,482789 (Thread-1): 18:45:28 | 6 of 6 START view model public.npi_with_crosswalks................... [RUN]
2020-02-03 23:45:28,483257 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,483384 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-03 23:45:28,483511 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:45:28,493665 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:45:28,495381 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,503167 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,503364 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-03 23:45:28,503716 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,506237 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,506381 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:45:28,506690 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,508405 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:45:28,508928 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,509054 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-03 23:45:28,509287 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:28,509398 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,509501 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_long
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-03 23:45:28,514522 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:45:28,517771 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,517900 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
alter table "demo_db"."public"."npi_with_crosswalks__dbt_tmp" rename to "npi_with_crosswalks"
2020-02-03 23:45:28,518323 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:45:28,519190 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-03 23:45:28,519303 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,519396 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-03 23:45:28,519785 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:28,522377 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:45:28,522496 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:45:28,522711 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:45:28,524887 (Thread-1): finished collecting timing info
2020-02-03 23:45:28,525486 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '84e5be17-1790-466c-b4e0-44aa99f0c0ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222869d0>]}
2020-02-03 23:45:28,648948 (Thread-1): 18:45:28 | 6 of 6 OK created view model public.npi_with_crosswalks.............. [CREATE VIEW in 0.04s]
2020-02-03 23:45:28,649177 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:45:28,698200 (MainThread): Using postgres connection "master".
2020-02-03 23:45:28,698596 (MainThread): On master: BEGIN
2020-02-03 23:45:28,699286 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:45:28,699647 (MainThread): On master: COMMIT
2020-02-03 23:45:28,699913 (MainThread): Using postgres connection "master".
2020-02-03 23:45:28,700150 (MainThread): On master: COMMIT
2020-02-03 23:45:28,700728 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:45:28,701550 (MainThread): 18:45:28 | 
2020-02-03 23:45:28,701913 (MainThread): 18:45:28 | Finished running 1 table model, 5 view models in 1.31s.
2020-02-03 23:45:28,702220 (MainThread): Connection 'master' was left open.
2020-02-03 23:45:28,702454 (MainThread): On master: Close
2020-02-03 23:45:28,702733 (MainThread): Connection 'model.demo_pipeline.npi_with_crosswalks' was left open.
2020-02-03 23:45:28,702954 (MainThread): On model.demo_pipeline.npi_with_crosswalks: Close
2020-02-03 23:45:28,720292 (MainThread): 
2020-02-03 23:45:28,720493 (MainThread): Completed successfully
2020-02-03 23:45:28,720605 (MainThread): 
Done. PASS=6 WARN=0 ERROR=0 SKIP=0 TOTAL=6
2020-02-03 23:45:28,720792 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121ec3a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e05650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121e05510>]}
2020-02-03 23:45:28,844185 (MainThread): Flushing usage events
2020-02-03 23:48:38,700517 (MainThread): Running with dbt=0.15.1
2020-02-03 23:48:38,735517 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:48:38,775617 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:48:38,776464 (MainThread): Tracking: tracking
2020-02-03 23:48:38,792315 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb83790>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb83910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb83410>]}
2020-02-03 23:48:39,90304 (MainThread): Partial parsing not enabled
2020-02-03 23:48:39,98225 (MainThread): Parsing macros/core.sql
2020-02-03 23:48:39,105099 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:48:39,112901 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:48:39,115285 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:48:39,128827 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:48:39,149396 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:48:39,161926 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:48:39,165780 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:48:39,173769 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:48:39,180316 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:48:39,185724 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:48:39,190675 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:48:39,194928 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:48:39,196016 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:48:39,197273 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:48:39,198856 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:48:39,200578 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:48:39,206144 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:48:39,207624 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:48:39,225489 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:48:39,226529 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:48:39,227698 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:48:39,228944 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:48:39,233100 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:48:39,234854 (MainThread): Parsing macros/relations.sql
2020-02-03 23:48:39,236552 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:48:39,243684 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:48:39,258635 (MainThread): Partial parsing not enabled
2020-02-03 23:48:39,276888 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:39,277075 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,292856 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:39,293017 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,300108 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,300272 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,306152 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:39,306320 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,311400 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:39,311536 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,317083 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:39,317247 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,322854 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:39,323001 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,356396 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:48:39,356556 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,365369 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:48:39,365481 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,373799 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:48:39,373894 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,379162 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:48:39,379248 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,434186 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:48:39,439425 (MainThread): 
2020-02-03 23:48:39,439754 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:48:39,439846 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:39,514966 (MainThread): Using postgres connection "master".
2020-02-03 23:48:39,515133 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:48:39,525332 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-03 23:48:39,569353 (MainThread): Using postgres connection "master".
2020-02-03 23:48:39,569521 (MainThread): On master: BEGIN
2020-02-03 23:48:39,570530 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:39,570746 (MainThread): Using postgres connection "master".
2020-02-03 23:48:39,570852 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:48:39,573047 (MainThread): SQL status: SELECT 10 in 0.00 seconds
2020-02-03 23:48:39,616623 (MainThread): Using postgres connection "master".
2020-02-03 23:48:39,616772 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:48:39,629480 (MainThread): SQL status: SELECT 7 in 0.01 seconds
2020-02-03 23:48:39,636773 (MainThread): On master: ROLLBACK
2020-02-03 23:48:39,637061 (MainThread): Using postgres connection "master".
2020-02-03 23:48:39,637156 (MainThread): On master: BEGIN
2020-02-03 23:48:39,637402 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:39,637497 (MainThread): On master: COMMIT
2020-02-03 23:48:39,637573 (MainThread): Using postgres connection "master".
2020-02-03 23:48:39,637636 (MainThread): On master: COMMIT
2020-02-03 23:48:39,637778 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:39,638052 (MainThread): 18:48:39 | Concurrency: 1 threads (target='dev')
2020-02-03 23:48:39,638160 (MainThread): 18:48:39 | 
2020-02-03 23:48:39,641139 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:48:39,641533 (Thread-1): 18:48:39 | 1 of 7 START view model public.stg_npi............................... [RUN]
2020-02-03 23:48:39,641826 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,641903 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:48:39,641989 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:48:39,651859 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:48:39,652283 (Thread-1): finished collecting timing info
2020-02-03 23:48:39,679973 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,680164 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:48:39,684389 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:39,686806 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,686917 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:48:39,687187 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:39,688340 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:48:39,688687 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,688766 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:48:39,688984 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:39,689063 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,689129 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:48:39,694589 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-02-03 23:48:39,698883 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,699033 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-03 23:48:39,699377 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:39,701444 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,701546 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:48:39,701844 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:39,702609 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:48:39,702710 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,702795 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:48:39,703358 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:39,705033 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:39,705140 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:48:39,710194 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:39,713647 (Thread-1): finished collecting timing info
2020-02-03 23:48:39,714391 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ddeb310>]}
2020-02-03 23:48:40,259640 (Thread-1): 18:48:40 | 1 of 7 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.07s]
2020-02-03 23:48:40,259991 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:48:40,260300 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:48:40,260779 (Thread-1): 18:48:40 | 2 of 7 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:48:40,261436 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,261595 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:48:40,261737 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:48:40,271949 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:48:40,272447 (Thread-1): finished collecting timing info
2020-02-03 23:48:40,279806 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,280468 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:48:40,281562 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:40,285380 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,285637 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:48:40,286020 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:40,289026 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:48:40,289561 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,289681 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:48:40,289951 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:40,290081 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,290181 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	Code as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:48:40,294471 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:40,298799 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,298966 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-03 23:48:40,299455 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:40,301906 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,302029 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-03 23:48:40,302402 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:40,303235 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:48:40,303338 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,303423 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:48:40,303891 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:40,305683 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:40,305789 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:48:40,306469 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:40,308712 (Thread-1): finished collecting timing info
2020-02-03 23:48:40,309309 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e1f5d10>]}
2020-02-03 23:48:40,754196 (Thread-1): 18:48:40 | 2 of 7 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.05s]
2020-02-03 23:48:40,754408 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:48:40,754564 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:48:40,755000 (Thread-1): 18:48:40 | 3 of 7 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:48:40,755395 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,755533 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:48:40,755715 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:48:40,762394 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:48:40,762786 (Thread-1): finished collecting timing info
2020-02-03 23:48:40,768291 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,768423 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:48:40,768766 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:40,770592 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,770681 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:48:40,770922 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:40,772106 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:48:40,772437 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,772527 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:48:40,772689 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:40,772813 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,772904 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:48:40,774302 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:40,780363 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,780536 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-03 23:48:40,780986 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:40,783215 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,783347 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:48:40,783756 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:40,785625 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:48:40,785760 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,785833 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:48:40,786298 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:40,787888 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:40,788025 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:48:40,788882 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:40,791043 (Thread-1): finished collecting timing info
2020-02-03 23:48:40,791597 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dec3890>]}
2020-02-03 23:48:41,413969 (Thread-1): 18:48:41 | 3 of 7 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:48:41,414308 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:48:41,414563 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:48:41,414823 (Thread-1): 18:48:41 | 4 of 7 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:48:41,415403 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,415545 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:48:41,415676 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:48:41,425356 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:48:41,427166 (Thread-1): finished collecting timing info
2020-02-03 23:48:41,453096 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,453265 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:48:41,453593 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:48:41,455767 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,455957 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:48:41,456358 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:48:41,458088 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:48:41,458473 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,458568 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:48:41,458746 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:41,458900 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,459054 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:48:41,460044 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 23:48:41,463813 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,463947 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:48:41,464304 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:41,466630 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,466756 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:48:41,467264 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:41,468192 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:48:41,468289 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,468438 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:48:41,469314 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:41,470970 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:41,471063 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:48:41,472409 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:48:41,474559 (Thread-1): finished collecting timing info
2020-02-03 23:48:41,475148 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dd52310>]}
2020-02-03 23:48:41,962520 (Thread-1): 18:48:41 | 4 of 7 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.06s]
2020-02-03 23:48:41,962851 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:48:41,963190 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:48:41,963991 (Thread-1): 18:48:41 | 5 of 7 START view model public.npi_with_crosswalks................... [RUN]
2020-02-03 23:48:41,965341 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:41,965632 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:48:41,965794 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:48:41,976109 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:48:41,976621 (Thread-1): finished collecting timing info
2020-02-03 23:48:41,987118 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:41,987304 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-03 23:48:41,987775 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:41,990593 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:41,990763 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:48:41,991111 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:41,992885 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:48:41,993465 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:41,993613 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-03 23:48:41,993907 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:41,994041 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:41,994142 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_long
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-03 23:48:41,995590 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:41,998641 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:41,998821 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
alter table "demo_db"."public"."npi_with_crosswalks__dbt_tmp" rename to "npi_with_crosswalks"
2020-02-03 23:48:41,999713 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:42,690 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-03 23:48:42,803 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:42,892 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-03 23:48:42,1313 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:42,3183 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:42,3288 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:48:42,3506 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:42,6025 (Thread-1): finished collecting timing info
2020-02-03 23:48:42,6672 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dedead0>]}
2020-02-03 23:48:42,655771 (Thread-1): 18:48:42 | 5 of 7 OK created view model public.npi_with_crosswalks.............. [CREATE VIEW in 0.04s]
2020-02-03 23:48:42,656041 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:48:42,656236 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:48:42,656443 (Thread-1): 18:48:42 | 6 of 7 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:48:42,656859 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,656981 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.npi_with_crosswalks).
2020-02-03 23:48:42,657105 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:48:42,665021 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:48:42,665631 (Thread-1): finished collecting timing info
2020-02-03 23:48:42,672826 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,672968 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:48:42,673363 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:42,677741 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,678100 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:48:42,678565 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:42,680800 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:48:42,681457 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,681635 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:48:42,681991 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:42,682115 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,682208 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:48:42,682999 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:42,686626 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,686797 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:48:42,687231 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:42,688185 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:48:42,688303 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,688387 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:48:42,688818 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:42,690670 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:42,690807 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:48:42,691058 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:42,693449 (Thread-1): finished collecting timing info
2020-02-03 23:48:42,694103 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dcb5e50>]}
2020-02-03 23:48:43,202629 (Thread-1): 18:48:43 | 6 of 7 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-03 23:48:43,202945 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:48:43,203293 (Thread-1): Began running node model.demo_pipeline.count_specialties
2020-02-03 23:48:43,203745 (Thread-1): 18:48:43 | 7 of 7 START view model public.count_specialties..................... [RUN]
2020-02-03 23:48:43,204296 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:43,204492 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-03 23:48:43,204675 (Thread-1): Compiling model.demo_pipeline.count_specialties
2020-02-03 23:48:43,212539 (Thread-1): Writing injected SQL for node "model.demo_pipeline.count_specialties"
2020-02-03 23:48:43,213136 (Thread-1): finished collecting timing info
2020-02-03 23:48:43,220169 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:43,220299 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_tmp" cascade
2020-02-03 23:48:43,220716 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:43,225105 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:43,225375 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-03 23:48:43,225945 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:43,228390 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.count_specialties"
2020-02-03 23:48:43,228962 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:43,229157 (Thread-1): On model.demo_pipeline.count_specialties: BEGIN
2020-02-03 23:48:43,229407 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:43,229517 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:43,229600 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */

  
  create view "demo_db"."public"."count_specialties__dbt_tmp" as (
    select 
	t.provider_taxonomy_description,
	s.state as state_long,
	count(distinct npi)
from "demo_db"."public"."npi_with_crosswalks" n
group by 1, 2
  );

2020-02-03 23:48:43,230109 (Thread-1): Postgres error: missing FROM-clause entry for table "t"
LINE 6:  t.provider_taxonomy_description,
         ^

2020-02-03 23:48:43,230243 (Thread-1): On model.demo_pipeline.count_specialties: ROLLBACK
2020-02-03 23:48:43,230505 (Thread-1): finished collecting timing info
2020-02-03 23:48:43,231021 (Thread-1): Database Error in model count_specialties (models/count_specialties.sql)
  missing FROM-clause entry for table "t"
  LINE 6:  t.provider_taxonomy_description,
           ^
  compiled SQL at target/run/demo_pipeline/count_specialties.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: missing FROM-clause entry for table "t"
LINE 6:  t.provider_taxonomy_description,
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model count_specialties (models/count_specialties.sql)
  missing FROM-clause entry for table "t"
  LINE 6:  t.provider_taxonomy_description,
           ^
  compiled SQL at target/run/demo_pipeline/count_specialties.sql
2020-02-03 23:48:43,239646 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd947023f-5528-4d9a-ba9d-f9b8ffa078c0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dd4cf10>]}
2020-02-03 23:48:43,582657 (Thread-1): 18:48:43 | 7 of 7 ERROR creating view model public.count_specialties............ [ERROR in 0.04s]
2020-02-03 23:48:43,582993 (Thread-1): Finished running node model.demo_pipeline.count_specialties
2020-02-03 23:48:43,651083 (MainThread): Using postgres connection "master".
2020-02-03 23:48:43,651310 (MainThread): On master: BEGIN
2020-02-03 23:48:43,651700 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:43,651874 (MainThread): On master: COMMIT
2020-02-03 23:48:43,652001 (MainThread): Using postgres connection "master".
2020-02-03 23:48:43,652113 (MainThread): On master: COMMIT
2020-02-03 23:48:43,652390 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:43,652776 (MainThread): 18:48:43 | 
2020-02-03 23:48:43,652953 (MainThread): 18:48:43 | Finished running 6 view models, 1 table model in 4.21s.
2020-02-03 23:48:43,653102 (MainThread): Connection 'master' was left open.
2020-02-03 23:48:43,653218 (MainThread): On master: Close
2020-02-03 23:48:43,653354 (MainThread): Connection 'model.demo_pipeline.count_specialties' was left open.
2020-02-03 23:48:43,653460 (MainThread): On model.demo_pipeline.count_specialties: Close
2020-02-03 23:48:43,674674 (MainThread): 
2020-02-03 23:48:43,674877 (MainThread): Completed with 1 error and 0 warnings:
2020-02-03 23:48:43,674987 (MainThread): 
2020-02-03 23:48:43,675088 (MainThread): Database Error in model count_specialties (models/count_specialties.sql)
2020-02-03 23:48:43,675177 (MainThread):   missing FROM-clause entry for table "t"
2020-02-03 23:48:43,675258 (MainThread):   LINE 6:  t.provider_taxonomy_description,
2020-02-03 23:48:43,675336 (MainThread):            ^
2020-02-03 23:48:43,675412 (MainThread):   compiled SQL at target/run/demo_pipeline/count_specialties.sql
2020-02-03 23:48:43,675500 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2020-02-03 23:48:43,675683 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dd28bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dd11650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dcc2b10>]}
2020-02-03 23:48:43,791576 (MainThread): Flushing usage events
2020-02-03 23:48:52,777142 (MainThread): Running with dbt=0.15.1
2020-02-03 23:48:52,816392 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-03 23:48:52,861513 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-03 23:48:52,862195 (MainThread): Tracking: tracking
2020-02-03 23:48:52,880067 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245ecd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245ec750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245eca10>]}
2020-02-03 23:48:53,79750 (MainThread): Partial parsing not enabled
2020-02-03 23:48:53,82400 (MainThread): Parsing macros/core.sql
2020-02-03 23:48:53,86419 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-03 23:48:53,92516 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-03 23:48:53,94978 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-03 23:48:53,107619 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-03 23:48:53,121452 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-03 23:48:53,134535 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-03 23:48:53,136105 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-03 23:48:53,140785 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-03 23:48:53,145671 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-03 23:48:53,154376 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-03 23:48:53,160671 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-03 23:48:53,169084 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-03 23:48:53,170528 (MainThread): Parsing macros/etc/query.sql
2020-02-03 23:48:53,172019 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-03 23:48:53,174014 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-03 23:48:53,176154 (MainThread): Parsing macros/etc/datetime.sql
2020-02-03 23:48:53,182912 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-03 23:48:53,184677 (MainThread): Parsing macros/adapters/common.sql
2020-02-03 23:48:53,203188 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-03 23:48:53,204291 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-03 23:48:53,205290 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-03 23:48:53,206453 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-03 23:48:53,208278 (MainThread): Parsing macros/catalog.sql
2020-02-03 23:48:53,209680 (MainThread): Parsing macros/relations.sql
2020-02-03 23:48:53,210949 (MainThread): Parsing macros/adapters.sql
2020-02-03 23:48:53,217596 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-03 23:48:53,231203 (MainThread): Partial parsing not enabled
2020-02-03 23:48:53,241140 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:53,241241 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,254975 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:53,255154 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,263157 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,263328 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,268723 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,268810 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,273945 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:53,274109 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,279072 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:53,279168 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,284265 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:53,284435 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,315812 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-03 23:48:53,315949 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,325927 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-03 23:48:53,326072 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,334464 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-03 23:48:53,334588 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,340092 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-03 23:48:53,340194 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,394414 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-03 23:48:53,400250 (MainThread): 
2020-02-03 23:48:53,400711 (MainThread): Acquiring new postgres connection "master".
2020-02-03 23:48:53,400801 (MainThread): Opening a new connection, currently in state init
2020-02-03 23:48:53,480726 (MainThread): Using postgres connection "master".
2020-02-03 23:48:53,480961 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-03 23:48:53,489021 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-03 23:48:53,533508 (MainThread): Using postgres connection "master".
2020-02-03 23:48:53,533638 (MainThread): On master: BEGIN
2020-02-03 23:48:53,534367 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:53,534543 (MainThread): Using postgres connection "master".
2020-02-03 23:48:53,534675 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-03 23:48:53,536936 (MainThread): SQL status: SELECT 10 in 0.00 seconds
2020-02-03 23:48:53,579955 (MainThread): Using postgres connection "master".
2020-02-03 23:48:53,580078 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-03 23:48:53,591590 (MainThread): SQL status: SELECT 7 in 0.01 seconds
2020-02-03 23:48:53,599814 (MainThread): On master: ROLLBACK
2020-02-03 23:48:53,600045 (MainThread): Using postgres connection "master".
2020-02-03 23:48:53,600144 (MainThread): On master: BEGIN
2020-02-03 23:48:53,600417 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:53,600538 (MainThread): On master: COMMIT
2020-02-03 23:48:53,600633 (MainThread): Using postgres connection "master".
2020-02-03 23:48:53,600714 (MainThread): On master: COMMIT
2020-02-03 23:48:53,600902 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:53,601158 (MainThread): 18:48:53 | Concurrency: 1 threads (target='dev')
2020-02-03 23:48:53,601276 (MainThread): 18:48:53 | 
2020-02-03 23:48:53,603911 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-03 23:48:53,604250 (Thread-1): 18:48:53 | 1 of 7 START view model public.stg_npi............................... [RUN]
2020-02-03 23:48:53,604516 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,604602 (Thread-1): Opening a new connection, currently in state init
2020-02-03 23:48:53,604689 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-03 23:48:53,614271 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:48:53,615390 (Thread-1): finished collecting timing info
2020-02-03 23:48:53,642507 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,642660 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-03 23:48:53,647058 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:53,649313 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,649428 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:48:53,649651 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:53,650849 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-03 23:48:53,651223 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,651309 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-03 23:48:53,651588 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:53,651667 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,651733 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-03 23:48:53,670384 (Thread-1): SQL status: CREATE VIEW in 0.02 seconds
2020-02-03 23:48:53,674251 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,674520 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-03 23:48:53,675338 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:53,678542 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,678733 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-03 23:48:53,679472 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:53,680826 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:48:53,680958 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,681056 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-03 23:48:53,681596 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:53,683377 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-03 23:48:53,683486 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-03 23:48:53,684508 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:53,686621 (Thread-1): finished collecting timing info
2020-02-03 23:48:53,687171 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12594ff50>]}
2020-02-03 23:48:53,838326 (Thread-1): 18:48:53 | 1 of 7 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.08s]
2020-02-03 23:48:53,838658 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-03 23:48:53,838983 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:48:53,839439 (Thread-1): 18:48:53 | 2 of 7 START view model public.stg_state_crosswalk................... [RUN]
2020-02-03 23:48:53,840010 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,840223 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-03 23:48:53,840419 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:48:53,848197 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:48:53,848650 (Thread-1): finished collecting timing info
2020-02-03 23:48:53,855130 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,855253 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-03 23:48:53,855581 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:53,857814 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,857956 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:48:53,858275 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:53,861559 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-03 23:48:53,862097 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,862220 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-03 23:48:53,862513 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:53,862640 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,862735 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	State as state, 
	Code as state_abbrev
from "demo_db"."public"."state_crosswalk"
  );

2020-02-03 23:48:53,863368 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:53,867176 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,867341 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-03 23:48:53,867865 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:53,870317 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,870473 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-03 23:48:53,870877 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:53,871701 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:48:53,871801 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,871880 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-03 23:48:53,872296 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:53,874008 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-03 23:48:53,874108 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-03 23:48:53,874743 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:53,876820 (Thread-1): finished collecting timing info
2020-02-03 23:48:53,877351 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12594fb50>]}
2020-02-03 23:48:54,34028 (Thread-1): 18:48:54 | 2 of 7 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-03 23:48:54,34374 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-03 23:48:54,34633 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:48:54,35035 (Thread-1): 18:48:54 | 3 of 7 START view model public.stg_taxonomy.......................... [RUN]
2020-02-03 23:48:54,35519 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,35654 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-03 23:48:54,35787 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-03 23:48:54,43597 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:48:54,44830 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,52356 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,52513 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-03 23:48:54,52937 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,55483 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,55623 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:48:54,55903 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,57474 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-03 23:48:54,57940 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,58057 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-03 23:48:54,58261 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:54,58393 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,58494 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-03 23:48:54,59238 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:54,63277 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,63399 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-03 23:48:54,63748 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,65977 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,66085 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-03 23:48:54,66390 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,68226 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:48:54,68347 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,68435 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-03 23:48:54,68948 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:54,70640 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-03 23:48:54,70749 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-03 23:48:54,71499 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,73754 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,74342 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d6e4e10>]}
2020-02-03 23:48:54,272720 (Thread-1): 18:48:54 | 3 of 7 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-03 23:48:54,273043 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-03 23:48:54,273300 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:48:54,273763 (Thread-1): 18:48:54 | 4 of 7 START table model public.my_first_dbt_model................... [RUN]
2020-02-03 23:48:54,274303 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,274446 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-03 23:48:54,274581 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-03 23:48:54,283945 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:48:54,284554 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,304839 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,305014 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-03 23:48:54,305338 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:48:54,307683 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,307821 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:48:54,308102 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-03 23:48:54,309547 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-03 23:48:54,309931 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,310025 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-03 23:48:54,310197 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:54,310303 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,310385 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-03 23:48:54,311297 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-03 23:48:54,314547 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,314645 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-03 23:48:54,314914 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,316927 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,317043 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-03 23:48:54,318265 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,319587 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:48:54,319775 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,319901 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-03 23:48:54,320417 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:54,322532 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-03 23:48:54,323275 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-03 23:48:54,347092 (Thread-1): SQL status: DROP TABLE in 0.02 seconds
2020-02-03 23:48:54,350493 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,351376 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259dd550>]}
2020-02-03 23:48:54,511255 (Thread-1): 18:48:54 | 4 of 7 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.08s]
2020-02-03 23:48:54,511596 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-03 23:48:54,511862 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:48:54,512068 (Thread-1): 18:48:54 | 5 of 7 START view model public.npi_with_crosswalks................... [RUN]
2020-02-03 23:48:54,512595 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,512743 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-03 23:48:54,512880 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:48:54,523410 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:48:54,523878 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,532493 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,532682 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-03 23:48:54,533021 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,536023 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,536278 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:48:54,536629 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,538285 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-03 23:48:54,538744 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,538856 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-03 23:48:54,539073 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:54,539178 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,539265 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_long
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-03 23:48:54,540588 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:54,543141 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,543287 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
alter table "demo_db"."public"."npi_with_crosswalks__dbt_tmp" rename to "npi_with_crosswalks"
2020-02-03 23:48:54,543767 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,544762 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-03 23:48:54,544875 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,544962 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-03 23:48:54,545376 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:54,547033 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-03 23:48:54,547140 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-03 23:48:54,547374 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,549630 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,550277 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12594b1d0>]}
2020-02-03 23:48:54,670712 (Thread-1): 18:48:54 | 5 of 7 OK created view model public.npi_with_crosswalks.............. [CREATE VIEW in 0.04s]
2020-02-03 23:48:54,671049 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-03 23:48:54,671303 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:48:54,671562 (Thread-1): 18:48:54 | 6 of 7 START view model public.my_second_dbt_model................... [RUN]
2020-02-03 23:48:54,672035 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,672165 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.npi_with_crosswalks).
2020-02-03 23:48:54,672297 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-03 23:48:54,680586 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:48:54,681287 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,688614 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,688808 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-03 23:48:54,689211 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,691833 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,692006 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:48:54,692318 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,693995 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-03 23:48:54,694505 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,694626 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-03 23:48:54,694941 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:54,695067 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,695175 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-03 23:48:54,695895 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-03 23:48:54,699682 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,699840 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-03 23:48:54,700284 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,701212 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:48:54,701316 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,701396 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-03 23:48:54,701791 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:54,703444 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-03 23:48:54,703542 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-03 23:48:54,703750 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,705946 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,706507 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259dd190>]}
2020-02-03 23:48:54,817887 (Thread-1): 18:48:54 | 6 of 7 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.03s]
2020-02-03 23:48:54,818211 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-03 23:48:54,818478 (Thread-1): Began running node model.demo_pipeline.count_specialties
2020-02-03 23:48:54,819084 (Thread-1): 18:48:54 | 7 of 7 START view model public.count_specialties..................... [RUN]
2020-02-03 23:48:54,819612 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,819858 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-03 23:48:54,820102 (Thread-1): Compiling model.demo_pipeline.count_specialties
2020-02-03 23:48:54,829028 (Thread-1): Writing injected SQL for node "model.demo_pipeline.count_specialties"
2020-02-03 23:48:54,829598 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,836799 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,836988 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_tmp" cascade
2020-02-03 23:48:54,837338 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,839750 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,839888 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-03 23:48:54,840182 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,842071 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.count_specialties"
2020-02-03 23:48:54,842588 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,842765 (Thread-1): On model.demo_pipeline.count_specialties: BEGIN
2020-02-03 23:48:54,843035 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:54,843141 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,843226 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */

  
  create view "demo_db"."public"."count_specialties__dbt_tmp" as (
    select 
	provider_taxonomy_description,
	state as state_long,
	count(distinct npi)
from "demo_db"."public"."npi_with_crosswalks" n
group by 1, 2
  );

2020-02-03 23:48:54,848416 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-02-03 23:48:54,850995 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,851136 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
alter table "demo_db"."public"."count_specialties__dbt_tmp" rename to "count_specialties"
2020-02-03 23:48:54,851522 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-03 23:48:54,852335 (Thread-1): On model.demo_pipeline.count_specialties: COMMIT
2020-02-03 23:48:54,852430 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,852505 (Thread-1): On model.demo_pipeline.count_specialties: COMMIT
2020-02-03 23:48:54,852813 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:54,854436 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-03 23:48:54,854532 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-03 23:48:54,854742 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-03 23:48:54,856887 (Thread-1): finished collecting timing info
2020-02-03 23:48:54,857455 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0a463467-bb67-4263-9832-6fe68a74306a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125863250>]}
2020-02-03 23:48:54,977243 (Thread-1): 18:48:54 | 7 of 7 OK created view model public.count_specialties................ [CREATE VIEW in 0.04s]
2020-02-03 23:48:54,977515 (Thread-1): Finished running node model.demo_pipeline.count_specialties
2020-02-03 23:48:55,48660 (MainThread): Using postgres connection "master".
2020-02-03 23:48:55,49053 (MainThread): On master: BEGIN
2020-02-03 23:48:55,49750 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-03 23:48:55,50097 (MainThread): On master: COMMIT
2020-02-03 23:48:55,50354 (MainThread): Using postgres connection "master".
2020-02-03 23:48:55,50579 (MainThread): On master: COMMIT
2020-02-03 23:48:55,51165 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-03 23:48:55,51950 (MainThread): 18:48:55 | 
2020-02-03 23:48:55,52301 (MainThread): 18:48:55 | Finished running 6 view models, 1 table model in 1.65s.
2020-02-03 23:48:55,52604 (MainThread): Connection 'master' was left open.
2020-02-03 23:48:55,52827 (MainThread): On master: Close
2020-02-03 23:48:55,53091 (MainThread): Connection 'model.demo_pipeline.count_specialties' was left open.
2020-02-03 23:48:55,53302 (MainThread): On model.demo_pipeline.count_specialties: Close
2020-02-03 23:48:55,73518 (MainThread): 
2020-02-03 23:48:55,73723 (MainThread): Completed successfully
2020-02-03 23:48:55,73847 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2020-02-03 23:48:55,74046 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125942390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125a40690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1259c39d0>]}
2020-02-03 23:48:55,251224 (MainThread): Flushing usage events
2020-02-04 17:32:10,288578 (MainThread): Running with dbt=0.15.1
2020-02-04 17:32:10,328868 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-04 17:32:10,368326 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-04 17:32:10,368861 (MainThread): Tracking: tracking
2020-02-04 17:32:10,399757 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ddcacd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ddcaa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ddca910>]}
2020-02-04 17:32:10,636106 (MainThread): Partial parsing not enabled
2020-02-04 17:32:10,641837 (MainThread): Parsing macros/core.sql
2020-02-04 17:32:10,648145 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-04 17:32:10,656476 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-04 17:32:10,659117 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-04 17:32:10,673315 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-04 17:32:10,690132 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-04 17:32:10,709708 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-04 17:32:10,711475 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-04 17:32:10,716452 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-04 17:32:10,721726 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-04 17:32:10,727223 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-04 17:32:10,734067 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-04 17:32:10,739034 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-04 17:32:10,740220 (MainThread): Parsing macros/etc/query.sql
2020-02-04 17:32:10,741560 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-04 17:32:10,743328 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-04 17:32:10,745170 (MainThread): Parsing macros/etc/datetime.sql
2020-02-04 17:32:10,751302 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-04 17:32:10,752899 (MainThread): Parsing macros/adapters/common.sql
2020-02-04 17:32:10,771049 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-04 17:32:10,772153 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-04 17:32:10,773059 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-04 17:32:10,774235 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-04 17:32:10,776321 (MainThread): Parsing macros/catalog.sql
2020-02-04 17:32:10,777745 (MainThread): Parsing macros/relations.sql
2020-02-04 17:32:10,779083 (MainThread): Parsing macros/adapters.sql
2020-02-04 17:32:10,786089 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-04 17:32:10,802193 (MainThread): Partial parsing not enabled
2020-02-04 17:32:10,812566 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:32:10,812682 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,824879 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:32:10,824982 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,830160 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:32:10,830233 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,834674 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:32:10,834775 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,838878 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:32:10,838998 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,843499 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:32:10,843581 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,846975 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:32:10,847052 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,880921 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-04 17:32:10,881099 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,893022 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-04 17:32:10,893201 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,905556 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-04 17:32:10,905743 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,913835 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-04 17:32:10,914014 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:10,984817 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-04 17:32:10,989758 (MainThread): 
2020-02-04 17:32:10,990140 (MainThread): Acquiring new postgres connection "master".
2020-02-04 17:32:10,990240 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:32:11,67664 (MainThread): Using postgres connection "master".
2020-02-04 17:32:11,67834 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-04 17:32:11,95251 (MainThread): SQL status: SELECT 6 in 0.03 seconds
2020-02-04 17:32:11,139878 (MainThread): Using postgres connection "master".
2020-02-04 17:32:11,140046 (MainThread): On master: BEGIN
2020-02-04 17:32:11,142596 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:32:11,142806 (MainThread): Using postgres connection "master".
2020-02-04 17:32:11,142905 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-04 17:32:11,149936 (MainThread): SQL status: SELECT 11 in 0.01 seconds
2020-02-04 17:32:11,195381 (MainThread): Using postgres connection "master".
2020-02-04 17:32:11,195545 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-04 17:32:11,215317 (MainThread): SQL status: SELECT 8 in 0.02 seconds
2020-02-04 17:32:11,224503 (MainThread): On master: ROLLBACK
2020-02-04 17:32:11,227564 (MainThread): Using postgres connection "master".
2020-02-04 17:32:11,227944 (MainThread): On master: BEGIN
2020-02-04 17:32:11,228580 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:32:11,228726 (MainThread): On master: COMMIT
2020-02-04 17:32:11,228824 (MainThread): Using postgres connection "master".
2020-02-04 17:32:11,228907 (MainThread): On master: COMMIT
2020-02-04 17:32:11,229088 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:32:11,229427 (MainThread): 12:32:11 | Concurrency: 1 threads (target='dev')
2020-02-04 17:32:11,229564 (MainThread): 12:32:11 | 
2020-02-04 17:32:11,232400 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:32:11,232662 (Thread-1): 12:32:11 | 1 of 3 START seed file public.HEALTHCARE_PROVIDER_TAXONOMY........... [RUN]
2020-02-04 17:32:11,232991 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:32:11,233078 (Thread-1): Opening a new connection, currently in state init
2020-02-04 17:32:11,233188 (Thread-1): finished collecting timing info
2020-02-04 17:32:11,282676 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:32:11,282842 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-04 17:32:11,286651 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:32:11,286836 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:32:11,286921 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"} */
truncate table "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-04 17:32:11,299992 (Thread-1): SQL status: TRUNCATE TABLE in 0.01 seconds
2020-02-04 17:32:11,301760 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-04 17:32:11,313673 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:32:11,313817 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s...
2020-02-04 17:32:11,321209 (Thread-1): SQL status: INSERT 0 521 in 0.01 seconds
2020-02-04 17:32:11,322549 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-04 17:32:11,323813 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-04 17:32:11,323936 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:32:11,324009 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-04 17:32:11,331510 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-02-04 17:32:11,335095 (Thread-1): finished collecting timing info
2020-02-04 17:32:11,336087 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98843a46-686b-49e7-8330-9886f157d97b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f188ed0>]}
2020-02-04 17:32:11,492002 (Thread-1): 12:32:11 | 1 of 3 OK loaded seed file public.HEALTHCARE_PROVIDER_TAXONOMY....... [INSERT 521 in 0.10s]
2020-02-04 17:32:11,492227 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:32:11,492475 (Thread-1): Began running node seed.demo_pipeline.abbr-name-list
2020-02-04 17:32:11,492753 (Thread-1): 12:32:11 | 2 of 3 START seed file public.abbr-name-list......................... [RUN]
2020-02-04 17:32:11,493140 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:32:11,493258 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-04 17:32:11,493376 (Thread-1): finished collecting timing info
2020-02-04 17:32:11,497581 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:32:11,497718 (Thread-1): On seed.demo_pipeline.abbr-name-list: BEGIN
2020-02-04 17:32:11,498168 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:32:11,498295 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:32:11,498400 (Thread-1): On seed.demo_pipeline.abbr-name-list: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.abbr-name-list"} */

    create table "demo_db"."public"."abbr-name-list" (name text,abbreviation text)
  
2020-02-04 17:32:11,502775 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-04 17:32:11,505480 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:32:11,505599 (Thread-1): On seed.demo_pipeline.abbr-name-list: 
            insert into "demo_db"."public"."abbr-name-list" (name, abbreviation) values
            (%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s...
2020-02-04 17:32:11,506234 (Thread-1): SQL status: INSERT 0 59 in 0.00 seconds
2020-02-04 17:32:11,506526 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.abbr-name-list"
2020-02-04 17:32:11,507535 (Thread-1): On seed.demo_pipeline.abbr-name-list: COMMIT
2020-02-04 17:32:11,507642 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:32:11,507728 (Thread-1): On seed.demo_pipeline.abbr-name-list: COMMIT
2020-02-04 17:32:11,511657 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:32:11,515812 (Thread-1): finished collecting timing info
2020-02-04 17:32:11,516557 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98843a46-686b-49e7-8330-9886f157d97b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f135b90>]}
2020-02-04 17:32:11,628845 (Thread-1): 12:32:11 | 2 of 3 OK loaded seed file public.abbr-name-list..................... [INSERT 59 in 0.02s]
2020-02-04 17:32:11,629183 (Thread-1): Finished running node seed.demo_pipeline.abbr-name-list
2020-02-04 17:32:11,629437 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-04 17:32:11,629695 (Thread-1): 12:32:11 | 3 of 3 START seed file public.npi_small_2019......................... [RUN]
2020-02-04 17:32:11,630194 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:32:11,630321 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.abbr-name-list).
2020-02-04 17:32:11,630460 (Thread-1): finished collecting timing info
2020-02-04 17:32:12,44468 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:32:12,44610 (Thread-1): On seed.demo_pipeline.npi_small_2019: BEGIN
2020-02-04 17:32:12,45093 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:32:12,45173 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:32:12,45237 (Thread-1): On seed.demo_pipeline.npi_small_2019: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.npi_small_2019"} */
truncate table "demo_db"."public"."npi_small_2019"
2020-02-04 17:32:12,46362 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:32:12,303643 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:32:12,303823 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-04 17:32:12,425211 (Thread-1): SQL status: INSERT 0 10000 in 0.12 seconds
2020-02-04 17:32:12,665890 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:32:12,666059 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-04 17:32:12,761725 (Thread-1): SQL status: INSERT 0 8649 in 0.10 seconds
2020-02-04 17:32:12,763225 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.npi_small_2019"
2020-02-04 17:32:12,764830 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-04 17:32:12,765054 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:32:12,765185 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-04 17:32:12,770019 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:32:12,773747 (Thread-1): finished collecting timing info
2020-02-04 17:32:12,774434 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '98843a46-686b-49e7-8330-9886f157d97b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f13d210>]}
2020-02-04 17:32:12,900771 (Thread-1): 12:32:12 | 3 of 3 OK loaded seed file public.npi_small_2019..................... [INSERT 18649 in 1.14s]
2020-02-04 17:32:12,901099 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-04 17:32:12,933130 (MainThread): Using postgres connection "master".
2020-02-04 17:32:12,933572 (MainThread): On master: BEGIN
2020-02-04 17:32:12,934181 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:32:12,934519 (MainThread): On master: COMMIT
2020-02-04 17:32:12,934718 (MainThread): Using postgres connection "master".
2020-02-04 17:32:12,934901 (MainThread): On master: COMMIT
2020-02-04 17:32:12,935465 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:32:12,936755 (MainThread): 12:32:12 | 
2020-02-04 17:32:12,937055 (MainThread): 12:32:12 | Finished running 3 seeds in 1.95s.
2020-02-04 17:32:12,937210 (MainThread): Connection 'master' was left open.
2020-02-04 17:32:12,937334 (MainThread): On master: Close
2020-02-04 17:32:12,937550 (MainThread): Connection 'seed.demo_pipeline.npi_small_2019' was left open.
2020-02-04 17:32:12,937692 (MainThread): On seed.demo_pipeline.npi_small_2019: Close
2020-02-04 17:32:12,951383 (MainThread): 
2020-02-04 17:32:12,951583 (MainThread): Completed successfully
2020-02-04 17:32:12,951727 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-02-04 17:32:12,951945 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f15a5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f3fe110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f3fee90>]}
2020-02-04 17:32:13,70969 (MainThread): Flushing usage events
2020-02-04 17:33:40,945815 (MainThread): Running with dbt=0.15.1
2020-02-04 17:33:40,981737 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-04 17:33:41,10740 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-04 17:33:41,11237 (MainThread): Tracking: tracking
2020-02-04 17:33:41,24672 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d2ec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d2e990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121d2e8d0>]}
2020-02-04 17:33:41,244598 (MainThread): Partial parsing not enabled
2020-02-04 17:33:41,246653 (MainThread): Parsing macros/core.sql
2020-02-04 17:33:41,250126 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-04 17:33:41,255674 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-04 17:33:41,257069 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-04 17:33:41,268359 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-04 17:33:41,281587 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-04 17:33:41,293692 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-04 17:33:41,295241 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-04 17:33:41,299744 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-04 17:33:41,305262 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-04 17:33:41,309386 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-04 17:33:41,313915 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-04 17:33:41,317336 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-04 17:33:41,318044 (MainThread): Parsing macros/etc/query.sql
2020-02-04 17:33:41,318878 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-04 17:33:41,320441 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-04 17:33:41,321914 (MainThread): Parsing macros/etc/datetime.sql
2020-02-04 17:33:41,327297 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-04 17:33:41,329183 (MainThread): Parsing macros/adapters/common.sql
2020-02-04 17:33:41,349126 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-04 17:33:41,350089 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-04 17:33:41,350784 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-04 17:33:41,351611 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-04 17:33:41,353351 (MainThread): Parsing macros/catalog.sql
2020-02-04 17:33:41,355080 (MainThread): Parsing macros/relations.sql
2020-02-04 17:33:41,356193 (MainThread): Parsing macros/adapters.sql
2020-02-04 17:33:41,363421 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-04 17:33:41,379222 (MainThread): Partial parsing not enabled
2020-02-04 17:33:41,390657 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:33:41,390817 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,404985 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:33:41,405121 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,410994 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,411082 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,415780 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,415897 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,420359 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:41,420490 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,424926 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:41,425017 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,428989 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:41,429099 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,461106 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-04 17:33:41,461270 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,470220 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-04 17:33:41,470355 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,479312 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-04 17:33:41,479460 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,485277 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-04 17:33:41,485505 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,544065 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-04 17:33:41,549115 (MainThread): 
2020-02-04 17:33:41,549460 (MainThread): Acquiring new postgres connection "master".
2020-02-04 17:33:41,549547 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:33:41,628703 (MainThread): Using postgres connection "master".
2020-02-04 17:33:41,628902 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-04 17:33:41,633107 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-04 17:33:41,679671 (MainThread): Using postgres connection "master".
2020-02-04 17:33:41,679816 (MainThread): On master: BEGIN
2020-02-04 17:33:41,680120 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:41,680202 (MainThread): Using postgres connection "master".
2020-02-04 17:33:41,680266 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-04 17:33:41,682308 (MainThread): SQL status: SELECT 12 in 0.00 seconds
2020-02-04 17:33:41,732181 (MainThread): Using postgres connection "master".
2020-02-04 17:33:41,732329 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-04 17:33:41,749240 (MainThread): SQL status: SELECT 8 in 0.02 seconds
2020-02-04 17:33:41,757895 (MainThread): On master: ROLLBACK
2020-02-04 17:33:41,758327 (MainThread): Using postgres connection "master".
2020-02-04 17:33:41,758419 (MainThread): On master: BEGIN
2020-02-04 17:33:41,758627 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:41,758715 (MainThread): On master: COMMIT
2020-02-04 17:33:41,758787 (MainThread): Using postgres connection "master".
2020-02-04 17:33:41,758850 (MainThread): On master: COMMIT
2020-02-04 17:33:41,758973 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:41,759229 (MainThread): 12:33:41 | Concurrency: 1 threads (target='dev')
2020-02-04 17:33:41,759337 (MainThread): 12:33:41 | 
2020-02-04 17:33:41,760827 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-04 17:33:41,760980 (Thread-1): 12:33:41 | 1 of 7 START view model public.stg_npi............................... [RUN]
2020-02-04 17:33:41,761222 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,761305 (Thread-1): Opening a new connection, currently in state init
2020-02-04 17:33:41,761395 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-04 17:33:41,771635 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-04 17:33:41,772217 (Thread-1): finished collecting timing info
2020-02-04 17:33:41,802718 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,802879 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-04 17:33:41,806609 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:41,810665 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,810824 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-04 17:33:41,811092 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:41,812454 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-04 17:33:41,812959 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,813051 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-04 17:33:41,813273 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:41,813356 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,813422 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-04 17:33:41,818800 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-02-04 17:33:41,821976 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,822095 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-04 17:33:41,822620 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:41,824559 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,824676 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-04 17:33:41,824989 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:41,825691 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-04 17:33:41,825776 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,825845 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-04 17:33:41,826282 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:41,827728 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:33:41,827826 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-04 17:33:41,829629 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:41,831603 (Thread-1): finished collecting timing info
2020-02-04 17:33:41,832125 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a63e2fc0-f510-4c06-a6fb-447efea9ed51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f30c10>]}
2020-02-04 17:33:41,960549 (Thread-1): 12:33:41 | 1 of 7 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.07s]
2020-02-04 17:33:41,960890 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-04 17:33:41,961147 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:33:41,961409 (Thread-1): 12:33:41 | 2 of 7 START view model public.stg_state_crosswalk................... [RUN]
2020-02-04 17:33:41,961894 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,962030 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-04 17:33:41,962163 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:33:41,969657 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-04 17:33:41,970110 (Thread-1): finished collecting timing info
2020-02-04 17:33:41,976046 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,976176 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-04 17:33:41,976525 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:41,979541 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,979638 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-04 17:33:41,979891 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:41,981186 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-04 17:33:41,981536 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,981633 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-04 17:33:41,981798 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:41,981902 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,981984 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."abbr-name-list"
  );

2020-02-04 17:33:41,982560 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:33:41,985832 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,985947 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-04 17:33:41,986347 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:41,988215 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,988305 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-04 17:33:41,988546 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:41,989265 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-04 17:33:41,989363 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,989439 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-04 17:33:41,989901 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:41,991417 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:33:41,991512 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-04 17:33:41,992273 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:41,994297 (Thread-1): finished collecting timing info
2020-02-04 17:33:41,994864 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a63e2fc0-f510-4c06-a6fb-447efea9ed51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1230ebe10>]}
2020-02-04 17:33:42,122184 (Thread-1): 12:33:42 | 2 of 7 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.03s]
2020-02-04 17:33:42,122528 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:33:42,122783 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-04 17:33:42,123044 (Thread-1): 12:33:42 | 3 of 7 START view model public.stg_taxonomy.......................... [RUN]
2020-02-04 17:33:42,123615 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,123760 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-04 17:33:42,123894 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-04 17:33:42,131482 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-04 17:33:42,131950 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,141760 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,141971 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-04 17:33:42,142362 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,145001 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,145149 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-04 17:33:42,145464 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,147289 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-04 17:33:42,147756 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,147873 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-04 17:33:42,148109 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:42,148219 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,148310 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-04 17:33:42,149098 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:33:42,153321 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,153503 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-04 17:33:42,153966 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:42,157525 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,157735 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-04 17:33:42,158315 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:42,159345 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-04 17:33:42,159465 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,159559 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-04 17:33:42,160236 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:42,162151 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:33:42,162267 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-04 17:33:42,162983 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,165389 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,165987 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a63e2fc0-f510-4c06-a6fb-447efea9ed51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1230ee710>]}
2020-02-04 17:33:42,286130 (Thread-1): 12:33:42 | 3 of 7 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-04 17:33:42,286455 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-04 17:33:42,286720 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-04 17:33:42,287420 (Thread-1): 12:33:42 | 4 of 7 START table model public.my_first_dbt_model................... [RUN]
2020-02-04 17:33:42,288102 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,288260 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-04 17:33:42,288396 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-04 17:33:42,298004 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-04 17:33:42,298629 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,316627 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,316784 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-04 17:33:42,317121 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:33:42,319071 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,319168 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-04 17:33:42,319419 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:33:42,320646 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-04 17:33:42,321049 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,321133 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-04 17:33:42,321321 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:42,321400 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,321467 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-04 17:33:42,322357 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-04 17:33:42,325169 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,325253 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-04 17:33:42,325510 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:42,327171 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,327253 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-04 17:33:42,327561 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:42,328240 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-04 17:33:42,328323 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,328391 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-04 17:33:42,328893 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:42,330685 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:33:42,330791 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-04 17:33:42,332969 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:33:42,335350 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,335909 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a63e2fc0-f510-4c06-a6fb-447efea9ed51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f6f8d0>]}
2020-02-04 17:33:42,468811 (Thread-1): 12:33:42 | 4 of 7 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.05s]
2020-02-04 17:33:42,469135 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-04 17:33:42,469393 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:33:42,469650 (Thread-1): 12:33:42 | 5 of 7 START view model public.npi_with_crosswalks................... [RUN]
2020-02-04 17:33:42,470249 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:33:42,470399 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-04 17:33:42,470538 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:33:42,481739 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-04 17:33:42,482305 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,489095 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:33:42,489252 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-04 17:33:42,489569 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,491676 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:33:42,491780 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-04 17:33:42,491986 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,493438 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-04 17:33:42,493858 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:33:42,493960 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-04 17:33:42,494194 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:42,494300 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:33:42,494384 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_long
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.abbreviation
  );

2020-02-04 17:33:42,499723 (Thread-1): Postgres error: column s.state does not exist
LINE 8:  s.state as state_long
         ^
HINT:  Perhaps you meant to reference the column "n.state".

2020-02-04 17:33:42,499925 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: ROLLBACK
2020-02-04 17:33:42,500295 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,500858 (Thread-1): Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
  column s.state does not exist
  LINE 8:  s.state as state_long
           ^
  HINT:  Perhaps you meant to reference the column "n.state".
  compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.ProgrammingError: column s.state does not exist
LINE 8:  s.state as state_long
         ^
HINT:  Perhaps you meant to reference the column "n.state".


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
  column s.state does not exist
  LINE 8:  s.state as state_long
           ^
  HINT:  Perhaps you meant to reference the column "n.state".
  compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
2020-02-04 17:33:42,511604 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a63e2fc0-f510-4c06-a6fb-447efea9ed51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f6f8d0>]}
2020-02-04 17:33:42,635349 (Thread-1): 12:33:42 | 5 of 7 ERROR creating view model public.npi_with_crosswalks.......... [ERROR in 0.04s]
2020-02-04 17:33:42,635688 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:33:42,636005 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-04 17:33:42,636588 (Thread-1): 12:33:42 | 6 of 7 START view model public.my_second_dbt_model................... [RUN]
2020-02-04 17:33:42,637008 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,637140 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.npi_with_crosswalks).
2020-02-04 17:33:42,637268 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-04 17:33:42,645892 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-04 17:33:42,646406 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,653159 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,653320 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-04 17:33:42,653795 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,656168 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,656283 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-04 17:33:42,656547 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,658233 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-04 17:33:42,658680 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,658789 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-04 17:33:42,659059 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:42,659184 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,659277 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-04 17:33:42,660014 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:33:42,662704 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,662868 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-04 17:33:42,663312 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:33:42,664250 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-04 17:33:42,664387 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,664474 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-04 17:33:42,665690 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:42,668592 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:33:42,668746 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-04 17:33:42,669065 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:33:42,671355 (Thread-1): finished collecting timing info
2020-02-04 17:33:42,671943 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a63e2fc0-f510-4c06-a6fb-447efea9ed51', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f63290>]}
2020-02-04 17:33:42,839901 (Thread-1): 12:33:42 | 6 of 7 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.03s]
2020-02-04 17:33:42,840135 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-04 17:33:42,840291 (Thread-1): Began running node model.demo_pipeline.count_specialties
2020-02-04 17:33:42,840445 (Thread-1): 12:33:42 | 7 of 7 SKIP relation public.count_specialties........................ [SKIP]
2020-02-04 17:33:42,840668 (Thread-1): Finished running node model.demo_pipeline.count_specialties
2020-02-04 17:33:42,899233 (MainThread): Using postgres connection "master".
2020-02-04 17:33:42,899472 (MainThread): On master: BEGIN
2020-02-04 17:33:42,899849 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:33:42,899999 (MainThread): On master: COMMIT
2020-02-04 17:33:42,900119 (MainThread): Using postgres connection "master".
2020-02-04 17:33:42,900230 (MainThread): On master: COMMIT
2020-02-04 17:33:42,900499 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:33:42,900898 (MainThread): 12:33:42 | 
2020-02-04 17:33:42,901078 (MainThread): 12:33:42 | Finished running 6 view models, 1 table model in 1.35s.
2020-02-04 17:33:42,901231 (MainThread): Connection 'master' was left open.
2020-02-04 17:33:42,901350 (MainThread): On master: Close
2020-02-04 17:33:42,901496 (MainThread): Connection 'model.demo_pipeline.my_second_dbt_model' was left open.
2020-02-04 17:33:42,901624 (MainThread): On model.demo_pipeline.my_second_dbt_model: Close
2020-02-04 17:33:42,923544 (MainThread): 
2020-02-04 17:33:42,924104 (MainThread): Completed with 1 error and 0 warnings:
2020-02-04 17:33:42,924517 (MainThread): 
2020-02-04 17:33:42,924687 (MainThread): Database Error in model npi_with_crosswalks (models/npi_with_crosswalks.sql)
2020-02-04 17:33:42,924806 (MainThread):   column s.state does not exist
2020-02-04 17:33:42,924915 (MainThread):   LINE 8:  s.state as state_long
2020-02-04 17:33:42,925019 (MainThread):            ^
2020-02-04 17:33:42,925131 (MainThread):   HINT:  Perhaps you meant to reference the column "n.state".
2020-02-04 17:33:42,925224 (MainThread):   compiled SQL at target/run/demo_pipeline/npi_with_crosswalks.sql
2020-02-04 17:33:42,925329 (MainThread): 
Done. PASS=6 WARN=0 ERROR=1 SKIP=0 TOTAL=7
2020-02-04 17:33:42,925530 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123178310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122f6fad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12307ddd0>]}
2020-02-04 17:33:43,82512 (MainThread): Flushing usage events
2020-02-04 17:34:08,52196 (MainThread): Running with dbt=0.15.1
2020-02-04 17:34:08,82584 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-04 17:34:08,112110 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=True, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-04 17:34:08,112611 (MainThread): Tracking: tracking
2020-02-04 17:34:08,126290 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126afd950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126afdd90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126afdb90>]}
2020-02-04 17:34:08,301410 (MainThread): Partial parsing not enabled
2020-02-04 17:34:08,303301 (MainThread): Parsing macros/core.sql
2020-02-04 17:34:08,306604 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-04 17:34:08,311739 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-04 17:34:08,313027 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-04 17:34:08,324072 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-04 17:34:08,337269 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-04 17:34:08,348892 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-04 17:34:08,350250 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-04 17:34:08,354651 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-04 17:34:08,359463 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-04 17:34:08,364713 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-04 17:34:08,369088 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-04 17:34:08,372565 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-04 17:34:08,373470 (MainThread): Parsing macros/etc/query.sql
2020-02-04 17:34:08,374415 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-04 17:34:08,375742 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-04 17:34:08,377196 (MainThread): Parsing macros/etc/datetime.sql
2020-02-04 17:34:08,382688 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-04 17:34:08,383973 (MainThread): Parsing macros/adapters/common.sql
2020-02-04 17:34:08,403102 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-04 17:34:08,404196 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-04 17:34:08,404861 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-04 17:34:08,405619 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-04 17:34:08,407303 (MainThread): Parsing macros/catalog.sql
2020-02-04 17:34:08,408462 (MainThread): Parsing macros/relations.sql
2020-02-04 17:34:08,409514 (MainThread): Parsing macros/adapters.sql
2020-02-04 17:34:08,416023 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-04 17:34:08,429667 (MainThread): Partial parsing not enabled
2020-02-04 17:34:08,440217 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:08,440361 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,452597 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:08,452698 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,458278 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:08,458371 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,462488 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:08,462564 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,466378 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:08,466452 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,470381 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:08,470464 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,474003 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:08,474078 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,503275 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-04 17:34:08,503405 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,511189 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-04 17:34:08,511270 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,518993 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-04 17:34:08,519081 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,524147 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-04 17:34:08,524229 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,575549 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-04 17:34:08,579532 (MainThread): 
2020-02-04 17:34:08,579928 (MainThread): Acquiring new postgres connection "master".
2020-02-04 17:34:08,579997 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:08,654548 (MainThread): Using postgres connection "master".
2020-02-04 17:34:08,654710 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-04 17:34:08,659025 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-04 17:34:08,702166 (MainThread): Using postgres connection "master".
2020-02-04 17:34:08,702379 (MainThread): On master: BEGIN
2020-02-04 17:34:08,702869 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:08,702980 (MainThread): Using postgres connection "master".
2020-02-04 17:34:08,703062 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-04 17:34:08,705338 (MainThread): SQL status: SELECT 10 in 0.00 seconds
2020-02-04 17:34:08,750280 (MainThread): Using postgres connection "master".
2020-02-04 17:34:08,750435 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-04 17:34:08,762969 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-04 17:34:08,768163 (MainThread): On master: ROLLBACK
2020-02-04 17:34:08,768442 (MainThread): Using postgres connection "master".
2020-02-04 17:34:08,768549 (MainThread): On master: BEGIN
2020-02-04 17:34:08,768840 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:08,768956 (MainThread): On master: COMMIT
2020-02-04 17:34:08,769045 (MainThread): Using postgres connection "master".
2020-02-04 17:34:08,769121 (MainThread): On master: COMMIT
2020-02-04 17:34:08,769275 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:08,769547 (MainThread): 12:34:08 | Concurrency: 1 threads (target='dev')
2020-02-04 17:34:08,769672 (MainThread): 12:34:08 | 
2020-02-04 17:34:08,771133 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:34:08,771305 (Thread-1): 12:34:08 | 1 of 3 START seed file public.HEALTHCARE_PROVIDER_TAXONOMY........... [RUN]
2020-02-04 17:34:08,771572 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:08,771663 (Thread-1): Opening a new connection, currently in state init
2020-02-04 17:34:08,771771 (Thread-1): finished collecting timing info
2020-02-04 17:34:08,824398 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:08,824591 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-04 17:34:08,827985 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:08,828098 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:08,828167 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"} */
truncate table "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-04 17:34:08,830110 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:34:08,831740 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-04 17:34:08,844442 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:08,845270 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s...
2020-02-04 17:34:08,850740 (Thread-1): SQL status: INSERT 0 521 in 0.01 seconds
2020-02-04 17:34:08,851128 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-04 17:34:08,852087 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-04 17:34:08,852172 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:08,852239 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-04 17:34:08,858151 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-02-04 17:34:08,861593 (Thread-1): finished collecting timing info
2020-02-04 17:34:08,862259 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4bbd0b1e-aeda-4eb8-8232-d050393d0a12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127c3a310>]}
2020-02-04 17:34:08,985281 (Thread-1): 12:34:08 | 1 of 3 OK loaded seed file public.HEALTHCARE_PROVIDER_TAXONOMY....... [INSERT 521 in 0.09s]
2020-02-04 17:34:08,985616 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:34:08,985992 (Thread-1): Began running node seed.demo_pipeline.abbr-name-list
2020-02-04 17:34:08,986268 (Thread-1): 12:34:08 | 2 of 3 START seed file public.abbr-name-list......................... [RUN]
2020-02-04 17:34:08,986815 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:08,986958 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-04 17:34:08,987096 (Thread-1): finished collecting timing info
2020-02-04 17:34:08,995559 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:08,995743 (Thread-1): On seed.demo_pipeline.abbr-name-list: BEGIN
2020-02-04 17:34:08,996192 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:08,996322 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:08,996427 (Thread-1): On seed.demo_pipeline.abbr-name-list: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.abbr-name-list"} */
truncate table "demo_db"."public"."abbr-name-list"
2020-02-04 17:34:08,997620 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:34:09,1752 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:09,1935 (Thread-1): On seed.demo_pipeline.abbr-name-list: 
            insert into "demo_db"."public"."abbr-name-list" (name, abbreviation) values
            (%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s...
2020-02-04 17:34:09,2711 (Thread-1): SQL status: INSERT 0 59 in 0.00 seconds
2020-02-04 17:34:09,3008 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.abbr-name-list"
2020-02-04 17:34:09,4144 (Thread-1): On seed.demo_pipeline.abbr-name-list: COMMIT
2020-02-04 17:34:09,4253 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:09,4342 (Thread-1): On seed.demo_pipeline.abbr-name-list: COMMIT
2020-02-04 17:34:09,9355 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:09,12941 (Thread-1): finished collecting timing info
2020-02-04 17:34:09,13609 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4bbd0b1e-aeda-4eb8-8232-d050393d0a12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ebefd0>]}
2020-02-04 17:34:09,138393 (Thread-1): 12:34:09 | 2 of 3 OK loaded seed file public.abbr-name-list..................... [INSERT 59 in 0.03s]
2020-02-04 17:34:09,138883 (Thread-1): Finished running node seed.demo_pipeline.abbr-name-list
2020-02-04 17:34:09,139274 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-04 17:34:09,139714 (Thread-1): 12:34:09 | 3 of 3 START seed file public.npi_small_2019......................... [RUN]
2020-02-04 17:34:09,140343 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:09,140574 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.abbr-name-list).
2020-02-04 17:34:09,140826 (Thread-1): finished collecting timing info
2020-02-04 17:34:09,557222 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:09,557374 (Thread-1): On seed.demo_pipeline.npi_small_2019: BEGIN
2020-02-04 17:34:09,557731 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:09,557810 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:09,557871 (Thread-1): On seed.demo_pipeline.npi_small_2019: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.npi_small_2019"} */
truncate table "demo_db"."public"."npi_small_2019"
2020-02-04 17:34:09,558977 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:34:09,813882 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:09,814066 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-04 17:34:09,940768 (Thread-1): SQL status: INSERT 0 10000 in 0.13 seconds
2020-02-04 17:34:10,185840 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:10,186012 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-04 17:34:10,283699 (Thread-1): SQL status: INSERT 0 8649 in 0.10 seconds
2020-02-04 17:34:10,285267 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.npi_small_2019"
2020-02-04 17:34:10,286600 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-04 17:34:10,286712 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:10,286798 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-04 17:34:10,292879 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-02-04 17:34:10,296077 (Thread-1): finished collecting timing info
2020-02-04 17:34:10,296805 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4bbd0b1e-aeda-4eb8-8232-d050393d0a12', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127eaf350>]}
2020-02-04 17:34:10,444276 (Thread-1): 12:34:10 | 3 of 3 OK loaded seed file public.npi_small_2019..................... [INSERT 18649 in 1.16s]
2020-02-04 17:34:10,444530 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-04 17:34:10,489768 (MainThread): Using postgres connection "master".
2020-02-04 17:34:10,490157 (MainThread): On master: BEGIN
2020-02-04 17:34:10,490833 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:10,491058 (MainThread): On master: COMMIT
2020-02-04 17:34:10,491223 (MainThread): Using postgres connection "master".
2020-02-04 17:34:10,491369 (MainThread): On master: COMMIT
2020-02-04 17:34:10,491849 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:10,492461 (MainThread): 12:34:10 | 
2020-02-04 17:34:10,492750 (MainThread): 12:34:10 | Finished running 3 seeds in 1.91s.
2020-02-04 17:34:10,492997 (MainThread): Connection 'master' was left open.
2020-02-04 17:34:10,493176 (MainThread): On master: Close
2020-02-04 17:34:10,493400 (MainThread): Connection 'seed.demo_pipeline.npi_small_2019' was left open.
2020-02-04 17:34:10,493603 (MainThread): On seed.demo_pipeline.npi_small_2019: Close
2020-02-04 17:34:10,507013 (MainThread): 
2020-02-04 17:34:10,507205 (MainThread): Random sample of table: public.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:34:10,507314 (MainThread): -----------------------------------------------------------
2020-02-04 17:34:10,507574 (MainThread): 
2020-02-04 17:34:10,507764 (MainThread): 
2020-02-04 17:34:10,507874 (MainThread): Random sample of table: public.abbr-name-list
2020-02-04 17:34:10,507972 (MainThread): ---------------------------------------------
2020-02-04 17:34:10,508174 (MainThread): 
2020-02-04 17:34:10,528508 (MainThread): 
2020-02-04 17:34:10,528750 (MainThread): Random sample of table: public.npi_small_2019
2020-02-04 17:34:10,529206 (MainThread): ---------------------------------------------
2020-02-04 17:34:10,595567 (MainThread): 
2020-02-04 17:34:10,596006 (MainThread): 
2020-02-04 17:34:10,596140 (MainThread): Completed successfully
2020-02-04 17:34:10,596256 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-02-04 17:34:10,596480 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128140610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128152090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12814ae90>]}
2020-02-04 17:34:10,716818 (MainThread): Flushing usage events
2020-02-04 17:34:48,784039 (MainThread): Running with dbt=0.15.1
2020-02-04 17:34:48,813897 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-04 17:34:48,843537 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=True, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-04 17:34:48,844002 (MainThread): Tracking: tracking
2020-02-04 17:34:48,857215 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f313810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f313a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11f313910>]}
2020-02-04 17:34:49,27212 (MainThread): Partial parsing not enabled
2020-02-04 17:34:49,29103 (MainThread): Parsing macros/core.sql
2020-02-04 17:34:49,32204 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-04 17:34:49,37042 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-04 17:34:49,38547 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-04 17:34:49,49539 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-04 17:34:49,62504 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-04 17:34:49,73873 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-04 17:34:49,75152 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-04 17:34:49,79325 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-04 17:34:49,83576 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-04 17:34:49,87938 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-04 17:34:49,91620 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-04 17:34:49,94624 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-04 17:34:49,95346 (MainThread): Parsing macros/etc/query.sql
2020-02-04 17:34:49,96102 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-04 17:34:49,97224 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-04 17:34:49,98536 (MainThread): Parsing macros/etc/datetime.sql
2020-02-04 17:34:49,104140 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-04 17:34:49,105483 (MainThread): Parsing macros/adapters/common.sql
2020-02-04 17:34:49,123706 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-04 17:34:49,124671 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-04 17:34:49,125340 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-04 17:34:49,126082 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-04 17:34:49,127527 (MainThread): Parsing macros/catalog.sql
2020-02-04 17:34:49,128694 (MainThread): Parsing macros/relations.sql
2020-02-04 17:34:49,129730 (MainThread): Parsing macros/adapters.sql
2020-02-04 17:34:49,136477 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-04 17:34:49,150850 (MainThread): Partial parsing not enabled
2020-02-04 17:34:49,162387 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:49,162527 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,175893 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:49,176034 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,181798 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:49,181876 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,186788 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:49,186919 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,191355 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:49,191455 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,195618 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:49,195702 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,199394 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:49,199476 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,231604 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-04 17:34:49,231747 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,241436 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-04 17:34:49,241601 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,250041 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-04 17:34:49,250131 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,255451 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-04 17:34:49,255542 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,306744 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-04 17:34:49,312600 (MainThread): 
2020-02-04 17:34:49,312949 (MainThread): Acquiring new postgres connection "master".
2020-02-04 17:34:49,313033 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:49,386099 (MainThread): Using postgres connection "master".
2020-02-04 17:34:49,386243 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-04 17:34:49,393090 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-04 17:34:49,438119 (MainThread): Using postgres connection "master".
2020-02-04 17:34:49,438270 (MainThread): On master: BEGIN
2020-02-04 17:34:49,438573 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:49,438663 (MainThread): Using postgres connection "master".
2020-02-04 17:34:49,438721 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-04 17:34:49,440538 (MainThread): SQL status: SELECT 10 in 0.00 seconds
2020-02-04 17:34:49,481868 (MainThread): Using postgres connection "master".
2020-02-04 17:34:49,482002 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-04 17:34:49,494081 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-04 17:34:49,499337 (MainThread): On master: ROLLBACK
2020-02-04 17:34:49,499568 (MainThread): Using postgres connection "master".
2020-02-04 17:34:49,499667 (MainThread): On master: BEGIN
2020-02-04 17:34:49,499945 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:49,500075 (MainThread): On master: COMMIT
2020-02-04 17:34:49,500156 (MainThread): Using postgres connection "master".
2020-02-04 17:34:49,500225 (MainThread): On master: COMMIT
2020-02-04 17:34:49,500375 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:49,500642 (MainThread): 12:34:49 | Concurrency: 1 threads (target='dev')
2020-02-04 17:34:49,500761 (MainThread): 12:34:49 | 
2020-02-04 17:34:49,502065 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:34:49,502223 (Thread-1): 12:34:49 | 1 of 3 START seed file public.HEALTHCARE_PROVIDER_TAXONOMY........... [RUN]
2020-02-04 17:34:49,502469 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:49,502551 (Thread-1): Opening a new connection, currently in state init
2020-02-04 17:34:49,502651 (Thread-1): finished collecting timing info
2020-02-04 17:34:49,551270 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:49,551474 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: BEGIN
2020-02-04 17:34:49,559671 (Thread-1): SQL status: BEGIN in 0.01 seconds
2020-02-04 17:34:49,559880 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:49,559965 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"} */
truncate table "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-04 17:34:49,561849 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:34:49,563318 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-04 17:34:49,577172 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:49,577684 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: 
            insert into "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s...
2020-02-04 17:34:49,582620 (Thread-1): SQL status: INSERT 0 521 in 0.00 seconds
2020-02-04 17:34:49,583004 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-04 17:34:49,583994 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-04 17:34:49,584084 (Thread-1): Using postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-04 17:34:49,584157 (Thread-1): On seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY: COMMIT
2020-02-04 17:34:49,588618 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:49,591603 (Thread-1): finished collecting timing info
2020-02-04 17:34:49,592180 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7f16d07-cdc4-4afe-a7e0-2a621bbd231b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12055d710>]}
2020-02-04 17:34:49,740351 (Thread-1): 12:34:49 | 1 of 3 OK loaded seed file public.HEALTHCARE_PROVIDER_TAXONOMY....... [INSERT 521 in 0.09s]
2020-02-04 17:34:49,740685 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:34:49,740953 (Thread-1): Began running node seed.demo_pipeline.abbr-name-list
2020-02-04 17:34:49,741229 (Thread-1): 12:34:49 | 2 of 3 START seed file public.abbr-name-list......................... [RUN]
2020-02-04 17:34:49,741738 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:49,741886 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY).
2020-02-04 17:34:49,742029 (Thread-1): finished collecting timing info
2020-02-04 17:34:49,748034 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:49,748165 (Thread-1): On seed.demo_pipeline.abbr-name-list: BEGIN
2020-02-04 17:34:49,748614 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:49,748734 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:49,748831 (Thread-1): On seed.demo_pipeline.abbr-name-list: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.abbr-name-list"} */
truncate table "demo_db"."public"."abbr-name-list"
2020-02-04 17:34:49,750173 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:34:49,753345 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:49,753468 (Thread-1): On seed.demo_pipeline.abbr-name-list: 
            insert into "demo_db"."public"."abbr-name-list" (name, abbreviation) values
            (%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s...
2020-02-04 17:34:49,754172 (Thread-1): SQL status: INSERT 0 59 in 0.00 seconds
2020-02-04 17:34:49,754483 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.abbr-name-list"
2020-02-04 17:34:49,755615 (Thread-1): On seed.demo_pipeline.abbr-name-list: COMMIT
2020-02-04 17:34:49,755736 (Thread-1): Using postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-04 17:34:49,755834 (Thread-1): On seed.demo_pipeline.abbr-name-list: COMMIT
2020-02-04 17:34:49,760521 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:49,764417 (Thread-1): finished collecting timing info
2020-02-04 17:34:49,765314 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7f16d07-cdc4-4afe-a7e0-2a621bbd231b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1204d33d0>]}
2020-02-04 17:34:49,907048 (Thread-1): 12:34:49 | 2 of 3 OK loaded seed file public.abbr-name-list..................... [INSERT 59 in 0.02s]
2020-02-04 17:34:49,907383 (Thread-1): Finished running node seed.demo_pipeline.abbr-name-list
2020-02-04 17:34:49,907637 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-04 17:34:49,907903 (Thread-1): 12:34:49 | 3 of 3 START seed file public.npi_small_2019......................... [RUN]
2020-02-04 17:34:49,908487 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:49,908631 (Thread-1): Re-using an available connection from the pool (formerly seed.demo_pipeline.abbr-name-list).
2020-02-04 17:34:49,908777 (Thread-1): finished collecting timing info
2020-02-04 17:34:50,329294 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:50,329448 (Thread-1): On seed.demo_pipeline.npi_small_2019: BEGIN
2020-02-04 17:34:50,329813 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:50,329894 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:50,329958 (Thread-1): On seed.demo_pipeline.npi_small_2019: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "seed.demo_pipeline.npi_small_2019"} */
truncate table "demo_db"."public"."npi_small_2019"
2020-02-04 17:34:50,331003 (Thread-1): SQL status: TRUNCATE TABLE in 0.00 seconds
2020-02-04 17:34:50,579010 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:50,579187 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-04 17:34:50,697433 (Thread-1): SQL status: INSERT 0 10000 in 0.12 seconds
2020-02-04 17:34:50,931599 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:50,931773 (Thread-1): On seed.demo_pipeline.npi_small_2019: 
            insert into "demo_db"."public"."npi_small_2019" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-04 17:34:51,25380 (Thread-1): SQL status: INSERT 0 8649 in 0.09 seconds
2020-02-04 17:34:51,26830 (Thread-1): Writing runtime SQL for node "seed.demo_pipeline.npi_small_2019"
2020-02-04 17:34:51,28043 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-04 17:34:51,28148 (Thread-1): Using postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-04 17:34:51,28230 (Thread-1): On seed.demo_pipeline.npi_small_2019: COMMIT
2020-02-04 17:34:51,33943 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-02-04 17:34:51,37856 (Thread-1): finished collecting timing info
2020-02-04 17:34:51,38736 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b7f16d07-cdc4-4afe-a7e0-2a621bbd231b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1206af390>]}
2020-02-04 17:34:51,190148 (Thread-1): 12:34:51 | 3 of 3 OK loaded seed file public.npi_small_2019..................... [INSERT 18649 in 1.13s]
2020-02-04 17:34:51,190490 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-04 17:34:51,193770 (MainThread): Using postgres connection "master".
2020-02-04 17:34:51,194006 (MainThread): On master: BEGIN
2020-02-04 17:34:51,194342 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:51,194532 (MainThread): On master: COMMIT
2020-02-04 17:34:51,194642 (MainThread): Using postgres connection "master".
2020-02-04 17:34:51,194741 (MainThread): On master: COMMIT
2020-02-04 17:34:51,195070 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:51,195404 (MainThread): 12:34:51 | 
2020-02-04 17:34:51,195588 (MainThread): 12:34:51 | Finished running 3 seeds in 1.88s.
2020-02-04 17:34:51,195746 (MainThread): Connection 'master' was left open.
2020-02-04 17:34:51,195905 (MainThread): On master: Close
2020-02-04 17:34:51,196056 (MainThread): Connection 'seed.demo_pipeline.npi_small_2019' was left open.
2020-02-04 17:34:51,196180 (MainThread): On seed.demo_pipeline.npi_small_2019: Close
2020-02-04 17:34:51,206952 (MainThread): 
2020-02-04 17:34:51,207128 (MainThread): Random sample of table: public.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-04 17:34:51,207237 (MainThread): -----------------------------------------------------------
2020-02-04 17:34:51,207498 (MainThread): 
2020-02-04 17:34:51,207716 (MainThread): 
2020-02-04 17:34:51,207860 (MainThread): Random sample of table: public.abbr-name-list
2020-02-04 17:34:51,207967 (MainThread): ---------------------------------------------
2020-02-04 17:34:51,208172 (MainThread): 
2020-02-04 17:34:51,230242 (MainThread): 
2020-02-04 17:34:51,230469 (MainThread): Random sample of table: public.npi_small_2019
2020-02-04 17:34:51,230582 (MainThread): ---------------------------------------------
2020-02-04 17:34:51,291087 (MainThread): 
2020-02-04 17:34:51,291613 (MainThread): 
2020-02-04 17:34:51,291751 (MainThread): Completed successfully
2020-02-04 17:34:51,291865 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-02-04 17:34:51,292066 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120940b90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c9eb50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120943350>]}
2020-02-04 17:34:51,424676 (MainThread): Flushing usage events
2020-02-04 17:34:57,16880 (MainThread): Running with dbt=0.15.1
2020-02-04 17:34:57,47077 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-04 17:34:57,76030 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-04 17:34:57,76512 (MainThread): Tracking: tracking
2020-02-04 17:34:57,90219 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120080d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd69710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120080d10>]}
2020-02-04 17:34:57,264206 (MainThread): Partial parsing not enabled
2020-02-04 17:34:57,266048 (MainThread): Parsing macros/core.sql
2020-02-04 17:34:57,269412 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-04 17:34:57,274424 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-04 17:34:57,275624 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-04 17:34:57,286716 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-04 17:34:57,299703 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-04 17:34:57,311380 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-04 17:34:57,312726 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-04 17:34:57,317092 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-04 17:34:57,321472 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-04 17:34:57,325258 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-04 17:34:57,329215 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-04 17:34:57,332396 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-04 17:34:57,333076 (MainThread): Parsing macros/etc/query.sql
2020-02-04 17:34:57,333870 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-04 17:34:57,335054 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-04 17:34:57,336624 (MainThread): Parsing macros/etc/datetime.sql
2020-02-04 17:34:57,341931 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-04 17:34:57,343157 (MainThread): Parsing macros/adapters/common.sql
2020-02-04 17:34:57,360601 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-04 17:34:57,361391 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-04 17:34:57,362134 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-04 17:34:57,362866 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-04 17:34:57,364308 (MainThread): Parsing macros/catalog.sql
2020-02-04 17:34:57,365453 (MainThread): Parsing macros/relations.sql
2020-02-04 17:34:57,366526 (MainThread): Parsing macros/adapters.sql
2020-02-04 17:34:57,374064 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-04 17:34:57,388555 (MainThread): Partial parsing not enabled
2020-02-04 17:34:57,398973 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:57,399096 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,411863 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:57,411999 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,417847 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,417935 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,422365 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,422458 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,426642 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:57,426733 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,431179 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:57,431292 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,435147 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:57,435231 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,464575 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-04 17:34:57,464708 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,472491 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-04 17:34:57,472583 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,480229 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-04 17:34:57,480322 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,485138 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-04 17:34:57,485219 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,542507 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-04 17:34:57,548610 (MainThread): 
2020-02-04 17:34:57,548999 (MainThread): Acquiring new postgres connection "master".
2020-02-04 17:34:57,549097 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:34:57,623289 (MainThread): Using postgres connection "master".
2020-02-04 17:34:57,623459 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-04 17:34:57,628215 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-04 17:34:57,672129 (MainThread): Using postgres connection "master".
2020-02-04 17:34:57,672284 (MainThread): On master: BEGIN
2020-02-04 17:34:57,672616 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:57,672692 (MainThread): Using postgres connection "master".
2020-02-04 17:34:57,672752 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-04 17:34:57,674902 (MainThread): SQL status: SELECT 10 in 0.00 seconds
2020-02-04 17:34:57,719398 (MainThread): Using postgres connection "master".
2020-02-04 17:34:57,719550 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-04 17:34:57,732415 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-04 17:34:57,737930 (MainThread): On master: ROLLBACK
2020-02-04 17:34:57,738207 (MainThread): Using postgres connection "master".
2020-02-04 17:34:57,738312 (MainThread): On master: BEGIN
2020-02-04 17:34:57,738609 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:57,738727 (MainThread): On master: COMMIT
2020-02-04 17:34:57,738821 (MainThread): Using postgres connection "master".
2020-02-04 17:34:57,738901 (MainThread): On master: COMMIT
2020-02-04 17:34:57,739072 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:57,739391 (MainThread): 12:34:57 | Concurrency: 1 threads (target='dev')
2020-02-04 17:34:57,739527 (MainThread): 12:34:57 | 
2020-02-04 17:34:57,741167 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-04 17:34:57,741362 (Thread-1): 12:34:57 | 1 of 7 START view model public.stg_npi............................... [RUN]
2020-02-04 17:34:57,741682 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,741827 (Thread-1): Opening a new connection, currently in state init
2020-02-04 17:34:57,741957 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-04 17:34:57,752214 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-04 17:34:57,752599 (Thread-1): finished collecting timing info
2020-02-04 17:34:57,785467 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,785617 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-04 17:34:57,789102 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:57,791266 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,791368 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-04 17:34:57,791557 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:57,792768 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-04 17:34:57,793115 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,793201 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-04 17:34:57,793445 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:57,793529 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,793599 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-04 17:34:57,795252 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:34:57,798404 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,798504 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-04 17:34:57,798872 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:57,800673 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,800762 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-04 17:34:57,801012 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:57,801694 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-04 17:34:57,801777 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,801848 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-04 17:34:57,802311 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:57,803835 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:34:57,803941 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-04 17:34:57,804830 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:57,806698 (Thread-1): finished collecting timing info
2020-02-04 17:34:57,807241 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121236410>]}
2020-02-04 17:34:57,928309 (Thread-1): 12:34:57 | 1 of 7 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.07s]
2020-02-04 17:34:57,928624 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-04 17:34:57,928816 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:34:57,929011 (Thread-1): 12:34:57 | 2 of 7 START view model public.stg_state_crosswalk................... [RUN]
2020-02-04 17:34:57,929402 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,929536 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-04 17:34:57,929663 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:34:57,937024 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-04 17:34:57,937646 (Thread-1): finished collecting timing info
2020-02-04 17:34:57,944144 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,944262 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-04 17:34:57,944599 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:57,946859 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,947058 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-04 17:34:57,947400 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:57,950420 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-04 17:34:57,950963 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,951083 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-04 17:34:57,951300 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:57,951409 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,951506 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	name as state,
	abbreviation as state_abbrev
from "demo_db"."public"."abbr-name-list"
  );

2020-02-04 17:34:57,953512 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:34:57,957448 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,957563 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-04 17:34:57,957957 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:57,960026 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,960125 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-04 17:34:57,960407 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:57,961239 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-04 17:34:57,961346 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,961425 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-04 17:34:57,961830 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:57,964112 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:34:57,964281 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-04 17:34:57,965233 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:57,967567 (Thread-1): finished collecting timing info
2020-02-04 17:34:57,968132 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12143e310>]}
2020-02-04 17:34:58,107377 (Thread-1): 12:34:58 | 2 of 7 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-04 17:34:58,107699 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:34:58,107951 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-04 17:34:58,108216 (Thread-1): 12:34:58 | 3 of 7 START view model public.stg_taxonomy.......................... [RUN]
2020-02-04 17:34:58,108835 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,108983 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-04 17:34:58,109114 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-04 17:34:58,116926 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-04 17:34:58,117407 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,124302 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,124429 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-04 17:34:58,124960 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,128429 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,128615 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-04 17:34:58,128929 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,131863 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-04 17:34:58,132426 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,132546 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-04 17:34:58,132788 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:58,132894 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,132981 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-04 17:34:58,133686 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:34:58,137649 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,137766 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-04 17:34:58,138107 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,140326 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,140429 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-04 17:34:58,140734 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,142534 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-04 17:34:58,142664 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,142749 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-04 17:34:58,143165 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:58,144903 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:34:58,145017 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-04 17:34:58,145721 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,148577 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,149381 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121236f90>]}
2020-02-04 17:34:58,296920 (Thread-1): 12:34:58 | 3 of 7 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-04 17:34:58,297248 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-04 17:34:58,297514 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-04 17:34:58,298038 (Thread-1): 12:34:58 | 4 of 7 START table model public.my_first_dbt_model................... [RUN]
2020-02-04 17:34:58,298846 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,299092 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-04 17:34:58,299326 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-04 17:34:58,308386 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-04 17:34:58,308813 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,324783 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,324915 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-04 17:34:58,325281 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:34:58,327028 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,327117 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-04 17:34:58,327336 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:34:58,328678 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-04 17:34:58,329112 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,329203 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-04 17:34:58,329541 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:58,329658 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,329727 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-04 17:34:58,330666 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-04 17:34:58,335298 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,335446 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-04 17:34:58,335886 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,337747 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,337834 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-04 17:34:58,338243 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,338943 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-04 17:34:58,339034 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,339105 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-04 17:34:58,339405 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:58,340645 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:34:58,340724 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-04 17:34:58,341987 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:34:58,343903 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,344396 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121469950>]}
2020-02-04 17:34:58,490570 (Thread-1): 12:34:58 | 4 of 7 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.05s]
2020-02-04 17:34:58,490881 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-04 17:34:58,491072 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:34:58,491263 (Thread-1): 12:34:58 | 5 of 7 START view model public.npi_with_crosswalks................... [RUN]
2020-02-04 17:34:58,491810 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,491954 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-04 17:34:58,492087 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:34:58,502942 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-04 17:34:58,503529 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,512109 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,512296 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-04 17:34:58,512634 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,515334 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,515510 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-04 17:34:58,515855 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,517518 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-04 17:34:58,518048 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,518167 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-04 17:34:58,518396 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:58,518495 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,518573 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_name
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-04 17:34:58,519836 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:34:58,522422 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,522601 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
alter table "demo_db"."public"."npi_with_crosswalks__dbt_tmp" rename to "npi_with_crosswalks"
2020-02-04 17:34:58,523159 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,524219 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-04 17:34:58,524341 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,524425 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-04 17:34:58,524873 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:58,526590 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:34:58,526715 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-04 17:34:58,527003 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,529389 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,530023 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121402d90>]}
2020-02-04 17:34:58,646696 (Thread-1): 12:34:58 | 5 of 7 OK created view model public.npi_with_crosswalks.............. [CREATE VIEW in 0.04s]
2020-02-04 17:34:58,647069 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:34:58,647347 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-04 17:34:58,647607 (Thread-1): 12:34:58 | 6 of 7 START view model public.my_second_dbt_model................... [RUN]
2020-02-04 17:34:58,648126 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,648272 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.npi_with_crosswalks).
2020-02-04 17:34:58,648405 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-04 17:34:58,656747 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-04 17:34:58,657315 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,664724 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,664934 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-04 17:34:58,665350 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,667870 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,668002 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-04 17:34:58,668513 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,670244 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-04 17:34:58,670778 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,670893 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-04 17:34:58,671189 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:58,671314 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,671403 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-04 17:34:58,672234 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:34:58,676728 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,676918 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-04 17:34:58,677446 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,678593 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-04 17:34:58,678755 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,678842 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-04 17:34:58,679294 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:58,681119 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:34:58,681262 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-04 17:34:58,681520 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,683852 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,684478 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121236f10>]}
2020-02-04 17:34:58,821108 (Thread-1): 12:34:58 | 6 of 7 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-04 17:34:58,821424 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-04 17:34:58,821704 (Thread-1): Began running node model.demo_pipeline.count_specialties
2020-02-04 17:34:58,821965 (Thread-1): 12:34:58 | 7 of 7 START view model public.count_specialties..................... [RUN]
2020-02-04 17:34:58,822545 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,822683 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-04 17:34:58,822809 (Thread-1): Compiling model.demo_pipeline.count_specialties
2020-02-04 17:34:58,831542 (Thread-1): Writing injected SQL for node "model.demo_pipeline.count_specialties"
2020-02-04 17:34:58,832257 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,841619 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,841818 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_tmp" cascade
2020-02-04 17:34:58,842156 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,845501 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,845711 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-04 17:34:58,846067 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,848899 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.count_specialties"
2020-02-04 17:34:58,849833 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,849981 (Thread-1): On model.demo_pipeline.count_specialties: BEGIN
2020-02-04 17:34:58,850342 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:58,850474 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,850568 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */

  
  create view "demo_db"."public"."count_specialties__dbt_tmp" as (
    select 
	provider_taxonomy_description,
	state as state_long,
	count(distinct npi)
from "demo_db"."public"."npi_with_crosswalks" n
group by 1, 2
  );

2020-02-04 17:34:58,852213 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:34:58,854816 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,854950 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
alter table "demo_db"."public"."count_specialties__dbt_tmp" rename to "count_specialties"
2020-02-04 17:34:58,855365 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:34:58,856237 (Thread-1): On model.demo_pipeline.count_specialties: COMMIT
2020-02-04 17:34:58,856347 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,856448 (Thread-1): On model.demo_pipeline.count_specialties: COMMIT
2020-02-04 17:34:58,856839 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:58,858552 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:34:58,858661 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-04 17:34:58,858872 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:34:58,861218 (Thread-1): finished collecting timing info
2020-02-04 17:34:58,861808 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0459f284-9222-4141-afe2-cb03d2a062ef', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121469710>]}
2020-02-04 17:34:58,996054 (Thread-1): 12:34:58 | 7 of 7 OK created view model public.count_specialties................ [CREATE VIEW in 0.04s]
2020-02-04 17:34:58,996290 (Thread-1): Finished running node model.demo_pipeline.count_specialties
2020-02-04 17:34:59,76170 (MainThread): Using postgres connection "master".
2020-02-04 17:34:59,76554 (MainThread): On master: BEGIN
2020-02-04 17:34:59,77232 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:34:59,77568 (MainThread): On master: COMMIT
2020-02-04 17:34:59,77816 (MainThread): Using postgres connection "master".
2020-02-04 17:34:59,78034 (MainThread): On master: COMMIT
2020-02-04 17:34:59,78642 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:34:59,79451 (MainThread): 12:34:59 | 
2020-02-04 17:34:59,79802 (MainThread): 12:34:59 | Finished running 6 view models, 1 table model in 1.53s.
2020-02-04 17:34:59,80104 (MainThread): Connection 'master' was left open.
2020-02-04 17:34:59,80331 (MainThread): On master: Close
2020-02-04 17:34:59,80622 (MainThread): Connection 'model.demo_pipeline.count_specialties' was left open.
2020-02-04 17:34:59,80848 (MainThread): On model.demo_pipeline.count_specialties: Close
2020-02-04 17:34:59,103720 (MainThread): 
2020-02-04 17:34:59,103983 (MainThread): Completed successfully
2020-02-04 17:34:59,104173 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2020-02-04 17:34:59,104389 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1212ee490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1212eef50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1212dfad0>]}
2020-02-04 17:34:59,258123 (MainThread): Flushing usage events
2020-02-04 17:35:36,616234 (MainThread): Running with dbt=0.15.1
2020-02-04 17:35:36,646880 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-04 17:35:36,677630 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-04 17:35:36,678102 (MainThread): Tracking: tracking
2020-02-04 17:35:36,694372 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11caeeed0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11caeec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11caeead0>]}
2020-02-04 17:35:36,912865 (MainThread): Partial parsing not enabled
2020-02-04 17:35:36,915229 (MainThread): Parsing macros/core.sql
2020-02-04 17:35:36,919400 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-04 17:35:36,925238 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-04 17:35:36,927343 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-04 17:35:36,939090 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-04 17:35:36,952520 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-04 17:35:36,964345 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-04 17:35:36,966275 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-04 17:35:36,971333 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-04 17:35:36,976395 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-04 17:35:36,980435 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-04 17:35:36,984335 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-04 17:35:36,987535 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-04 17:35:36,988700 (MainThread): Parsing macros/etc/query.sql
2020-02-04 17:35:36,989905 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-04 17:35:36,991530 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-04 17:35:36,993205 (MainThread): Parsing macros/etc/datetime.sql
2020-02-04 17:35:36,998561 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-04 17:35:37,285 (MainThread): Parsing macros/adapters/common.sql
2020-02-04 17:35:37,18691 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-04 17:35:37,19878 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-04 17:35:37,20925 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-04 17:35:37,22166 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-04 17:35:37,24563 (MainThread): Parsing macros/catalog.sql
2020-02-04 17:35:37,26853 (MainThread): Parsing macros/relations.sql
2020-02-04 17:35:37,28599 (MainThread): Parsing macros/adapters.sql
2020-02-04 17:35:37,35959 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-04 17:35:37,50997 (MainThread): Partial parsing not enabled
2020-02-04 17:35:37,61861 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:37,61975 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,75689 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:37,75871 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,83521 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,83689 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,89098 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,89199 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,95874 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,96172 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,107327 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,107548 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,115245 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:37,115486 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,154360 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-04 17:35:37,154512 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,163352 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-04 17:35:37,163463 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,172596 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-04 17:35:37,172749 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,178098 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-04 17:35:37,178188 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,232674 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-04 17:35:37,240562 (MainThread): 
2020-02-04 17:35:37,240978 (MainThread): Acquiring new postgres connection "master".
2020-02-04 17:35:37,241072 (MainThread): Opening a new connection, currently in state init
2020-02-04 17:35:37,313382 (MainThread): Using postgres connection "master".
2020-02-04 17:35:37,313545 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-04 17:35:37,317595 (MainThread): SQL status: SELECT 6 in 0.00 seconds
2020-02-04 17:35:37,359894 (MainThread): Using postgres connection "master".
2020-02-04 17:35:37,360051 (MainThread): On master: BEGIN
2020-02-04 17:35:37,361559 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:37,361777 (MainThread): Using postgres connection "master".
2020-02-04 17:35:37,361889 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-04 17:35:37,364240 (MainThread): SQL status: SELECT 12 in 0.00 seconds
2020-02-04 17:35:37,411910 (MainThread): Using postgres connection "master".
2020-02-04 17:35:37,412088 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-04 17:35:37,429629 (MainThread): SQL status: SELECT 8 in 0.02 seconds
2020-02-04 17:35:37,437940 (MainThread): On master: ROLLBACK
2020-02-04 17:35:37,438346 (MainThread): Using postgres connection "master".
2020-02-04 17:35:37,438439 (MainThread): On master: BEGIN
2020-02-04 17:35:37,438743 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:37,438839 (MainThread): On master: COMMIT
2020-02-04 17:35:37,438914 (MainThread): Using postgres connection "master".
2020-02-04 17:35:37,438993 (MainThread): On master: COMMIT
2020-02-04 17:35:37,439118 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:37,439375 (MainThread): 12:35:37 | Concurrency: 1 threads (target='dev')
2020-02-04 17:35:37,439482 (MainThread): 12:35:37 | 
2020-02-04 17:35:37,442616 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-04 17:35:37,442843 (Thread-1): 12:35:37 | 1 of 7 START view model public.stg_npi............................... [RUN]
2020-02-04 17:35:37,443137 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,443217 (Thread-1): Opening a new connection, currently in state init
2020-02-04 17:35:37,443304 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-04 17:35:37,453091 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-04 17:35:37,453454 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,482156 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,482330 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-04 17:35:37,485653 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,488061 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,488246 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-04 17:35:37,488507 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,489740 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_npi"
2020-02-04 17:35:37,490108 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,490193 (Thread-1): On model.demo_pipeline.stg_npi: BEGIN
2020-02-04 17:35:37,490385 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:37,490467 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,490537 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."npi_small_2019"
  );

2020-02-04 17:35:37,492439 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:35:37,495613 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,495708 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-04 17:35:37,496096 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,498155 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,498256 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
alter table "demo_db"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-04 17:35:37,498622 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,499306 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-04 17:35:37,499391 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,499461 (Thread-1): On model.demo_pipeline.stg_npi: COMMIT
2020-02-04 17:35:37,499961 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:37,501569 (Thread-1): Using postgres connection "model.demo_pipeline.stg_npi".
2020-02-04 17:35:37,501675 (Thread-1): On model.demo_pipeline.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-04 17:35:37,503126 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,505200 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,505743 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc5d090>]}
2020-02-04 17:35:37,626698 (Thread-1): 12:35:37 | 1 of 7 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.06s]
2020-02-04 17:35:37,627028 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-04 17:35:37,627335 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:35:37,627791 (Thread-1): 12:35:37 | 2 of 7 START view model public.stg_state_crosswalk................... [RUN]
2020-02-04 17:35:37,628262 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,628396 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_npi).
2020-02-04 17:35:37,628523 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:35:37,636350 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-04 17:35:37,636842 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,643500 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,643638 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-04 17:35:37,644005 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,648800 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,649025 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-04 17:35:37,649396 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,651806 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-04 17:35:37,652322 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,652438 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: BEGIN
2020-02-04 17:35:37,652670 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:37,652773 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,652857 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	name as state,
	abbreviation as state_abbrev
from "demo_db"."public"."abbr-name-list"
  );

2020-02-04 17:35:37,653485 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:35:37,657147 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,657254 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk" rename to "stg_state_crosswalk__dbt_backup"
2020-02-04 17:35:37,657573 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,659625 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,659722 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
alter table "demo_db"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-04 17:35:37,659984 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,660713 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-04 17:35:37,660809 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,660888 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: COMMIT
2020-02-04 17:35:37,661290 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:37,662887 (Thread-1): Using postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-04 17:35:37,662993 (Thread-1): On model.demo_pipeline.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-04 17:35:37,663675 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,666049 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,666704 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11de59050>]}
2020-02-04 17:35:37,783541 (Thread-1): 12:35:37 | 2 of 7 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-04 17:35:37,783882 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-04 17:35:37,784153 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-04 17:35:37,784505 (Thread-1): 12:35:37 | 3 of 7 START view model public.stg_taxonomy.......................... [RUN]
2020-02-04 17:35:37,785201 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,785591 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_state_crosswalk).
2020-02-04 17:35:37,785794 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-04 17:35:37,793985 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-04 17:35:37,794525 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,802763 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,802961 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-04 17:35:37,803325 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,805945 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,806075 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-04 17:35:37,806392 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,807983 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-04 17:35:37,808418 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,808526 (Thread-1): On model.demo_pipeline.stg_taxonomy: BEGIN
2020-02-04 17:35:37,808715 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:37,808820 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,808908 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	*
from "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  );

2020-02-04 17:35:37,809579 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:35:37,813351 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,813464 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy" rename to "stg_taxonomy__dbt_backup"
2020-02-04 17:35:37,813790 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,816764 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,816870 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
alter table "demo_db"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-04 17:35:37,817266 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,818146 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-04 17:35:37,818257 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,818413 (Thread-1): On model.demo_pipeline.stg_taxonomy: COMMIT
2020-02-04 17:35:37,819193 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:37,821267 (Thread-1): Using postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-04 17:35:37,821370 (Thread-1): On model.demo_pipeline.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-04 17:35:37,822196 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:37,824502 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,825082 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc5b7d0>]}
2020-02-04 17:35:37,939564 (Thread-1): 12:35:37 | 3 of 7 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.04s]
2020-02-04 17:35:37,939909 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-04 17:35:37,940165 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-04 17:35:37,940409 (Thread-1): 12:35:37 | 4 of 7 START table model public.my_first_dbt_model................... [RUN]
2020-02-04 17:35:37,940954 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,941103 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.stg_taxonomy).
2020-02-04 17:35:37,941238 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-04 17:35:37,952128 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-04 17:35:37,952668 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,972398 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,972575 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_tmp" cascade
2020-02-04 17:35:37,973090 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:35:37,975135 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,975229 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-04 17:35:37,975484 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:35:37,976728 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-04 17:35:37,977057 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,977143 (Thread-1): On model.demo_pipeline.my_first_dbt_model: BEGIN
2020-02-04 17:35:37,977346 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:37,977453 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,977532 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */


  create  table "demo_db"."public"."my_first_dbt_model__dbt_tmp"
  as (
    /*
    Welcome to your first dbt model!
    Did you know that you can also configure models directly within SQL files?
    This will override configurations stated in dbt_project.yml

    Try changing "table" to "view" below
*/



with source_data as (

    select 1 as id
    union all
    select null as id

)

select *
from source_data

/*
    Uncomment the line below to remove records with null `id` values
*/

-- where id is not null
  );
2020-02-04 17:35:37,978362 (Thread-1): SQL status: SELECT 2 in 0.00 seconds
2020-02-04 17:35:37,981367 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,981453 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model" rename to "my_first_dbt_model__dbt_backup"
2020-02-04 17:35:37,981763 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,983504 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,983590 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
alter table "demo_db"."public"."my_first_dbt_model__dbt_tmp" rename to "my_first_dbt_model"
2020-02-04 17:35:37,983892 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:37,984605 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-04 17:35:37,984689 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,984758 (Thread-1): On model.demo_pipeline.my_first_dbt_model: COMMIT
2020-02-04 17:35:37,985227 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:37,986620 (Thread-1): Using postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-04 17:35:37,986704 (Thread-1): On model.demo_pipeline.my_first_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_first_dbt_model"} */
drop table if exists "demo_db"."public"."my_first_dbt_model__dbt_backup" cascade
2020-02-04 17:35:37,988158 (Thread-1): SQL status: DROP TABLE in 0.00 seconds
2020-02-04 17:35:37,990054 (Thread-1): finished collecting timing info
2020-02-04 17:35:37,990560 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dcd1e90>]}
2020-02-04 17:35:38,104830 (Thread-1): 12:35:38 | 4 of 7 OK created table model public.my_first_dbt_model.............. [SELECT 2 in 0.05s]
2020-02-04 17:35:38,105169 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-04 17:35:38,105423 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:35:38,105660 (Thread-1): 12:35:38 | 5 of 7 START view model public.npi_with_crosswalks................... [RUN]
2020-02-04 17:35:38,106290 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,106434 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_first_dbt_model).
2020-02-04 17:35:38,106565 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:35:38,119703 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-04 17:35:38,120221 (Thread-1): finished collecting timing info
2020-02-04 17:35:38,127332 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,127476 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-04 17:35:38,127817 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,130175 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,130290 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-04 17:35:38,130551 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,132250 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-04 17:35:38,132719 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,132839 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: BEGIN
2020-02-04 17:35:38,133096 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:38,133239 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,133336 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */

  
  create view "demo_db"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_name
from "demo_db"."public"."stg_npi" n
left join "demo_db"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "demo_db"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-04 17:35:38,135025 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:35:38,138411 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,138576 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
alter table "demo_db"."public"."npi_with_crosswalks__dbt_tmp" rename to "npi_with_crosswalks"
2020-02-04 17:35:38,139047 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:38,139967 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-04 17:35:38,140080 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,140171 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: COMMIT
2020-02-04 17:35:38,140591 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:38,142406 (Thread-1): Using postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-04 17:35:38,142515 (Thread-1): On model.demo_pipeline.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.npi_with_crosswalks"} */
drop view if exists "demo_db"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-04 17:35:38,142792 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,145046 (Thread-1): finished collecting timing info
2020-02-04 17:35:38,145642 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc23f10>]}
2020-02-04 17:35:38,285648 (Thread-1): 12:35:38 | 5 of 7 OK created view model public.npi_with_crosswalks.............. [CREATE VIEW in 0.04s]
2020-02-04 17:35:38,285973 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-04 17:35:38,286232 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-04 17:35:38,286491 (Thread-1): 12:35:38 | 6 of 7 START view model public.my_second_dbt_model................... [RUN]
2020-02-04 17:35:38,286942 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,287075 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.npi_with_crosswalks).
2020-02-04 17:35:38,287208 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-04 17:35:38,295525 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-04 17:35:38,296219 (Thread-1): finished collecting timing info
2020-02-04 17:35:38,304914 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,305101 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_tmp" cascade
2020-02-04 17:35:38,305450 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,307935 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,308084 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-04 17:35:38,308389 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,311255 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-04 17:35:38,311756 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,311878 (Thread-1): On model.demo_pipeline.my_second_dbt_model: BEGIN
2020-02-04 17:35:38,312120 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:38,312228 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,312316 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */

  
  create view "demo_db"."public"."my_second_dbt_model__dbt_tmp" as (
    -- Use the `ref` function to select from other models

select *
from "demo_db"."public"."my_first_dbt_model"
where id = 1
  );

2020-02-04 17:35:38,313011 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:35:38,315469 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,315585 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
alter table "demo_db"."public"."my_second_dbt_model__dbt_tmp" rename to "my_second_dbt_model"
2020-02-04 17:35:38,315932 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:38,316828 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-04 17:35:38,316940 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,317039 (Thread-1): On model.demo_pipeline.my_second_dbt_model: COMMIT
2020-02-04 17:35:38,317459 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:38,319341 (Thread-1): Using postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-04 17:35:38,319464 (Thread-1): On model.demo_pipeline.my_second_dbt_model: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.my_second_dbt_model"} */
drop view if exists "demo_db"."public"."my_second_dbt_model__dbt_backup" cascade
2020-02-04 17:35:38,319748 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,322123 (Thread-1): finished collecting timing info
2020-02-04 17:35:38,322770 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11deb2f50>]}
2020-02-04 17:35:38,449066 (Thread-1): 12:35:38 | 6 of 7 OK created view model public.my_second_dbt_model.............. [CREATE VIEW in 0.04s]
2020-02-04 17:35:38,449403 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-04 17:35:38,449654 (Thread-1): Began running node model.demo_pipeline.count_specialties
2020-02-04 17:35:38,449906 (Thread-1): 12:35:38 | 7 of 7 START view model public.count_specialties..................... [RUN]
2020-02-04 17:35:38,450518 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,450658 (Thread-1): Re-using an available connection from the pool (formerly model.demo_pipeline.my_second_dbt_model).
2020-02-04 17:35:38,450792 (Thread-1): Compiling model.demo_pipeline.count_specialties
2020-02-04 17:35:38,458289 (Thread-1): Writing injected SQL for node "model.demo_pipeline.count_specialties"
2020-02-04 17:35:38,458761 (Thread-1): finished collecting timing info
2020-02-04 17:35:38,466802 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,466986 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_tmp" cascade
2020-02-04 17:35:38,467305 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,470661 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,470905 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-04 17:35:38,471353 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,473187 (Thread-1): Writing runtime SQL for node "model.demo_pipeline.count_specialties"
2020-02-04 17:35:38,473731 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,473853 (Thread-1): On model.demo_pipeline.count_specialties: BEGIN
2020-02-04 17:35:38,474083 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:38,474187 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,474271 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */

  
  create view "demo_db"."public"."count_specialties__dbt_tmp" as (
    select 
	provider_taxonomy_description,
	state_name,
	count(distinct npi)
from "demo_db"."public"."npi_with_crosswalks" n
group by 1, 2
  );

2020-02-04 17:35:38,475771 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-04 17:35:38,478276 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,478418 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
alter table "demo_db"."public"."count_specialties__dbt_tmp" rename to "count_specialties"
2020-02-04 17:35:38,478823 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-04 17:35:38,479694 (Thread-1): On model.demo_pipeline.count_specialties: COMMIT
2020-02-04 17:35:38,479811 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,479892 (Thread-1): On model.demo_pipeline.count_specialties: COMMIT
2020-02-04 17:35:38,480287 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:38,481931 (Thread-1): Using postgres connection "model.demo_pipeline.count_specialties".
2020-02-04 17:35:38,482025 (Thread-1): On model.demo_pipeline.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "node_id": "model.demo_pipeline.count_specialties"} */
drop view if exists "demo_db"."public"."count_specialties__dbt_backup" cascade
2020-02-04 17:35:38,482260 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-04 17:35:38,484569 (Thread-1): finished collecting timing info
2020-02-04 17:35:38,485245 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6331dc83-14b5-41ce-aefe-7550c747f5c1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11deb2d50>]}
2020-02-04 17:35:38,601784 (Thread-1): 12:35:38 | 7 of 7 OK created view model public.count_specialties................ [CREATE VIEW in 0.03s]
2020-02-04 17:35:38,602134 (Thread-1): Finished running node model.demo_pipeline.count_specialties
2020-02-04 17:35:38,683739 (MainThread): Using postgres connection "master".
2020-02-04 17:35:38,684161 (MainThread): On master: BEGIN
2020-02-04 17:35:38,685008 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-04 17:35:38,685357 (MainThread): On master: COMMIT
2020-02-04 17:35:38,685614 (MainThread): Using postgres connection "master".
2020-02-04 17:35:38,685816 (MainThread): On master: COMMIT
2020-02-04 17:35:38,686199 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-04 17:35:38,686740 (MainThread): 12:35:38 | 
2020-02-04 17:35:38,686989 (MainThread): 12:35:38 | Finished running 6 view models, 1 table model in 1.45s.
2020-02-04 17:35:38,687262 (MainThread): Connection 'master' was left open.
2020-02-04 17:35:38,687406 (MainThread): On master: Close
2020-02-04 17:35:38,687564 (MainThread): Connection 'model.demo_pipeline.count_specialties' was left open.
2020-02-04 17:35:38,687755 (MainThread): On model.demo_pipeline.count_specialties: Close
2020-02-04 17:35:38,709575 (MainThread): 
2020-02-04 17:35:38,709784 (MainThread): Completed successfully
2020-02-04 17:35:38,709922 (MainThread): 
Done. PASS=7 WARN=0 ERROR=0 SKIP=0 TOTAL=7
2020-02-04 17:35:38,710181 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11de90c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc4fb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dc4f0d0>]}
2020-02-04 17:35:38,829213 (MainThread): Flushing usage events
2020-02-05 15:26:24,449831 (MainThread): Running with dbt=0.15.1
2020-02-05 15:26:24,489289 (MainThread): The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use "pip install psycopg2-binary" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.
2020-02-05 15:26:24,533583 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.generate.GenerateTask'>, compile=True, debug=False, exclude=None, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='docs.generate', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='generate', write_json=True)
2020-02-05 15:26:24,534454 (MainThread): Tracking: tracking
2020-02-05 15:26:24,569107 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12925ce90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128f449d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12925ca50>]}
2020-02-05 15:26:24,802521 (MainThread): Partial parsing not enabled
2020-02-05 15:26:24,805398 (MainThread): Parsing macros/core.sql
2020-02-05 15:26:24,808667 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-05 15:26:24,814660 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-05 15:26:24,816894 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-05 15:26:24,831211 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-05 15:26:24,848370 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-05 15:26:24,861935 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-05 15:26:24,863777 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-05 15:26:24,869461 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-05 15:26:24,875516 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-05 15:26:24,881051 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-05 15:26:24,885850 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-05 15:26:24,889965 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-05 15:26:24,891205 (MainThread): Parsing macros/etc/query.sql
2020-02-05 15:26:24,892326 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-05 15:26:24,893823 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-05 15:26:24,895845 (MainThread): Parsing macros/etc/datetime.sql
2020-02-05 15:26:24,905177 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-05 15:26:24,907185 (MainThread): Parsing macros/adapters/common.sql
2020-02-05 15:26:24,931505 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-05 15:26:24,932903 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-05 15:26:24,934128 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-05 15:26:24,935503 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-05 15:26:24,938148 (MainThread): Parsing macros/catalog.sql
2020-02-05 15:26:24,939720 (MainThread): Parsing macros/relations.sql
2020-02-05 15:26:24,941073 (MainThread): Parsing macros/adapters.sql
2020-02-05 15:26:24,950694 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-05 15:26:24,970528 (MainThread): Partial parsing not enabled
2020-02-05 15:26:24,985268 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-05 15:26:24,985420 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,4648 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-05 15:26:25,4788 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,12091 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-05 15:26:25,12274 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,18387 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-05 15:26:25,18513 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,24647 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-05 15:26:25,24840 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,37697 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-05 15:26:25,37851 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,43124 (MainThread): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-05 15:26:25,43245 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,82154 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-05 15:26:25,82389 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,92809 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-05 15:26:25,92941 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,107859 (MainThread): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-05 15:26:25,108032 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,115315 (MainThread): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-05 15:26:25,115457 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,187396 (MainThread): Found 7 models, 4 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-05 15:26:25,193380 (MainThread): 
2020-02-05 15:26:25,193588 (MainThread): 10:26:25 | Concurrency: 1 threads (target='dev')
2020-02-05 15:26:25,193754 (MainThread): 10:26:25 | 
2020-02-05 15:26:25,195745 (Thread-1): Began running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-05 15:26:25,196159 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY".
2020-02-05 15:26:25,196258 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,196354 (Thread-1): Compiling seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-05 15:26:25,208919 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,209493 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,210263 (Thread-1): Finished running node seed.demo_pipeline.HEALTHCARE_PROVIDER_TAXONOMY
2020-02-05 15:26:25,210433 (Thread-1): Began running node seed.demo_pipeline.abbr-name-list
2020-02-05 15:26:25,210812 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.abbr-name-list".
2020-02-05 15:26:25,210959 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,211073 (Thread-1): Compiling seed.demo_pipeline.abbr-name-list
2020-02-05 15:26:25,216229 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,216758 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,217160 (Thread-1): Finished running node seed.demo_pipeline.abbr-name-list
2020-02-05 15:26:25,217373 (Thread-1): Began running node seed.demo_pipeline.npi_small_2019
2020-02-05 15:26:25,217922 (Thread-1): Acquiring new postgres connection "seed.demo_pipeline.npi_small_2019".
2020-02-05 15:26:25,218168 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,218379 (Thread-1): Compiling seed.demo_pipeline.npi_small_2019
2020-02-05 15:26:25,223588 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,223872 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,224233 (Thread-1): Finished running node seed.demo_pipeline.npi_small_2019
2020-02-05 15:26:25,224353 (Thread-1): Began running node model.demo_pipeline.my_first_dbt_model
2020-02-05 15:26:25,224825 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_first_dbt_model".
2020-02-05 15:26:25,224943 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,225037 (Thread-1): Compiling model.demo_pipeline.my_first_dbt_model
2020-02-05 15:26:25,239997 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_first_dbt_model"
2020-02-05 15:26:25,240529 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,241087 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,241719 (Thread-1): Finished running node model.demo_pipeline.my_first_dbt_model
2020-02-05 15:26:25,241844 (Thread-1): Began running node model.demo_pipeline.stg_taxonomy
2020-02-05 15:26:25,242401 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-05 15:26:25,242878 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,243571 (Thread-1): Compiling model.demo_pipeline.stg_taxonomy
2020-02-05 15:26:25,250166 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_taxonomy"
2020-02-05 15:26:25,250772 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,251249 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,251748 (Thread-1): Finished running node model.demo_pipeline.stg_taxonomy
2020-02-05 15:26:25,251876 (Thread-1): Began running node model.demo_pipeline.stg_state_crosswalk
2020-02-05 15:26:25,252147 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-05 15:26:25,252249 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,252338 (Thread-1): Compiling model.demo_pipeline.stg_state_crosswalk
2020-02-05 15:26:25,257955 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_state_crosswalk"
2020-02-05 15:26:25,258318 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,258539 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,258924 (Thread-1): Finished running node model.demo_pipeline.stg_state_crosswalk
2020-02-05 15:26:25,259054 (Thread-1): Began running node model.demo_pipeline.stg_npi
2020-02-05 15:26:25,259525 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-05 15:26:25,259627 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,259711 (Thread-1): Compiling model.demo_pipeline.stg_npi
2020-02-05 15:26:25,268201 (Thread-1): Writing injected SQL for node "model.demo_pipeline.stg_npi"
2020-02-05 15:26:25,268857 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,269466 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,269983 (Thread-1): Finished running node model.demo_pipeline.stg_npi
2020-02-05 15:26:25,270130 (Thread-1): Began running node model.demo_pipeline.my_second_dbt_model
2020-02-05 15:26:25,270362 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.my_second_dbt_model".
2020-02-05 15:26:25,270606 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,270782 (Thread-1): Compiling model.demo_pipeline.my_second_dbt_model
2020-02-05 15:26:25,277133 (Thread-1): Writing injected SQL for node "model.demo_pipeline.my_second_dbt_model"
2020-02-05 15:26:25,277509 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,277729 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,278141 (Thread-1): Finished running node model.demo_pipeline.my_second_dbt_model
2020-02-05 15:26:25,278271 (Thread-1): Began running node test.demo_pipeline.not_null_my_first_dbt_model_id
2020-02-05 15:26:25,278577 (Thread-1): Acquiring new postgres connection "test.demo_pipeline.not_null_my_first_dbt_model_id".
2020-02-05 15:26:25,278695 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,278959 (Thread-1): Compiling test.demo_pipeline.not_null_my_first_dbt_model_id
2020-02-05 15:26:25,292795 (Thread-1): Writing injected SQL for node "test.demo_pipeline.not_null_my_first_dbt_model_id"
2020-02-05 15:26:25,293269 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,293540 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,293865 (Thread-1): Finished running node test.demo_pipeline.not_null_my_first_dbt_model_id
2020-02-05 15:26:25,293983 (Thread-1): Began running node test.demo_pipeline.unique_my_first_dbt_model_id
2020-02-05 15:26:25,294223 (Thread-1): Acquiring new postgres connection "test.demo_pipeline.unique_my_first_dbt_model_id".
2020-02-05 15:26:25,294495 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,294630 (Thread-1): Compiling test.demo_pipeline.unique_my_first_dbt_model_id
2020-02-05 15:26:25,303149 (Thread-1): Writing injected SQL for node "test.demo_pipeline.unique_my_first_dbt_model_id"
2020-02-05 15:26:25,303645 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,304023 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,304601 (Thread-1): Finished running node test.demo_pipeline.unique_my_first_dbt_model_id
2020-02-05 15:26:25,304959 (Thread-1): Began running node model.demo_pipeline.npi_with_crosswalks
2020-02-05 15:26:25,305578 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-05 15:26:25,306143 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,306336 (Thread-1): Compiling model.demo_pipeline.npi_with_crosswalks
2020-02-05 15:26:25,316378 (Thread-1): Writing injected SQL for node "model.demo_pipeline.npi_with_crosswalks"
2020-02-05 15:26:25,316916 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,317462 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,318036 (Thread-1): Finished running node model.demo_pipeline.npi_with_crosswalks
2020-02-05 15:26:25,318356 (Thread-1): Began running node test.demo_pipeline.not_null_my_second_dbt_model_id
2020-02-05 15:26:25,318679 (Thread-1): Acquiring new postgres connection "test.demo_pipeline.not_null_my_second_dbt_model_id".
2020-02-05 15:26:25,318763 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,318843 (Thread-1): Compiling test.demo_pipeline.not_null_my_second_dbt_model_id
2020-02-05 15:26:25,327645 (Thread-1): Writing injected SQL for node "test.demo_pipeline.not_null_my_second_dbt_model_id"
2020-02-05 15:26:25,328645 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,328999 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,329385 (Thread-1): Finished running node test.demo_pipeline.not_null_my_second_dbt_model_id
2020-02-05 15:26:25,329506 (Thread-1): Began running node test.demo_pipeline.unique_my_second_dbt_model_id
2020-02-05 15:26:25,329727 (Thread-1): Acquiring new postgres connection "test.demo_pipeline.unique_my_second_dbt_model_id".
2020-02-05 15:26:25,329810 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,329888 (Thread-1): Compiling test.demo_pipeline.unique_my_second_dbt_model_id
2020-02-05 15:26:25,337328 (Thread-1): Writing injected SQL for node "test.demo_pipeline.unique_my_second_dbt_model_id"
2020-02-05 15:26:25,337668 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,337960 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,338308 (Thread-1): Finished running node test.demo_pipeline.unique_my_second_dbt_model_id
2020-02-05 15:26:25,338422 (Thread-1): Began running node model.demo_pipeline.count_specialties
2020-02-05 15:26:25,338714 (Thread-1): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-05 15:26:25,338931 (Thread-1): Opening a new connection, currently in state init
2020-02-05 15:26:25,339039 (Thread-1): Compiling model.demo_pipeline.count_specialties
2020-02-05 15:26:25,345094 (Thread-1): Writing injected SQL for node "model.demo_pipeline.count_specialties"
2020-02-05 15:26:25,345899 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,346373 (Thread-1): finished collecting timing info
2020-02-05 15:26:25,346847 (Thread-1): Finished running node model.demo_pipeline.count_specialties
2020-02-05 15:26:25,408577 (MainThread): Connection 'test.demo_pipeline.not_null_my_second_dbt_model_id' was properly closed.
2020-02-05 15:26:25,408882 (MainThread): Connection 'model.demo_pipeline.count_specialties' was properly closed.
2020-02-05 15:26:25,440961 (MainThread): 10:26:25 | Done.
2020-02-05 15:26:25,447154 (MainThread): Acquiring new postgres connection "generate_catalog".
2020-02-05 15:26:25,447336 (MainThread): Opening a new connection, currently in state init
2020-02-05 15:26:25,447542 (MainThread): 10:26:25 | Building catalog
2020-02-05 15:26:25,617741 (MainThread): Using postgres connection "generate_catalog".
2020-02-05 15:26:25,617985 (MainThread): On generate_catalog: BEGIN
2020-02-05 15:26:25,640258 (MainThread): SQL status: BEGIN in 0.02 seconds
2020-02-05 15:26:25,640452 (MainThread): Using postgres connection "generate_catalog".
2020-02-05 15:26:25,640539 (MainThread): On generate_catalog: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "demo_pipeline", "target_name": "dev", "connection_name": "generate_catalog"} */

    
    

    select
        'demo_db' as table_database,
        sch.nspname as table_schema,
        tbl.relname as table_name,
        case tbl.relkind
            when 'v' then 'VIEW'
            else 'BASE TABLE'
        end as table_type,
        null::text as table_comment,
        col.attname as column_name,
        col.attnum as column_index,
        pg_catalog.format_type(col.atttypid, col.atttypmod) as column_type,
        null::text as column_comment,
        pg_get_userbyid(tbl.relowner) as table_owner

    from pg_catalog.pg_namespace sch
    join pg_catalog.pg_class tbl on tbl.relnamespace = sch.oid
    join pg_catalog.pg_attribute col on col.attrelid = tbl.oid

    where sch.nspname != 'information_schema'
      and sch.nspname not like 'pg\_%' -- avoid postgres system schemas, '_' is a wildcard so escape it
      and not pg_is_other_temp_schema(sch.oid) -- not a temporary schema belonging to another session
      and tbl.relpersistence = 'p' -- [p]ermanent table. Other values are [u]nlogged table, [t]emporary table
      and tbl.relkind in ('r', 'v', 'f', 'p') -- o[r]dinary table, [v]iew, [f]oreign table, [p]artitioned table. Other values are [i]ndex, [S]equence, [c]omposite type, [t]OAST table, [m]aterialized view
      and col.attnum > 0 -- negative numbers are used for system columns such as oid
      and not col.attisdropped -- column as not been dropped

    order by
        sch.nspname,
        tbl.relname,
        col.attnum
2020-02-05 15:26:25,653317 (MainThread): SQL status: SELECT 47 in 0.01 seconds
2020-02-05 15:26:25,672668 (MainThread): On generate_catalog: ROLLBACK
2020-02-05 15:26:25,763338 (MainThread): 10:26:25 | Catalog written to /Users/sam/code/demo_pipeline/target/catalog.json
2020-02-05 15:26:25,763879 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1293c9810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12a468f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12a411050>]}
2020-02-05 15:26:25,896567 (MainThread): Flushing usage events
2020-02-05 15:26:25,896799 (MainThread): Connection 'generate_catalog' was left open.
2020-02-05 15:26:25,896889 (MainThread): On generate_catalog: Close
2020-02-05 15:26:54,434156 (MainThread): Running with dbt=0.15.1
2020-02-05 15:26:54,458705 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8080, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-02-05 15:26:54,459061 (MainThread): Tracking: tracking
2020-02-05 15:26:54,475459 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12203d310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109d1bb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122016250>]}
2020-02-05 15:26:54,607739 (MainThread): Serving docs at 0.0.0.0:8080
2020-02-05 15:26:54,607934 (MainThread): To access from your browser, navigate to http://localhost:8080.
2020-02-05 15:26:54,608027 (MainThread): Press Ctrl+C to exit.


2020-02-05 15:26:54,608607 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1217c2d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12205b890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12205b910>]}
2020-02-05 15:26:54,734817 (MainThread): Flushing usage events
2020-02-05 15:26:54,735066 (MainThread): Encountered an error:
2020-02-05 15:26:54,735179 (MainThread): [Errno 48] Address already in use
2020-02-05 15:26:54,738643 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/serve.py", line 30, in run
    SimpleHTTPRequestHandler
  File "/opt/miniconda3/lib/python3.7/socketserver.py", line 452, in __init__
    self.server_bind()
  File "/opt/miniconda3/lib/python3.7/socketserver.py", line 466, in server_bind
    self.socket.bind(self.server_address)
OSError: [Errno 48] Address already in use

2020-02-05 15:30:15,372650 (MainThread): Running with dbt=0.15.1
2020-02-05 15:30:15,402057 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.serve.ServeTask'>, debug=False, log_cache_events=False, log_format='default', partial_parse=None, port=8080, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method=None, single_threaded=False, strict=False, target=None, test_new_parser=False, use_cache=True, vars='{}', warn_error=False, which='serve', write_json=True)
2020-02-05 15:30:15,403004 (MainThread): Tracking: tracking
2020-02-05 15:30:15,424775 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1200ca710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120105290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1200d1f90>]}
2020-02-05 15:30:15,619780 (MainThread): Serving docs at 0.0.0.0:8080
2020-02-05 15:30:15,620087 (MainThread): To access from your browser, navigate to http://localhost:8080.
2020-02-05 15:30:15,620245 (MainThread): Press Ctrl+C to exit.


2020-02-05 15:53:22,74797 (MainThread): Flushing usage events
2020-02-05 15:53:22,75633 (MainThread): ctrl-c
2020-02-27 05:26:20,797383 (MainThread): Running with dbt=0.15.1
2020-02-27 05:26:20,874212 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:26:20,874646 (MainThread): Tracking: tracking
2020-02-27 05:26:20,893031 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12829e590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11be70450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12829e990>]}
2020-02-27 05:26:21,608500 (MainThread): Partial parsing not enabled
2020-02-27 05:26:21,615496 (MainThread): Parsing macros/core.sql
2020-02-27 05:26:21,621600 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:26:21,628863 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:26:21,631394 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:26:21,643824 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:26:21,656523 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:26:21,668950 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:26:21,670593 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:26:21,675232 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:26:21,680194 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:26:21,684815 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:26:21,690047 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:26:21,693964 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:26:21,695045 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:26:21,696313 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:26:21,697910 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:26:21,699534 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:26:21,705157 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:26:21,707089 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:26:21,725908 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:26:21,726976 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:26:21,727892 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:26:21,728878 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:26:21,730789 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:26:21,732614 (MainThread): Parsing macros/relations.sql
2020-02-27 05:26:21,734351 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:26:21,741817 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:26:21,755082 (MainThread): Partial parsing not enabled
2020-02-27 05:26:21,764392 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-27 05:26:21,764471 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:26:21,776043 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-27 05:26:21,776135 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:26:21,781379 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-27 05:26:21,781453 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:26:21,785524 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-27 05:26:21,785637 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:26:21,789574 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-27 05:26:21,789651 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:26:21,812930 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1283b4210>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1283d9f10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1283e5890>]}
2020-02-27 05:26:22,174383 (MainThread): Flushing usage events
2020-02-27 05:26:22,174720 (MainThread): Connection 'model.demo_pipeline.stg_taxonomy' was properly closed.
2020-02-27 05:26:22,174940 (MainThread): Encountered an error:
2020-02-27 05:26:22,175174 (MainThread): Compilation Error in model stg_npi (models/staging/stg_npi.sql)
  Model 'model.demo_pipeline.stg_npi' depends on model 'npi_small_2019' which was not found or is disabled
2020-02-27 05:26:22,180649 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 300, in run
    self._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 81, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 54, in _runtime_initialize
    self.load_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 46, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 441, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 331, in load_all
    manifest = loader.create_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 312, in create_manifest
    manifest, self.root_project.project_name
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 224, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 206, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/utils.py", line 411, in invalid_ref_fail_unless_test
    target_model_package)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 479, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 357, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_npi (models/staging/stg_npi.sql)
  Model 'model.demo_pipeline.stg_npi' depends on model 'npi_small_2019' which was not found or is disabled

2020-02-27 05:29:59,600537 (MainThread): Running with dbt=0.15.1
2020-02-27 05:29:59,671139 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:29:59,671612 (MainThread): Tracking: tracking
2020-02-27 05:29:59,687313 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b75490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b75c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122b75e90>]}
2020-02-27 05:30:00,103068 (MainThread): Partial parsing not enabled
2020-02-27 05:30:00,109355 (MainThread): Parsing macros/core.sql
2020-02-27 05:30:00,114523 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:30:00,121399 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:30:00,123072 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:30:00,136954 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:30:00,153882 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:30:00,170521 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:30:00,172398 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:30:00,179950 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:30:00,186734 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:30:00,192571 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:30:00,197614 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:30:00,201577 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:30:00,202395 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:30:00,203343 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:30:00,204670 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:30:00,206213 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:30:00,211857 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:30:00,213273 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:30:00,231677 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:30:00,232544 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:30:00,233259 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:30:00,234075 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:30:00,235724 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:30:00,236989 (MainThread): Parsing macros/relations.sql
2020-02-27 05:30:00,238123 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:30:00,244801 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:30:00,258109 (MainThread): Partial parsing not enabled
2020-02-27 05:30:00,267764 (MainThread): Acquiring new postgres connection "model.demo_pipeline.count_specialties".
2020-02-27 05:30:00,267858 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:30:00,279898 (MainThread): Acquiring new postgres connection "model.demo_pipeline.npi_with_crosswalks".
2020-02-27 05:30:00,279996 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:30:00,285344 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_npi".
2020-02-27 05:30:00,285420 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:30:00,289098 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_state_crosswalk".
2020-02-27 05:30:00,289172 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:30:00,292837 (MainThread): Acquiring new postgres connection "model.demo_pipeline.stg_taxonomy".
2020-02-27 05:30:00,292915 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:30:00,312037 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123c45a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123c45a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123c80e50>]}
2020-02-27 05:30:00,678218 (MainThread): Flushing usage events
2020-02-27 05:30:00,678558 (MainThread): Connection 'model.demo_pipeline.stg_taxonomy' was properly closed.
2020-02-27 05:30:00,678776 (MainThread): Encountered an error:
2020-02-27 05:30:00,679019 (MainThread): Compilation Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  Model 'model.demo_pipeline.stg_state_crosswalk' depends on model 'state_abbreviatons' which was not found or is disabled
2020-02-27 05:30:00,682138 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 300, in run
    self._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 81, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 54, in _runtime_initialize
    self.load_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 46, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 441, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 331, in load_all
    manifest = loader.create_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 312, in create_manifest
    manifest, self.root_project.project_name
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 224, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 206, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/utils.py", line 411, in invalid_ref_fail_unless_test
    target_model_package)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 479, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 357, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  Model 'model.demo_pipeline.stg_state_crosswalk' depends on model 'state_abbreviatons' which was not found or is disabled

2020-02-27 05:31:11,375957 (MainThread): Running with dbt=0.15.1
2020-02-27 05:31:11,439627 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:31:11,440075 (MainThread): Tracking: tracking
2020-02-27 05:31:11,453043 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ccaa10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ccad10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ccac50>]}
2020-02-27 05:31:11,852670 (MainThread): Partial parsing not enabled
2020-02-27 05:31:11,854291 (MainThread): Parsing macros/core.sql
2020-02-27 05:31:11,857301 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:31:11,861886 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:31:11,863032 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:31:11,873638 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:31:11,886019 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:31:11,897197 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:31:11,898398 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:31:11,902254 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:31:11,906505 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:31:11,910171 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:31:11,914026 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:31:11,917488 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:31:11,918124 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:31:11,918859 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:31:11,919972 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:31:11,921311 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:31:11,926985 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:31:11,928221 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:31:11,945589 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:31:11,946429 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:31:11,947072 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:31:11,947800 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:31:11,949212 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:31:11,950324 (MainThread): Parsing macros/relations.sql
2020-02-27 05:31:11,951339 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:31:11,957772 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:31:11,970588 (MainThread): Partial parsing not enabled
2020-02-27 05:31:11,980240 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:31:11,980334 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:11,992113 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:31:11,992207 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:11,997473 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:31:11,997547 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:12,1741 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:31:12,1820 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:12,5527 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:31:12,5601 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:12,22672 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120d62990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120dcd410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120d99810>]}
2020-02-27 05:31:12,393314 (MainThread): Flushing usage events
2020-02-27 05:31:12,393653 (MainThread): Connection 'model.ge_tutorials.stg_taxonomy' was properly closed.
2020-02-27 05:31:12,393878 (MainThread): Encountered an error:
2020-02-27 05:31:12,394125 (MainThread): Compilation Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  Model 'model.ge_tutorials.stg_state_crosswalk' depends on model 'state_abbreviatons' which was not found or is disabled
2020-02-27 05:31:12,397303 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 300, in run
    self._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 81, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 54, in _runtime_initialize
    self.load_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 46, in load_manifest
    self.manifest = get_full_manifest(self.config)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/perf_utils.py", line 23, in get_full_manifest
    return load_manifest(config, internal, set_header)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 441, in load_manifest
    return ManifestLoader.load_all(config, internal_manifest, macro_hook)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 331, in load_all
    manifest = loader.create_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/manifest.py", line 312, in create_manifest
    manifest, self.root_project.project_name
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 224, in process_refs
    cls.process_refs_for_node(manifest, current_project, node)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/parser/util.py", line 206, in process_refs_for_node
    disabled=(target_model is cls.DISABLED)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/utils.py", line 411, in invalid_ref_fail_unless_test
    target_model_package)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 479, in ref_target_not_found
    raise_compiler_error(msg, model)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 357, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  Model 'model.ge_tutorials.stg_state_crosswalk' depends on model 'state_abbreviatons' which was not found or is disabled

2020-02-27 05:31:30,791643 (MainThread): Running with dbt=0.15.1
2020-02-27 05:31:30,856670 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:31:30,857129 (MainThread): Tracking: tracking
2020-02-27 05:31:30,869968 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b588290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b588f50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b588e10>]}
2020-02-27 05:31:31,361459 (MainThread): Partial parsing not enabled
2020-02-27 05:31:31,363191 (MainThread): Parsing macros/core.sql
2020-02-27 05:31:31,366556 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:31:31,371413 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:31:31,372594 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:31:31,383732 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:31:31,396618 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:31:31,408425 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:31:31,409743 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:31:31,413884 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:31:31,418659 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:31:31,422723 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:31:31,426406 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:31:31,429639 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:31:31,430279 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:31:31,431030 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:31:31,432146 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:31:31,433613 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:31:31,439710 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:31:31,440984 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:31:31,458315 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:31:31,459124 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:31:31,459776 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:31:31,460517 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:31:31,461973 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:31:31,463110 (MainThread): Parsing macros/relations.sql
2020-02-27 05:31:31,464141 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:31:31,470535 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:31:31,483904 (MainThread): Partial parsing not enabled
2020-02-27 05:31:31,494355 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:31:31,494485 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:31,506680 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:31:31,506776 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:31,512551 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:31:31,512644 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:31,516625 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:31:31,516705 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:31,520496 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:31:31,520572 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:31:31,539994 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.ge_tutorials.example

2020-02-27 05:31:31,576071 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11a35f110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c6ddc90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c6dde90>]}
2020-02-27 05:31:32,71952 (MainThread): Flushing usage events
2020-02-27 05:31:32,72236 (MainThread): Connection 'model.ge_tutorials.stg_taxonomy' was properly closed.
2020-02-27 05:31:32,72414 (MainThread): Encountered an error:
2020-02-27 05:31:32,72562 (MainThread): Found a cycle: model.ge_tutorials.stg_taxonomy --> model.ge_tutorials.stg_taxonomy
2020-02-27 05:31:32,74286 (MainThread): Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 80, in main
    results, succeeded = handle_and_check(args)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 158, in handle_and_check
    task, res = run_from_args(parsed)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/main.py", line 210, in run_from_args
    results = task.run()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 300, in run
    self._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 81, in _runtime_initialize
    super()._runtime_initialize()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 55, in _runtime_initialize
    self.compile_manifest()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/task/runnable.py", line 50, in compile_manifest
    self.linker = compile_manifest(self.config, self.manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/compilation.py", line 219, in compile_manifest
    return compiler.compile(manifest, write=write)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/compilation.py", line 200, in compile
    self.link_graph(linker, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/compilation.py", line 195, in link_graph
    raise RuntimeError("Found a cycle: {}".format(cycle))
RuntimeError: Found a cycle: model.ge_tutorials.stg_taxonomy --> model.ge_tutorials.stg_taxonomy

2020-02-27 05:34:40,522847 (MainThread): Running with dbt=0.15.1
2020-02-27 05:34:40,589680 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:34:40,590193 (MainThread): Tracking: tracking
2020-02-27 05:34:40,604415 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122237490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122237d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122237e10>]}
2020-02-27 05:34:41,434065 (MainThread): Partial parsing not enabled
2020-02-27 05:34:41,435776 (MainThread): Parsing macros/core.sql
2020-02-27 05:34:41,438952 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:34:41,443882 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:34:41,445066 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:34:41,455824 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:34:41,468259 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:34:41,479958 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:34:41,481405 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:34:41,485792 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:34:41,490498 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:34:41,494668 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:34:41,498354 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:34:41,501400 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:34:41,502114 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:34:41,502873 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:34:41,504000 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:34:41,505310 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:34:41,511266 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:34:41,512533 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:34:41,531846 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:34:41,532765 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:34:41,533504 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:34:41,534326 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:34:41,535928 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:34:41,537179 (MainThread): Parsing macros/relations.sql
2020-02-27 05:34:41,538312 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:34:41,546233 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:34:41,560477 (MainThread): Partial parsing not enabled
2020-02-27 05:34:41,570477 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:34:41,570639 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:34:41,583516 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:34:41,583633 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:34:41,589056 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:34:41,589134 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:34:41,593033 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:34:41,593113 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:34:41,596822 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:34:41,596896 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:34:41,615082 (MainThread): WARNING: Configuration paths exist in your dbt_project.yml file which do not apply to any resources.
There are 1 unused configuration paths:
- models.ge_tutorials.example

2020-02-27 05:34:41,649808 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-27 05:34:41,652294 (MainThread): 
2020-02-27 05:34:41,652569 (MainThread): Acquiring new postgres connection "master".
2020-02-27 05:34:41,652646 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:34:41,722240 (MainThread): Using postgres connection "master".
2020-02-27 05:34:41,722400 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:34:41,824818 (MainThread): SQL status: SELECT 7 in 0.10 seconds
2020-02-27 05:34:41,854615 (MainThread): Using postgres connection "master".
2020-02-27 05:34:41,854781 (MainThread): On master: BEGIN
2020-02-27 05:34:41,855841 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:34:41,856062 (MainThread): Using postgres connection "master".
2020-02-27 05:34:41,856171 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 05:34:41,884682 (MainThread): SQL status: SELECT 12 in 0.03 seconds
2020-02-27 05:34:41,918972 (MainThread): Using postgres connection "master".
2020-02-27 05:34:41,919100 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 05:34:41,958409 (MainThread): SQL status: SELECT 8 in 0.04 seconds
2020-02-27 05:34:41,967116 (MainThread): On master: ROLLBACK
2020-02-27 05:34:41,967391 (MainThread): Using postgres connection "master".
2020-02-27 05:34:41,967477 (MainThread): On master: BEGIN
2020-02-27 05:34:41,967701 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:34:41,967804 (MainThread): On master: COMMIT
2020-02-27 05:34:41,967890 (MainThread): Using postgres connection "master".
2020-02-27 05:34:41,967962 (MainThread): On master: COMMIT
2020-02-27 05:34:41,968144 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:34:41,968446 (MainThread): 21:34:41 | Concurrency: 1 threads (target='dev')
2020-02-27 05:34:41,968584 (MainThread): 21:34:41 | 
2020-02-27 05:34:41,970432 (Thread-1): Began running node model.ge_tutorials.stg_npi
2020-02-27 05:34:41,970587 (Thread-1): 21:34:41 | 1 of 5 START view model public.stg_npi............................... [RUN]
2020-02-27 05:34:41,970863 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:34:41,970952 (Thread-1): Opening a new connection, currently in state init
2020-02-27 05:34:41,971049 (Thread-1): Compiling model.ge_tutorials.stg_npi
2020-02-27 05:34:41,981920 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 05:34:41,982518 (Thread-1): finished collecting timing info
2020-02-27 05:34:42,9429 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:34:42,9724 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-27 05:34:42,15021 (Thread-1): SQL status: DROP VIEW in 0.01 seconds
2020-02-27 05:34:42,17141 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:34:42,17244 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-27 05:34:42,17426 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:34:42,18610 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 05:34:42,19030 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:34:42,19114 (Thread-1): On model.ge_tutorials.stg_npi: BEGIN
2020-02-27 05:34:42,19287 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:34:42,19366 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:34:42,19431 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	npi,
	entity_type_code,
	organization_name,
	last_name,
	first_name,
	state,
	taxonomy_code
from "demo_db"."public"."npi_small"
  );

2020-02-27 05:34:42,19768 (Thread-1): Postgres error: relation "public.npi_small" does not exist
LINE 13: from "demo_db"."public"."npi_small"
              ^

2020-02-27 05:34:42,19869 (Thread-1): On model.ge_tutorials.stg_npi: ROLLBACK
2020-02-27 05:34:42,20051 (Thread-1): finished collecting timing info
2020-02-27 05:34:42,20394 (Thread-1): Database Error in model stg_npi (models/staging/stg_npi.sql)
  relation "public.npi_small" does not exist
  LINE 13: from "demo_db"."public"."npi_small"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_npi.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.npi_small" does not exist
LINE 13: from "demo_db"."public"."npi_small"
              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_npi (models/staging/stg_npi.sql)
  relation "public.npi_small" does not exist
  LINE 13: from "demo_db"."public"."npi_small"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_npi.sql
2020-02-27 05:34:42,28170 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a0776ef-18c0-41bc-b373-b203aa5e84d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122396710>]}
2020-02-27 05:34:42,408142 (Thread-1): 21:34:42 | 1 of 5 ERROR creating view model public.stg_npi...................... [ERROR in 0.06s]
2020-02-27 05:34:42,408486 (Thread-1): Finished running node model.ge_tutorials.stg_npi
2020-02-27 05:34:42,408768 (Thread-1): Began running node model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:34:42,409033 (Thread-1): 21:34:42 | 2 of 5 START view model public.stg_state_crosswalk................... [RUN]
2020-02-27 05:34:42,409627 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:34:42,409775 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_npi).
2020-02-27 05:34:42,409911 (Thread-1): Compiling model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:34:42,417448 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_state_crosswalk"
2020-02-27 05:34:42,417905 (Thread-1): finished collecting timing info
2020-02-27 05:34:42,424529 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:34:42,424647 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-27 05:34:42,425052 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:34:42,427237 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:34:42,427369 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-27 05:34:42,427632 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:34:42,429366 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_state_crosswalk"
2020-02-27 05:34:42,429896 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:34:42,430010 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: BEGIN
2020-02-27 05:34:42,430291 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:34:42,430396 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:34:42,430480 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	name as state,
	abbreviation as state_abbrev
from "demo_db"."public"."state_abbreviations"
  );

2020-02-27 05:34:42,430763 (Thread-1): Postgres error: relation "public.state_abbreviations" does not exist
LINE 8: from "demo_db"."public"."state_abbreviations"
             ^

2020-02-27 05:34:42,430868 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: ROLLBACK
2020-02-27 05:34:42,431084 (Thread-1): finished collecting timing info
2020-02-27 05:34:42,431537 (Thread-1): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  relation "public.state_abbreviations" does not exist
  LINE 8: from "demo_db"."public"."state_abbreviations"
               ^
  compiled SQL at target/run/ge_tutorials/staging/stg_state_crosswalk.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.state_abbreviations" does not exist
LINE 8: from "demo_db"."public"."state_abbreviations"
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  relation "public.state_abbreviations" does not exist
  LINE 8: from "demo_db"."public"."state_abbreviations"
               ^
  compiled SQL at target/run/ge_tutorials/staging/stg_state_crosswalk.sql
2020-02-27 05:34:42,432096 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a0776ef-18c0-41bc-b373-b203aa5e84d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1237cd090>]}
2020-02-27 05:34:42,806115 (Thread-1): 21:34:42 | 2 of 5 ERROR creating view model public.stg_state_crosswalk.......... [ERROR in 0.02s]
2020-02-27 05:34:42,806463 (Thread-1): Finished running node model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:34:42,806819 (Thread-1): Began running node model.ge_tutorials.stg_taxonomy
2020-02-27 05:34:42,807415 (Thread-1): 21:34:42 | 3 of 5 START view model public.stg_taxonomy.......................... [RUN]
2020-02-27 05:34:42,808123 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:34:42,808268 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_state_crosswalk).
2020-02-27 05:34:42,808403 (Thread-1): Compiling model.ge_tutorials.stg_taxonomy
2020-02-27 05:34:42,816544 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_taxonomy"
2020-02-27 05:34:42,817055 (Thread-1): finished collecting timing info
2020-02-27 05:34:42,824880 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:34:42,825023 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-27 05:34:42,825543 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:34:42,828185 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:34:42,828375 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-27 05:34:42,828752 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:34:42,831173 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_taxonomy"
2020-02-27 05:34:42,832912 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:34:42,833123 (Thread-1): On model.ge_tutorials.stg_taxonomy: BEGIN
2020-02-27 05:34:42,833453 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:34:42,833586 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:34:42,833683 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	medicare_specialty_code,
	medicare_provider_supplier_type_description,
	provider_taxonomy_code,
	provider_taxonomy_description
from "demo_db"."public"."healthcare_provider_taxonomy"
  );

2020-02-27 05:34:42,833971 (Thread-1): Postgres error: relation "public.healthcare_provider_taxonomy" does not exist
LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
              ^

2020-02-27 05:34:42,834085 (Thread-1): On model.ge_tutorials.stg_taxonomy: ROLLBACK
2020-02-27 05:34:42,834326 (Thread-1): finished collecting timing info
2020-02-27 05:34:42,834824 (Thread-1): Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
  relation "public.healthcare_provider_taxonomy" does not exist
  LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_taxonomy.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.healthcare_provider_taxonomy" does not exist
LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
  relation "public.healthcare_provider_taxonomy" does not exist
  LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_taxonomy.sql
2020-02-27 05:34:42,835433 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4a0776ef-18c0-41bc-b373-b203aa5e84d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x123528fd0>]}
2020-02-27 05:34:43,200137 (Thread-1): 21:34:43 | 3 of 5 ERROR creating view model public.stg_taxonomy................. [ERROR in 0.03s]
2020-02-27 05:34:43,200482 (Thread-1): Finished running node model.ge_tutorials.stg_taxonomy
2020-02-27 05:34:43,200973 (Thread-1): Began running node model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:34:43,201172 (Thread-1): 21:34:43 | 4 of 5 SKIP relation public.npi_with_crosswalks...................... [SKIP]
2020-02-27 05:34:43,201337 (Thread-1): Finished running node model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:34:43,201668 (Thread-1): Began running node model.ge_tutorials.count_specialties
2020-02-27 05:34:43,201869 (Thread-1): 21:34:43 | 5 of 5 SKIP relation public.count_specialties........................ [SKIP]
2020-02-27 05:34:43,202035 (Thread-1): Finished running node model.ge_tutorials.count_specialties
2020-02-27 05:34:43,209994 (MainThread): Using postgres connection "master".
2020-02-27 05:34:43,210398 (MainThread): On master: BEGIN
2020-02-27 05:34:43,210988 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:34:43,211189 (MainThread): On master: COMMIT
2020-02-27 05:34:43,211349 (MainThread): Using postgres connection "master".
2020-02-27 05:34:43,211495 (MainThread): On master: COMMIT
2020-02-27 05:34:43,211865 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:34:43,212262 (MainThread): 21:34:43 | 
2020-02-27 05:34:43,212443 (MainThread): 21:34:43 | Finished running 5 view models in 1.56s.
2020-02-27 05:34:43,212592 (MainThread): Connection 'master' was left open.
2020-02-27 05:34:43,212710 (MainThread): On master: Close
2020-02-27 05:34:43,212853 (MainThread): Connection 'model.ge_tutorials.stg_taxonomy' was left open.
2020-02-27 05:34:43,212963 (MainThread): On model.ge_tutorials.stg_taxonomy: Close
2020-02-27 05:34:43,224708 (MainThread): 
2020-02-27 05:34:43,224928 (MainThread): Completed with 3 errors and 0 warnings:
2020-02-27 05:34:43,225187 (MainThread): 
2020-02-27 05:34:43,225352 (MainThread): Database Error in model stg_npi (models/staging/stg_npi.sql)
2020-02-27 05:34:43,225482 (MainThread):   relation "public.npi_small" does not exist
2020-02-27 05:34:43,225618 (MainThread):   LINE 13: from "demo_db"."public"."npi_small"
2020-02-27 05:34:43,225726 (MainThread):                 ^
2020-02-27 05:34:43,225819 (MainThread):   compiled SQL at target/run/ge_tutorials/staging/stg_npi.sql
2020-02-27 05:34:43,225914 (MainThread): 
2020-02-27 05:34:43,226015 (MainThread): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
2020-02-27 05:34:43,226106 (MainThread):   relation "public.state_abbreviations" does not exist
2020-02-27 05:34:43,226190 (MainThread):   LINE 8: from "demo_db"."public"."state_abbreviations"
2020-02-27 05:34:43,226271 (MainThread):                ^
2020-02-27 05:34:43,226352 (MainThread):   compiled SQL at target/run/ge_tutorials/staging/stg_state_crosswalk.sql
2020-02-27 05:34:43,226440 (MainThread): 
2020-02-27 05:34:43,226534 (MainThread): Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
2020-02-27 05:34:43,226621 (MainThread):   relation "public.healthcare_provider_taxonomy" does not exist
2020-02-27 05:34:43,226702 (MainThread):   LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
2020-02-27 05:34:43,226811 (MainThread):                 ^
2020-02-27 05:34:43,226890 (MainThread):   compiled SQL at target/run/ge_tutorials/staging/stg_taxonomy.sql
2020-02-27 05:34:43,226983 (MainThread): 
Done. PASS=2 WARN=0 ERROR=3 SKIP=0 TOTAL=5
2020-02-27 05:34:43,227168 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12352cfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12352c150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12352c3d0>]}
2020-02-27 05:34:43,591321 (MainThread): Flushing usage events
2020-02-27 05:35:11,308312 (MainThread): Running with dbt=0.15.1
2020-02-27 05:35:11,369964 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:35:11,370404 (MainThread): Tracking: tracking
2020-02-27 05:35:11,383051 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12508bcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1161531d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12559f690>]}
2020-02-27 05:35:11,775480 (MainThread): Partial parsing not enabled
2020-02-27 05:35:11,777010 (MainThread): Parsing macros/core.sql
2020-02-27 05:35:11,779767 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:35:11,784214 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:35:11,785363 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:35:11,796358 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:35:11,808766 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:35:11,820182 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:35:11,821426 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:35:11,825432 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:35:11,829768 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:35:11,834149 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:35:11,839262 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:35:11,842667 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:35:11,843370 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:35:11,844197 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:35:11,845436 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:35:11,846865 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:35:11,852822 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:35:11,854068 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:35:11,870601 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:35:11,871371 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:35:11,872005 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:35:11,872733 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:35:11,874261 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:35:11,875457 (MainThread): Parsing macros/relations.sql
2020-02-27 05:35:11,876466 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:35:11,883120 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:35:11,897002 (MainThread): Partial parsing not enabled
2020-02-27 05:35:11,906617 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:35:11,906705 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:11,919297 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:35:11,919438 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:11,925115 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:11,925190 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:11,928936 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:11,929008 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:11,932707 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:11,932777 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:11,979360 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-27 05:35:11,983423 (MainThread): 
2020-02-27 05:35:11,983858 (MainThread): Acquiring new postgres connection "master".
2020-02-27 05:35:11,984017 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:12,57442 (MainThread): Using postgres connection "master".
2020-02-27 05:35:12,57579 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:35:12,102086 (MainThread): SQL status: SELECT 7 in 0.04 seconds
2020-02-27 05:35:12,131488 (MainThread): Using postgres connection "master".
2020-02-27 05:35:12,131624 (MainThread): On master: BEGIN
2020-02-27 05:35:12,131947 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:12,132018 (MainThread): Using postgres connection "master".
2020-02-27 05:35:12,132074 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 05:35:12,133870 (MainThread): SQL status: SELECT 12 in 0.00 seconds
2020-02-27 05:35:12,162491 (MainThread): Using postgres connection "master".
2020-02-27 05:35:12,162611 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 05:35:12,177629 (MainThread): SQL status: SELECT 8 in 0.01 seconds
2020-02-27 05:35:12,187147 (MainThread): On master: ROLLBACK
2020-02-27 05:35:12,187453 (MainThread): Using postgres connection "master".
2020-02-27 05:35:12,187551 (MainThread): On master: BEGIN
2020-02-27 05:35:12,187792 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:12,187895 (MainThread): On master: COMMIT
2020-02-27 05:35:12,187972 (MainThread): Using postgres connection "master".
2020-02-27 05:35:12,188039 (MainThread): On master: COMMIT
2020-02-27 05:35:12,188194 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:35:12,188475 (MainThread): 21:35:12 | Concurrency: 1 threads (target='dev')
2020-02-27 05:35:12,188590 (MainThread): 21:35:12 | 
2020-02-27 05:35:12,190201 (Thread-1): Began running node model.ge_tutorials.stg_npi
2020-02-27 05:35:12,190442 (Thread-1): 21:35:12 | 1 of 5 START view model public.stg_npi............................... [RUN]
2020-02-27 05:35:12,190717 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:12,190797 (Thread-1): Opening a new connection, currently in state init
2020-02-27 05:35:12,190878 (Thread-1): Compiling model.ge_tutorials.stg_npi
2020-02-27 05:35:12,200945 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 05:35:12,201269 (Thread-1): finished collecting timing info
2020-02-27 05:35:12,228898 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:12,229054 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_tmp" cascade
2020-02-27 05:35:12,232408 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:35:12,234671 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:12,234814 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "demo_db"."public"."stg_npi__dbt_backup" cascade
2020-02-27 05:35:12,235101 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:35:12,236623 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 05:35:12,237063 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:12,237152 (Thread-1): On model.ge_tutorials.stg_npi: BEGIN
2020-02-27 05:35:12,237397 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:12,237548 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:12,237666 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */

  
  create view "demo_db"."public"."stg_npi__dbt_tmp" as (
    select 
	npi,
	entity_type_code,
	organization_name,
	last_name,
	first_name,
	state,
	taxonomy_code
from "demo_db"."public"."npi_small"
  );

2020-02-27 05:35:12,238464 (Thread-1): Postgres error: relation "public.npi_small" does not exist
LINE 13: from "demo_db"."public"."npi_small"
              ^

2020-02-27 05:35:12,239543 (Thread-1): On model.ge_tutorials.stg_npi: ROLLBACK
2020-02-27 05:35:12,240816 (Thread-1): finished collecting timing info
2020-02-27 05:35:12,241403 (Thread-1): Database Error in model stg_npi (models/staging/stg_npi.sql)
  relation "public.npi_small" does not exist
  LINE 13: from "demo_db"."public"."npi_small"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_npi.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.npi_small" does not exist
LINE 13: from "demo_db"."public"."npi_small"
              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_npi (models/staging/stg_npi.sql)
  relation "public.npi_small" does not exist
  LINE 13: from "demo_db"."public"."npi_small"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_npi.sql
2020-02-27 05:35:12,242932 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16350c0a-cd9e-4b2c-ae75-7c6df1403918', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126765690>]}
2020-02-27 05:35:12,612109 (Thread-1): 21:35:12 | 1 of 5 ERROR creating view model public.stg_npi...................... [ERROR in 0.05s]
2020-02-27 05:35:12,612437 (Thread-1): Finished running node model.ge_tutorials.stg_npi
2020-02-27 05:35:12,612775 (Thread-1): Began running node model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:35:12,613358 (Thread-1): 21:35:12 | 2 of 5 START view model public.stg_state_crosswalk................... [RUN]
2020-02-27 05:35:12,613990 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:12,614280 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_npi).
2020-02-27 05:35:12,614435 (Thread-1): Compiling model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:35:12,623085 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_state_crosswalk"
2020-02-27 05:35:12,623684 (Thread-1): finished collecting timing info
2020-02-27 05:35:12,630279 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:12,630396 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-27 05:35:12,630820 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:35:12,633664 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:12,633857 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "demo_db"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-27 05:35:12,634286 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:35:12,636871 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_state_crosswalk"
2020-02-27 05:35:12,637605 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:12,637786 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: BEGIN
2020-02-27 05:35:12,638085 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:12,638192 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:12,638272 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */

  
  create view "demo_db"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	name as state,
	abbreviation as state_abbrev
from "demo_db"."public"."state_abbreviations"
  );

2020-02-27 05:35:12,638615 (Thread-1): Postgres error: relation "public.state_abbreviations" does not exist
LINE 8: from "demo_db"."public"."state_abbreviations"
             ^

2020-02-27 05:35:12,638783 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: ROLLBACK
2020-02-27 05:35:12,639135 (Thread-1): finished collecting timing info
2020-02-27 05:35:12,639645 (Thread-1): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  relation "public.state_abbreviations" does not exist
  LINE 8: from "demo_db"."public"."state_abbreviations"
               ^
  compiled SQL at target/run/ge_tutorials/staging/stg_state_crosswalk.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.state_abbreviations" does not exist
LINE 8: from "demo_db"."public"."state_abbreviations"
             ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
  relation "public.state_abbreviations" does not exist
  LINE 8: from "demo_db"."public"."state_abbreviations"
               ^
  compiled SQL at target/run/ge_tutorials/staging/stg_state_crosswalk.sql
2020-02-27 05:35:12,640230 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16350c0a-cd9e-4b2c-ae75-7c6df1403918', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12686a490>]}
2020-02-27 05:35:13,19246 (Thread-1): 21:35:13 | 2 of 5 ERROR creating view model public.stg_state_crosswalk.......... [ERROR in 0.03s]
2020-02-27 05:35:13,19579 (Thread-1): Finished running node model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:35:13,19837 (Thread-1): Began running node model.ge_tutorials.stg_taxonomy
2020-02-27 05:35:13,20091 (Thread-1): 21:35:13 | 3 of 5 START view model public.stg_taxonomy.......................... [RUN]
2020-02-27 05:35:13,20553 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:13,20676 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_state_crosswalk).
2020-02-27 05:35:13,20798 (Thread-1): Compiling model.ge_tutorials.stg_taxonomy
2020-02-27 05:35:13,28236 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_taxonomy"
2020-02-27 05:35:13,28804 (Thread-1): finished collecting timing info
2020-02-27 05:35:13,36506 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:13,36659 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-27 05:35:13,37111 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:35:13,40431 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:13,40666 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "demo_db"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-27 05:35:13,41094 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:35:13,42940 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_taxonomy"
2020-02-27 05:35:13,43511 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:13,43630 (Thread-1): On model.ge_tutorials.stg_taxonomy: BEGIN
2020-02-27 05:35:13,44012 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:13,44133 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:13,44219 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */

  
  create view "demo_db"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	medicare_specialty_code,
	medicare_provider_supplier_type_description,
	provider_taxonomy_code,
	provider_taxonomy_description
from "demo_db"."public"."healthcare_provider_taxonomy"
  );

2020-02-27 05:35:13,44510 (Thread-1): Postgres error: relation "public.healthcare_provider_taxonomy" does not exist
LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
              ^

2020-02-27 05:35:13,44613 (Thread-1): On model.ge_tutorials.stg_taxonomy: ROLLBACK
2020-02-27 05:35:13,44849 (Thread-1): finished collecting timing info
2020-02-27 05:35:13,45323 (Thread-1): Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
  relation "public.healthcare_provider_taxonomy" does not exist
  LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_taxonomy.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedTable: relation "public.healthcare_provider_taxonomy" does not exist
LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
              ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
  relation "public.healthcare_provider_taxonomy" does not exist
  LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
                ^
  compiled SQL at target/run/ge_tutorials/staging/stg_taxonomy.sql
2020-02-27 05:35:13,46119 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '16350c0a-cd9e-4b2c-ae75-7c6df1403918', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12687ec10>]}
2020-02-27 05:35:13,410187 (Thread-1): 21:35:13 | 3 of 5 ERROR creating view model public.stg_taxonomy................. [ERROR in 0.03s]
2020-02-27 05:35:13,410517 (Thread-1): Finished running node model.ge_tutorials.stg_taxonomy
2020-02-27 05:35:13,411171 (Thread-1): Began running node model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:35:13,411380 (Thread-1): 21:35:13 | 4 of 5 SKIP relation public.npi_with_crosswalks...................... [SKIP]
2020-02-27 05:35:13,411545 (Thread-1): Finished running node model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:35:13,411879 (Thread-1): Began running node model.ge_tutorials.count_specialties
2020-02-27 05:35:13,412073 (Thread-1): 21:35:13 | 5 of 5 SKIP relation public.count_specialties........................ [SKIP]
2020-02-27 05:35:13,412235 (Thread-1): Finished running node model.ge_tutorials.count_specialties
2020-02-27 05:35:13,416797 (MainThread): Using postgres connection "master".
2020-02-27 05:35:13,417045 (MainThread): On master: BEGIN
2020-02-27 05:35:13,417392 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:13,417542 (MainThread): On master: COMMIT
2020-02-27 05:35:13,417656 (MainThread): Using postgres connection "master".
2020-02-27 05:35:13,417759 (MainThread): On master: COMMIT
2020-02-27 05:35:13,418025 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:35:13,418402 (MainThread): 21:35:13 | 
2020-02-27 05:35:13,418583 (MainThread): 21:35:13 | Finished running 5 view models in 1.43s.
2020-02-27 05:35:13,418701 (MainThread): Connection 'master' was left open.
2020-02-27 05:35:13,418789 (MainThread): On master: Close
2020-02-27 05:35:13,418899 (MainThread): Connection 'model.ge_tutorials.stg_taxonomy' was left open.
2020-02-27 05:35:13,418983 (MainThread): On model.ge_tutorials.stg_taxonomy: Close
2020-02-27 05:35:13,429984 (MainThread): 
2020-02-27 05:35:13,430260 (MainThread): Completed with 3 errors and 0 warnings:
2020-02-27 05:35:13,430390 (MainThread): 
2020-02-27 05:35:13,430552 (MainThread): Database Error in model stg_npi (models/staging/stg_npi.sql)
2020-02-27 05:35:13,430688 (MainThread):   relation "public.npi_small" does not exist
2020-02-27 05:35:13,430783 (MainThread):   LINE 13: from "demo_db"."public"."npi_small"
2020-02-27 05:35:13,430868 (MainThread):                 ^
2020-02-27 05:35:13,430953 (MainThread):   compiled SQL at target/run/ge_tutorials/staging/stg_npi.sql
2020-02-27 05:35:13,431044 (MainThread): 
2020-02-27 05:35:13,431148 (MainThread): Database Error in model stg_state_crosswalk (models/staging/stg_state_crosswalk.sql)
2020-02-27 05:35:13,431235 (MainThread):   relation "public.state_abbreviations" does not exist
2020-02-27 05:35:13,431313 (MainThread):   LINE 8: from "demo_db"."public"."state_abbreviations"
2020-02-27 05:35:13,431429 (MainThread):                ^
2020-02-27 05:35:13,431567 (MainThread):   compiled SQL at target/run/ge_tutorials/staging/stg_state_crosswalk.sql
2020-02-27 05:35:13,431674 (MainThread): 
2020-02-27 05:35:13,431795 (MainThread): Database Error in model stg_taxonomy (models/staging/stg_taxonomy.sql)
2020-02-27 05:35:13,431896 (MainThread):   relation "public.healthcare_provider_taxonomy" does not exist
2020-02-27 05:35:13,432052 (MainThread):   LINE 10: from "demo_db"."public"."healthcare_provider_taxonomy"
2020-02-27 05:35:13,432155 (MainThread):                 ^
2020-02-27 05:35:13,432244 (MainThread):   compiled SQL at target/run/ge_tutorials/staging/stg_taxonomy.sql
2020-02-27 05:35:13,432345 (MainThread): 
Done. PASS=2 WARN=0 ERROR=3 SKIP=0 TOTAL=5
2020-02-27 05:35:13,432539 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x125033850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126888e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126888c90>]}
2020-02-27 05:35:13,811362 (MainThread): Flushing usage events
2020-02-27 05:35:24,638504 (MainThread): Running with dbt=0.15.1
2020-02-27 05:35:24,702132 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-27 05:35:24,702581 (MainThread): Tracking: tracking
2020-02-27 05:35:24,716634 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd22490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e5b1290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11fd22ed0>]}
2020-02-27 05:35:25,113696 (MainThread): Partial parsing not enabled
2020-02-27 05:35:25,115256 (MainThread): Parsing macros/core.sql
2020-02-27 05:35:25,118090 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:35:25,122717 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:35:25,123876 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:35:25,134772 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:35:25,147397 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:35:25,158216 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:35:25,159535 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:35:25,163462 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:35:25,168119 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:35:25,171939 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:35:25,175969 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:35:25,179329 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:35:25,179986 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:35:25,180725 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:35:25,181836 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:35:25,183132 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:35:25,189044 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:35:25,190315 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:35:25,206791 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:35:25,207565 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:35:25,208514 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:35:25,209259 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:35:25,210732 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:35:25,211854 (MainThread): Parsing macros/relations.sql
2020-02-27 05:35:25,212963 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:35:25,219507 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:35:25,232420 (MainThread): Partial parsing not enabled
2020-02-27 05:35:25,242018 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:35:25,242110 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:25,254309 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:35:25,254416 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:25,260131 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:35:25,260213 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:25,263893 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:35:25,263966 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:25,267602 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:35:25,267674 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:25,315531 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-27 05:35:25,320007 (MainThread): 
2020-02-27 05:35:25,320360 (MainThread): Acquiring new postgres connection "master".
2020-02-27 05:35:25,320449 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:35:25,392035 (MainThread): Using postgres connection "master".
2020-02-27 05:35:25,392197 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:35:25,396668 (MainThread): SQL status: SELECT 7 in 0.00 seconds
2020-02-27 05:35:25,424328 (MainThread): Using postgres connection "master".
2020-02-27 05:35:25,424467 (MainThread): On master: BEGIN
2020-02-27 05:35:25,424779 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:25,424851 (MainThread): Using postgres connection "master".
2020-02-27 05:35:25,424908 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'demo_db' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'demo_db' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 05:35:25,426688 (MainThread): SQL status: SELECT 12 in 0.00 seconds
2020-02-27 05:35:25,454873 (MainThread): Using postgres connection "master".
2020-02-27 05:35:25,454980 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 05:35:25,473106 (MainThread): SQL status: SELECT 8 in 0.02 seconds
2020-02-27 05:35:25,481605 (MainThread): On master: ROLLBACK
2020-02-27 05:35:25,481901 (MainThread): Using postgres connection "master".
2020-02-27 05:35:25,482008 (MainThread): On master: BEGIN
2020-02-27 05:35:25,482422 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:25,482524 (MainThread): On master: COMMIT
2020-02-27 05:35:25,482593 (MainThread): Using postgres connection "master".
2020-02-27 05:35:25,482653 (MainThread): On master: COMMIT
2020-02-27 05:35:25,482852 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:35:25,483120 (MainThread): 21:35:25 | Concurrency: 1 threads (target='dev')
2020-02-27 05:35:25,483224 (MainThread): 21:35:25 | 
2020-02-27 05:35:25,484931 (Thread-1): Began running node seed.ge_tutorials.healthcare_provider_taxonomy
2020-02-27 05:35:25,485111 (Thread-1): 21:35:25 | 1 of 3 START seed file public.healthcare_provider_taxonomy........... [RUN]
2020-02-27 05:35:25,485412 (Thread-1): Acquiring new postgres connection "seed.ge_tutorials.healthcare_provider_taxonomy".
2020-02-27 05:35:25,485490 (Thread-1): Opening a new connection, currently in state init
2020-02-27 05:35:25,485588 (Thread-1): finished collecting timing info
2020-02-27 05:35:25,519763 (Thread-1): finished collecting timing info
2020-02-27 05:35:25,520167 (Thread-1): Compilation Error in seed healthcare_provider_taxonomy (data/healthcare_provider_taxonomy.csv)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY", or rename it to be less ambiguous.
  Searched for: "demo_db"."public"."healthcare_provider_taxonomy"
  Found: "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  
  > in macro materialization_seed_default (macros/materializations/seed/seed.sql)
  > called by seed healthcare_provider_taxonomy (data/healthcare_provider_taxonomy.csv)
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 376, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 732, in get_relation
    identifier)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 720, in _make_match
    if relation.matches(**search):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/relation.py", line 207, in matches
    dbt.exceptions.approximate_relation_match(target, self)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 636, in approximate_relation_match
    relation=relation))
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/exceptions.py", line 357, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in seed healthcare_provider_taxonomy (data/healthcare_provider_taxonomy.csv)
  When searching for a relation, dbt found an approximate match. Instead of guessing 
  which relation to use, dbt will move on. Please delete "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY", or rename it to be less ambiguous.
  Searched for: "demo_db"."public"."healthcare_provider_taxonomy"
  Found: "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
  
  > in macro materialization_seed_default (macros/materializations/seed/seed.sql)
  > called by seed healthcare_provider_taxonomy (data/healthcare_provider_taxonomy.csv)
2020-02-27 05:35:25,522173 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d108857-38aa-43e0-9328-1afb6d74c09d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120ef8850>]}
2020-02-27 05:35:25,886943 (Thread-1): 21:35:25 | 1 of 3 ERROR loading seed file public.healthcare_provider_taxonomy... [ERROR in 0.04s]
2020-02-27 05:35:25,887285 (Thread-1): Finished running node seed.ge_tutorials.healthcare_provider_taxonomy
2020-02-27 05:35:25,887548 (Thread-1): Began running node seed.ge_tutorials.npi_small
2020-02-27 05:35:25,887817 (Thread-1): 21:35:25 | 2 of 3 START seed file public.npi_small.............................. [RUN]
2020-02-27 05:35:25,888221 (Thread-1): Acquiring new postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:35:25,888353 (Thread-1): Opening a new connection, currently in state init
2020-02-27 05:35:25,888497 (Thread-1): finished collecting timing info
2020-02-27 05:35:26,326202 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-27 05:35:26,356100 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:35:26,356255 (Thread-1): On seed.ge_tutorials.npi_small: BEGIN
2020-02-27 05:35:26,360519 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:26,360776 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:35:26,360867 (Thread-1): On seed.ge_tutorials.npi_small: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "seed.ge_tutorials.npi_small"} */

    create table "demo_db"."public"."npi_small" (NPI integer,Entity_Type_Code integer,Organization_Name text,Last_Name text,First_Name text,State text,Taxonomy_Code text)
  
2020-02-27 05:35:26,375307 (Thread-1): SQL status: CREATE TABLE in 0.01 seconds
2020-02-27 05:35:26,650150 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:35:26,650313 (Thread-1): On seed.ge_tutorials.npi_small: 
            insert into "demo_db"."public"."npi_small" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,...
2020-02-27 05:35:26,777061 (Thread-1): SQL status: INSERT 0 10000 in 0.13 seconds
2020-02-27 05:35:27,5477 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:35:27,5639 (Thread-1): On seed.ge_tutorials.npi_small: 
            insert into "demo_db"."public"."npi_small" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,...
2020-02-27 05:35:27,99197 (Thread-1): SQL status: INSERT 0 8649 in 0.09 seconds
2020-02-27 05:35:27,100463 (Thread-1): Writing runtime SQL for node "seed.ge_tutorials.npi_small"
2020-02-27 05:35:27,101709 (Thread-1): On seed.ge_tutorials.npi_small: COMMIT
2020-02-27 05:35:27,101823 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:35:27,101907 (Thread-1): On seed.ge_tutorials.npi_small: COMMIT
2020-02-27 05:35:27,107146 (Thread-1): SQL status: COMMIT in 0.01 seconds
2020-02-27 05:35:27,110150 (Thread-1): finished collecting timing info
2020-02-27 05:35:27,110783 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d108857-38aa-43e0-9328-1afb6d74c09d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x120e9bb50>]}
2020-02-27 05:35:27,475718 (Thread-1): 21:35:27 | 2 of 3 OK loaded seed file public.npi_small.......................... [INSERT 18649 in 1.22s]
2020-02-27 05:35:27,476051 (Thread-1): Finished running node seed.ge_tutorials.npi_small
2020-02-27 05:35:27,476401 (Thread-1): Began running node seed.ge_tutorials.state_abbreviations
2020-02-27 05:35:27,476911 (Thread-1): 21:35:27 | 3 of 3 START seed file public.state_abbreviations.................... [RUN]
2020-02-27 05:35:27,478062 (Thread-1): Acquiring new postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:35:27,478340 (Thread-1): Re-using an available connection from the pool (formerly seed.ge_tutorials.npi_small).
2020-02-27 05:35:27,478664 (Thread-1): finished collecting timing info
2020-02-27 05:35:27,485071 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:35:27,485266 (Thread-1): On seed.ge_tutorials.state_abbreviations: BEGIN
2020-02-27 05:35:27,485775 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:27,485903 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:35:27,486005 (Thread-1): On seed.ge_tutorials.state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "seed.ge_tutorials.state_abbreviations"} */

    create table "demo_db"."public"."state_abbreviations" (name text,abbreviation text)
  
2020-02-27 05:35:27,487579 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-27 05:35:27,490435 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:35:27,490553 (Thread-1): On seed.ge_tutorials.state_abbreviations: 
            insert into "demo_db"."public"."state_abbreviations" (name, abbreviation) values
            (%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s...
2020-02-27 05:35:27,491172 (Thread-1): SQL status: INSERT 0 59 in 0.00 seconds
2020-02-27 05:35:27,491466 (Thread-1): Writing runtime SQL for node "seed.ge_tutorials.state_abbreviations"
2020-02-27 05:35:27,492516 (Thread-1): On seed.ge_tutorials.state_abbreviations: COMMIT
2020-02-27 05:35:27,492625 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:35:27,492713 (Thread-1): On seed.ge_tutorials.state_abbreviations: COMMIT
2020-02-27 05:35:27,497157 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:35:27,502606 (Thread-1): finished collecting timing info
2020-02-27 05:35:27,503445 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3d108857-38aa-43e0-9328-1afb6d74c09d', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1211633d0>]}
2020-02-27 05:35:27,874981 (Thread-1): 21:35:27 | 3 of 3 OK loaded seed file public.state_abbreviations................ [INSERT 59 in 0.03s]
2020-02-27 05:35:27,875314 (Thread-1): Finished running node seed.ge_tutorials.state_abbreviations
2020-02-27 05:35:27,971629 (MainThread): Using postgres connection "master".
2020-02-27 05:35:27,972020 (MainThread): On master: BEGIN
2020-02-27 05:35:27,972648 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:35:27,972994 (MainThread): On master: COMMIT
2020-02-27 05:35:27,973246 (MainThread): Using postgres connection "master".
2020-02-27 05:35:27,973472 (MainThread): On master: COMMIT
2020-02-27 05:35:27,974063 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:35:27,974801 (MainThread): 21:35:27 | 
2020-02-27 05:35:27,975158 (MainThread): 21:35:27 | Finished running 3 seeds in 2.65s.
2020-02-27 05:35:27,975458 (MainThread): Connection 'master' was left open.
2020-02-27 05:35:27,975974 (MainThread): On master: Close
2020-02-27 05:35:27,976506 (MainThread): Connection 'seed.ge_tutorials.state_abbreviations' was left open.
2020-02-27 05:35:27,976974 (MainThread): On seed.ge_tutorials.state_abbreviations: Close
2020-02-27 05:35:27,990741 (MainThread): 
2020-02-27 05:35:27,990936 (MainThread): Completed with 1 error and 0 warnings:
2020-02-27 05:35:27,991058 (MainThread): 
2020-02-27 05:35:27,991167 (MainThread): Compilation Error in seed healthcare_provider_taxonomy (data/healthcare_provider_taxonomy.csv)
2020-02-27 05:35:27,991264 (MainThread):   When searching for a relation, dbt found an approximate match. Instead of guessing 
2020-02-27 05:35:27,991354 (MainThread):   which relation to use, dbt will move on. Please delete "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY", or rename it to be less ambiguous.
2020-02-27 05:35:27,991441 (MainThread):   Searched for: "demo_db"."public"."healthcare_provider_taxonomy"
2020-02-27 05:35:27,991532 (MainThread):   Found: "demo_db"."public"."HEALTHCARE_PROVIDER_TAXONOMY"
2020-02-27 05:35:27,991620 (MainThread):   
2020-02-27 05:35:27,991704 (MainThread):   > in macro materialization_seed_default (macros/materializations/seed/seed.sql)
2020-02-27 05:35:27,991788 (MainThread):   > called by seed healthcare_provider_taxonomy (data/healthcare_provider_taxonomy.csv)
2020-02-27 05:35:27,991880 (MainThread): 
Done. PASS=2 WARN=0 ERROR=1 SKIP=0 TOTAL=3
2020-02-27 05:35:27,992148 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121168050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12117c850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x121163050>]}
2020-02-27 05:35:28,355841 (MainThread): Flushing usage events
2020-02-27 05:37:58,670543 (MainThread): Running with dbt=0.15.1
2020-02-27 05:37:58,733033 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-27 05:37:58,733484 (MainThread): Tracking: tracking
2020-02-27 05:37:58,748373 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127abc950>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127abce50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127abccd0>]}
2020-02-27 05:38:00,202833 (MainThread): Partial parsing not enabled
2020-02-27 05:38:00,204957 (MainThread): Parsing macros/core.sql
2020-02-27 05:38:00,209260 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:38:00,216107 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:38:00,217790 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:38:00,232134 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:38:00,245345 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:38:00,256816 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:38:00,258249 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:38:00,262703 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:38:00,267733 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:38:00,271979 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:38:00,276222 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:38:00,279556 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:38:00,280252 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:38:00,281069 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:38:00,282286 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:38:00,283705 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:38:00,289764 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:38:00,291368 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:38:00,310034 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:38:00,310992 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:38:00,311720 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:38:00,312536 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:38:00,314234 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:38:00,315489 (MainThread): Parsing macros/relations.sql
2020-02-27 05:38:00,316628 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:38:00,323325 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:38:00,336494 (MainThread): Partial parsing not enabled
2020-02-27 05:38:00,346082 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:00,346173 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:00,357599 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:00,357684 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:00,362996 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:00,363071 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:00,367062 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:00,367143 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:00,370865 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:00,370938 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:00,419375 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-27 05:38:00,423617 (MainThread): 
2020-02-27 05:38:00,424003 (MainThread): Acquiring new postgres connection "master".
2020-02-27 05:38:00,424208 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:00,494551 (MainThread): Using postgres connection "master".
2020-02-27 05:38:00,494707 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:38:00,550035 (MainThread): Got an error when attempting to open a postgres connection: 'FATAL:  database "demo_db" does not exist
'
2020-02-27 05:38:00,550261 (MainThread): Error running SQL: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:38:00,550372 (MainThread): Rolling back transaction.
2020-02-27 05:38:00,550495 (MainThread): On master: No close available on handle
2020-02-27 05:38:00,550862 (MainThread): Connection 'master' was properly closed.
2020-02-27 05:38:00,551004 (MainThread): ERROR: Database Error
  FATAL:  database "demo_db" does not exist
  
2020-02-27 05:38:00,551187 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12754cf50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127b67c10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c96e10>]}
2020-02-27 05:38:00,905953 (MainThread): Flushing usage events
2020-02-27 05:38:38,251877 (MainThread): Running with dbt=0.15.1
2020-02-27 05:38:38,314386 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.seed.SeedTask'>, debug=False, full_refresh=False, log_cache_events=False, log_format='default', partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='seed', show=False, single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='seed', write_json=True)
2020-02-27 05:38:38,314808 (MainThread): Tracking: tracking
2020-02-27 05:38:38,328019 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12711e490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127658050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127658150>]}
2020-02-27 05:38:38,728284 (MainThread): Partial parsing not enabled
2020-02-27 05:38:38,729822 (MainThread): Parsing macros/core.sql
2020-02-27 05:38:38,732615 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:38:38,737081 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:38:38,738242 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:38:38,749030 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:38:38,761453 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:38:38,771952 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:38:38,773810 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:38:38,777978 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:38:38,782333 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:38:38,786103 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:38:38,790071 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:38:38,793131 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:38:38,793789 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:38:38,794530 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:38:38,795635 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:38:38,797496 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:38:38,803244 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:38:38,804582 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:38:38,821985 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:38:38,822924 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:38:38,823576 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:38:38,824319 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:38:38,825776 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:38:38,826916 (MainThread): Parsing macros/relations.sql
2020-02-27 05:38:38,827953 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:38:38,834739 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:38:38,848121 (MainThread): Partial parsing not enabled
2020-02-27 05:38:38,857772 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:38,857857 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:38,870021 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:38,870112 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:38,875623 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:38,875703 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:38,879446 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:38,879517 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:38,883217 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:38,883287 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:38,930650 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-27 05:38:38,934746 (MainThread): 
2020-02-27 05:38:38,935124 (MainThread): Acquiring new postgres connection "master".
2020-02-27 05:38:38,935220 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:39,5248 (MainThread): Using postgres connection "master".
2020-02-27 05:38:39,5405 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:38:39,50853 (MainThread): SQL status: SELECT 6 in 0.05 seconds
2020-02-27 05:38:39,78972 (MainThread): Using postgres connection "master".
2020-02-27 05:38:39,79112 (MainThread): On master: BEGIN
2020-02-27 05:38:39,79447 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:39,79519 (MainThread): Using postgres connection "master".
2020-02-27 05:38:39,79575 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'ge_tutorials' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ge_tutorials' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 05:38:39,81678 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-27 05:38:39,103676 (MainThread): Using postgres connection "master".
2020-02-27 05:38:39,103769 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 05:38:39,105732 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-27 05:38:39,106338 (MainThread): On master: ROLLBACK
2020-02-27 05:38:39,106575 (MainThread): Using postgres connection "master".
2020-02-27 05:38:39,106644 (MainThread): On master: BEGIN
2020-02-27 05:38:39,106882 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:39,106957 (MainThread): On master: COMMIT
2020-02-27 05:38:39,107018 (MainThread): Using postgres connection "master".
2020-02-27 05:38:39,107073 (MainThread): On master: COMMIT
2020-02-27 05:38:39,107356 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:39,107575 (MainThread): 21:38:39 | Concurrency: 1 threads (target='dev')
2020-02-27 05:38:39,107692 (MainThread): 21:38:39 | 
2020-02-27 05:38:39,109413 (Thread-1): Began running node seed.ge_tutorials.healthcare_provider_taxonomy
2020-02-27 05:38:39,109540 (Thread-1): 21:38:39 | 1 of 3 START seed file public.healthcare_provider_taxonomy........... [RUN]
2020-02-27 05:38:39,109878 (Thread-1): Acquiring new postgres connection "seed.ge_tutorials.healthcare_provider_taxonomy".
2020-02-27 05:38:39,109946 (Thread-1): Opening a new connection, currently in state init
2020-02-27 05:38:39,110031 (Thread-1): finished collecting timing info
2020-02-27 05:38:39,156732 (Thread-1): * Deprecation Warning: 
    The quote_columns parameter was not set for seeds, so the default value of
    False was chosen. The default will change to True in a future release.

    For more information, see:
    https://docs.getdbt.com/v0.15/docs/seeds#section-specify-column-quoting
    

2020-02-27 05:38:39,157113 (Thread-1): Using postgres connection "seed.ge_tutorials.healthcare_provider_taxonomy".
2020-02-27 05:38:39,157196 (Thread-1): On seed.ge_tutorials.healthcare_provider_taxonomy: BEGIN
2020-02-27 05:38:39,160514 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:39,160661 (Thread-1): Using postgres connection "seed.ge_tutorials.healthcare_provider_taxonomy".
2020-02-27 05:38:39,160733 (Thread-1): On seed.ge_tutorials.healthcare_provider_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "seed.ge_tutorials.healthcare_provider_taxonomy"} */

    create table "ge_tutorials"."public"."healthcare_provider_taxonomy" (MEDICARE_SPECIALTY_CODE text,MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION text,PROVIDER_TAXONOMY_CODE text,PROVIDER_TAXONOMY_DESCRIPTION text)
  
2020-02-27 05:38:39,165683 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-27 05:38:39,177842 (Thread-1): Using postgres connection "seed.ge_tutorials.healthcare_provider_taxonomy".
2020-02-27 05:38:39,178021 (Thread-1): On seed.ge_tutorials.healthcare_provider_taxonomy: 
            insert into "ge_tutorials"."public"."healthcare_provider_taxonomy" (MEDICARE_SPECIALTY_CODE, MEDICARE_PROVIDER_SUPPLIER_TYPE_DESCRIPTION, PROVIDER_TAXONOMY_CODE, PROVIDER_TAXONOMY_DESCRIPTION) values
            (%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,%s,%s),(%s,%s,...
2020-02-27 05:38:39,182177 (Thread-1): SQL status: INSERT 0 521 in 0.00 seconds
2020-02-27 05:38:39,182506 (Thread-1): Writing runtime SQL for node "seed.ge_tutorials.healthcare_provider_taxonomy"
2020-02-27 05:38:39,183389 (Thread-1): On seed.ge_tutorials.healthcare_provider_taxonomy: COMMIT
2020-02-27 05:38:39,183473 (Thread-1): Using postgres connection "seed.ge_tutorials.healthcare_provider_taxonomy".
2020-02-27 05:38:39,183538 (Thread-1): On seed.ge_tutorials.healthcare_provider_taxonomy: COMMIT
2020-02-27 05:38:39,187542 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:39,190365 (Thread-1): finished collecting timing info
2020-02-27 05:38:39,190949 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '542266ff-ba99-422e-9664-243afeca04e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12885ffd0>]}
2020-02-27 05:38:39,557603 (Thread-1): 21:38:39 | 1 of 3 OK loaded seed file public.healthcare_provider_taxonomy....... [INSERT 521 in 0.08s]
2020-02-27 05:38:39,557872 (Thread-1): Finished running node seed.ge_tutorials.healthcare_provider_taxonomy
2020-02-27 05:38:39,558144 (Thread-1): Began running node seed.ge_tutorials.npi_small
2020-02-27 05:38:39,558439 (Thread-1): 21:38:39 | 2 of 3 START seed file public.npi_small.............................. [RUN]
2020-02-27 05:38:39,558890 (Thread-1): Acquiring new postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:38:39,559011 (Thread-1): Re-using an available connection from the pool (formerly seed.ge_tutorials.healthcare_provider_taxonomy).
2020-02-27 05:38:39,559136 (Thread-1): finished collecting timing info
2020-02-27 05:38:40,3575 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:38:40,3756 (Thread-1): On seed.ge_tutorials.npi_small: BEGIN
2020-02-27 05:38:40,4224 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:40,4305 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:38:40,4367 (Thread-1): On seed.ge_tutorials.npi_small: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "seed.ge_tutorials.npi_small"} */

    create table "ge_tutorials"."public"."npi_small" (NPI integer,Entity_Type_Code integer,Organization_Name text,Last_Name text,First_Name text,State text,Taxonomy_Code text)
  
2020-02-27 05:38:40,6019 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-27 05:38:40,248061 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:38:40,248239 (Thread-1): On seed.ge_tutorials.npi_small: 
            insert into "ge_tutorials"."public"."npi_small" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-27 05:38:40,381671 (Thread-1): SQL status: INSERT 0 10000 in 0.13 seconds
2020-02-27 05:38:40,608682 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:38:40,608832 (Thread-1): On seed.ge_tutorials.npi_small: 
            insert into "ge_tutorials"."public"."npi_small" (NPI, Entity_Type_Code, Organization_Name, Last_Name, First_Name, State, Taxonomy_Code) values
            (%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s),(%s,%s,%s,%s,%s,%s,%s)...
2020-02-27 05:38:40,707080 (Thread-1): SQL status: INSERT 0 8649 in 0.10 seconds
2020-02-27 05:38:40,708732 (Thread-1): Writing runtime SQL for node "seed.ge_tutorials.npi_small"
2020-02-27 05:38:40,710153 (Thread-1): On seed.ge_tutorials.npi_small: COMMIT
2020-02-27 05:38:40,710363 (Thread-1): Using postgres connection "seed.ge_tutorials.npi_small".
2020-02-27 05:38:40,710494 (Thread-1): On seed.ge_tutorials.npi_small: COMMIT
2020-02-27 05:38:40,714340 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:40,717298 (Thread-1): finished collecting timing info
2020-02-27 05:38:40,719256 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '542266ff-ba99-422e-9664-243afeca04e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c29bd0>]}
2020-02-27 05:38:41,85435 (Thread-1): 21:38:41 | 2 of 3 OK loaded seed file public.npi_small.......................... [INSERT 18649 in 1.16s]
2020-02-27 05:38:41,85759 (Thread-1): Finished running node seed.ge_tutorials.npi_small
2020-02-27 05:38:41,86077 (Thread-1): Began running node seed.ge_tutorials.state_abbreviations
2020-02-27 05:38:41,86754 (Thread-1): 21:38:41 | 3 of 3 START seed file public.state_abbreviations.................... [RUN]
2020-02-27 05:38:41,87827 (Thread-1): Acquiring new postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:38:41,88063 (Thread-1): Re-using an available connection from the pool (formerly seed.ge_tutorials.npi_small).
2020-02-27 05:38:41,88271 (Thread-1): finished collecting timing info
2020-02-27 05:38:41,93078 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:38:41,93214 (Thread-1): On seed.ge_tutorials.state_abbreviations: BEGIN
2020-02-27 05:38:41,93720 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:41,93852 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:38:41,93956 (Thread-1): On seed.ge_tutorials.state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "seed.ge_tutorials.state_abbreviations"} */

    create table "ge_tutorials"."public"."state_abbreviations" (name text,abbreviation text)
  
2020-02-27 05:38:41,95495 (Thread-1): SQL status: CREATE TABLE in 0.00 seconds
2020-02-27 05:38:41,97875 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:38:41,97984 (Thread-1): On seed.ge_tutorials.state_abbreviations: 
            insert into "ge_tutorials"."public"."state_abbreviations" (name, abbreviation) values
            (%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(%s,%s),(...
2020-02-27 05:38:41,98531 (Thread-1): SQL status: INSERT 0 59 in 0.00 seconds
2020-02-27 05:38:41,98779 (Thread-1): Writing runtime SQL for node "seed.ge_tutorials.state_abbreviations"
2020-02-27 05:38:41,99689 (Thread-1): On seed.ge_tutorials.state_abbreviations: COMMIT
2020-02-27 05:38:41,99779 (Thread-1): Using postgres connection "seed.ge_tutorials.state_abbreviations".
2020-02-27 05:38:41,99865 (Thread-1): On seed.ge_tutorials.state_abbreviations: COMMIT
2020-02-27 05:38:41,104396 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:41,108152 (Thread-1): finished collecting timing info
2020-02-27 05:38:41,108875 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '542266ff-ba99-422e-9664-243afeca04e5', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c30a10>]}
2020-02-27 05:38:41,472652 (Thread-1): 21:38:41 | 3 of 3 OK loaded seed file public.state_abbreviations................ [INSERT 59 in 0.02s]
2020-02-27 05:38:41,472982 (Thread-1): Finished running node seed.ge_tutorials.state_abbreviations
2020-02-27 05:38:41,561742 (MainThread): Using postgres connection "master".
2020-02-27 05:38:41,561963 (MainThread): On master: BEGIN
2020-02-27 05:38:41,562306 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:41,562488 (MainThread): On master: COMMIT
2020-02-27 05:38:41,562611 (MainThread): Using postgres connection "master".
2020-02-27 05:38:41,562735 (MainThread): On master: COMMIT
2020-02-27 05:38:41,562960 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:41,563259 (MainThread): 21:38:41 | 
2020-02-27 05:38:41,563399 (MainThread): 21:38:41 | Finished running 3 seeds in 2.63s.
2020-02-27 05:38:41,563567 (MainThread): Connection 'master' was left open.
2020-02-27 05:38:41,563671 (MainThread): On master: Close
2020-02-27 05:38:41,563815 (MainThread): Connection 'seed.ge_tutorials.state_abbreviations' was left open.
2020-02-27 05:38:41,563941 (MainThread): On seed.ge_tutorials.state_abbreviations: Close
2020-02-27 05:38:41,572795 (MainThread): 
2020-02-27 05:38:41,572965 (MainThread): Completed successfully
2020-02-27 05:38:41,573082 (MainThread): 
Done. PASS=3 WARN=0 ERROR=0 SKIP=0 TOTAL=3
2020-02-27 05:38:41,573269 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c38490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128a7f5d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128a85f10>]}
2020-02-27 05:38:41,937140 (MainThread): Flushing usage events
2020-02-27 05:38:55,861315 (MainThread): Running with dbt=0.15.1
2020-02-27 05:38:55,924245 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 05:38:55,924737 (MainThread): Tracking: tracking
2020-02-27 05:38:55,938494 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cc93450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cc93d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cc93c50>]}
2020-02-27 05:38:56,376082 (MainThread): Partial parsing not enabled
2020-02-27 05:38:56,377521 (MainThread): Parsing macros/core.sql
2020-02-27 05:38:56,380304 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 05:38:56,384732 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 05:38:56,385893 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 05:38:56,396746 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 05:38:56,409232 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 05:38:56,420170 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 05:38:56,421364 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 05:38:56,426048 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 05:38:56,430319 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 05:38:56,435571 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 05:38:56,439579 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 05:38:56,442674 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 05:38:56,443326 (MainThread): Parsing macros/etc/query.sql
2020-02-27 05:38:56,444095 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 05:38:56,445222 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 05:38:56,446531 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 05:38:56,452165 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 05:38:56,453416 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 05:38:56,470626 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 05:38:56,471503 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 05:38:56,472144 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 05:38:56,472877 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 05:38:56,474313 (MainThread): Parsing macros/catalog.sql
2020-02-27 05:38:56,475432 (MainThread): Parsing macros/relations.sql
2020-02-27 05:38:56,476452 (MainThread): Parsing macros/adapters.sql
2020-02-27 05:38:56,482699 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 05:38:56,495627 (MainThread): Partial parsing not enabled
2020-02-27 05:38:56,505067 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:56,505148 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:56,518079 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:56,518218 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:56,523729 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,523810 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:56,527699 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:56,527776 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:56,531447 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:56,531521 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:56,578942 (MainThread): Found 5 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 3 seed files, 0 sources
2020-02-27 05:38:56,583188 (MainThread): 
2020-02-27 05:38:56,583636 (MainThread): Acquiring new postgres connection "master".
2020-02-27 05:38:56,583801 (MainThread): Opening a new connection, currently in state init
2020-02-27 05:38:56,660581 (MainThread): Using postgres connection "master".
2020-02-27 05:38:56,660764 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 05:38:56,706125 (MainThread): SQL status: SELECT 6 in 0.05 seconds
2020-02-27 05:38:56,734726 (MainThread): Using postgres connection "master".
2020-02-27 05:38:56,734880 (MainThread): On master: BEGIN
2020-02-27 05:38:56,735222 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:56,735300 (MainThread): Using postgres connection "master".
2020-02-27 05:38:56,735360 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'ge_tutorials' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ge_tutorials' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 05:38:56,737123 (MainThread): SQL status: SELECT 3 in 0.00 seconds
2020-02-27 05:38:56,761242 (MainThread): Using postgres connection "master".
2020-02-27 05:38:56,761361 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 05:38:56,764662 (MainThread): SQL status: SELECT 0 in 0.00 seconds
2020-02-27 05:38:56,765700 (MainThread): On master: ROLLBACK
2020-02-27 05:38:56,765917 (MainThread): Using postgres connection "master".
2020-02-27 05:38:56,766013 (MainThread): On master: BEGIN
2020-02-27 05:38:56,766304 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:56,766423 (MainThread): On master: COMMIT
2020-02-27 05:38:56,766519 (MainThread): Using postgres connection "master".
2020-02-27 05:38:56,766599 (MainThread): On master: COMMIT
2020-02-27 05:38:56,766774 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:56,767077 (MainThread): 21:38:56 | Concurrency: 1 threads (target='dev')
2020-02-27 05:38:56,767213 (MainThread): 21:38:56 | 
2020-02-27 05:38:56,768838 (Thread-1): Began running node model.ge_tutorials.stg_npi
2020-02-27 05:38:56,769011 (Thread-1): 21:38:56 | 1 of 5 START view model public.stg_npi............................... [RUN]
2020-02-27 05:38:56,769280 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,769377 (Thread-1): Opening a new connection, currently in state init
2020-02-27 05:38:56,769482 (Thread-1): Compiling model.ge_tutorials.stg_npi
2020-02-27 05:38:56,779929 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 05:38:56,780271 (Thread-1): finished collecting timing info
2020-02-27 05:38:56,808482 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,808647 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_tmp" cascade
2020-02-27 05:38:56,811962 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:56,813938 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,814042 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 05:38:56,814313 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:56,815480 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 05:38:56,815835 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,815916 (Thread-1): On model.ge_tutorials.stg_npi: BEGIN
2020-02-27 05:38:56,816092 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:56,816170 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,816235 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */

  
  create view "ge_tutorials"."public"."stg_npi__dbt_tmp" as (
    select 
	npi,
	entity_type_code,
	organization_name,
	last_name,
	first_name,
	state,
	taxonomy_code
from "ge_tutorials"."public"."npi_small"
  );

2020-02-27 05:38:56,817831 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 05:38:56,819571 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,819654 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-27 05:38:56,819977 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 05:38:56,820603 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 05:38:56,820687 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,820754 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 05:38:56,821410 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:56,824698 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 05:38:56,824903 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 05:38:56,825385 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:56,828982 (Thread-1): finished collecting timing info
2020-02-27 05:38:56,829817 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0432b65a-edea-46fc-b791-cfc91efc069f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11de7e510>]}
2020-02-27 05:38:57,195509 (Thread-1): 21:38:57 | 1 of 5 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.06s]
2020-02-27 05:38:57,195851 (Thread-1): Finished running node model.ge_tutorials.stg_npi
2020-02-27 05:38:57,196185 (Thread-1): Began running node model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:38:57,196685 (Thread-1): 21:38:57 | 2 of 5 START view model public.stg_state_crosswalk................... [RUN]
2020-02-27 05:38:57,197377 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,197609 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_npi).
2020-02-27 05:38:57,197789 (Thread-1): Compiling model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:38:57,206058 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_state_crosswalk"
2020-02-27 05:38:57,206558 (Thread-1): finished collecting timing info
2020-02-27 05:38:57,213245 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,213387 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "ge_tutorials"."public"."stg_state_crosswalk__dbt_tmp" cascade
2020-02-27 05:38:57,213726 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:57,216309 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,216455 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "ge_tutorials"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-27 05:38:57,216846 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:57,221123 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_state_crosswalk"
2020-02-27 05:38:57,221732 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,221909 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: BEGIN
2020-02-27 05:38:57,222181 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:57,222308 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,222411 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */

  
  create view "ge_tutorials"."public"."stg_state_crosswalk__dbt_tmp" as (
    select 
	name as state,
	abbreviation as state_abbrev
from "ge_tutorials"."public"."state_abbreviations"
  );

2020-02-27 05:38:57,223292 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 05:38:57,226755 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,226940 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
alter table "ge_tutorials"."public"."stg_state_crosswalk__dbt_tmp" rename to "stg_state_crosswalk"
2020-02-27 05:38:57,227472 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 05:38:57,228439 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: COMMIT
2020-02-27 05:38:57,228554 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,228644 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: COMMIT
2020-02-27 05:38:57,229057 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:57,230773 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_crosswalk".
2020-02-27 05:38:57,230881 (Thread-1): On model.ge_tutorials.stg_state_crosswalk: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_crosswalk"} */
drop view if exists "ge_tutorials"."public"."stg_state_crosswalk__dbt_backup" cascade
2020-02-27 05:38:57,231098 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:57,233559 (Thread-1): finished collecting timing info
2020-02-27 05:38:57,234142 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0432b65a-edea-46fc-b791-cfc91efc069f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11e22bf10>]}
2020-02-27 05:38:57,608176 (Thread-1): 21:38:57 | 2 of 5 OK created view model public.stg_state_crosswalk.............. [CREATE VIEW in 0.04s]
2020-02-27 05:38:57,608505 (Thread-1): Finished running node model.ge_tutorials.stg_state_crosswalk
2020-02-27 05:38:57,608769 (Thread-1): Began running node model.ge_tutorials.stg_taxonomy
2020-02-27 05:38:57,609176 (Thread-1): 21:38:57 | 3 of 5 START view model public.stg_taxonomy.......................... [RUN]
2020-02-27 05:38:57,609644 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,609773 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_state_crosswalk).
2020-02-27 05:38:57,609896 (Thread-1): Compiling model.ge_tutorials.stg_taxonomy
2020-02-27 05:38:57,617297 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_taxonomy"
2020-02-27 05:38:57,617746 (Thread-1): finished collecting timing info
2020-02-27 05:38:57,624271 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,624395 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "ge_tutorials"."public"."stg_taxonomy__dbt_tmp" cascade
2020-02-27 05:38:57,624762 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:57,627065 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,627219 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "ge_tutorials"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-27 05:38:57,627525 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:57,629223 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_taxonomy"
2020-02-27 05:38:57,629752 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,629893 (Thread-1): On model.ge_tutorials.stg_taxonomy: BEGIN
2020-02-27 05:38:57,630201 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:57,630336 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,630431 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */

  
  create view "ge_tutorials"."public"."stg_taxonomy__dbt_tmp" as (
    select 
	medicare_specialty_code,
	medicare_provider_supplier_type_description,
	provider_taxonomy_code,
	provider_taxonomy_description
from "ge_tutorials"."public"."healthcare_provider_taxonomy"
  );

2020-02-27 05:38:57,631337 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 05:38:57,633908 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,634089 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
alter table "ge_tutorials"."public"."stg_taxonomy__dbt_tmp" rename to "stg_taxonomy"
2020-02-27 05:38:57,634559 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 05:38:57,635528 (Thread-1): On model.ge_tutorials.stg_taxonomy: COMMIT
2020-02-27 05:38:57,635655 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,635757 (Thread-1): On model.ge_tutorials.stg_taxonomy: COMMIT
2020-02-27 05:38:57,636191 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:57,638119 (Thread-1): Using postgres connection "model.ge_tutorials.stg_taxonomy".
2020-02-27 05:38:57,638277 (Thread-1): On model.ge_tutorials.stg_taxonomy: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_taxonomy"} */
drop view if exists "ge_tutorials"."public"."stg_taxonomy__dbt_backup" cascade
2020-02-27 05:38:57,638542 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:57,640923 (Thread-1): finished collecting timing info
2020-02-27 05:38:57,641552 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0432b65a-edea-46fc-b791-cfc91efc069f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dfe9950>]}
2020-02-27 05:38:57,996963 (Thread-1): 21:38:57 | 3 of 5 OK created view model public.stg_taxonomy..................... [CREATE VIEW in 0.03s]
2020-02-27 05:38:57,997310 (Thread-1): Finished running node model.ge_tutorials.stg_taxonomy
2020-02-27 05:38:57,997893 (Thread-1): Began running node model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:38:57,998180 (Thread-1): 21:38:57 | 4 of 5 START view model public.npi_with_crosswalks................... [RUN]
2020-02-27 05:38:57,998591 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:57,998718 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_taxonomy).
2020-02-27 05:38:57,998842 (Thread-1): Compiling model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:38:58,9397 (Thread-1): Writing injected SQL for node "model.ge_tutorials.npi_with_crosswalks"
2020-02-27 05:38:58,9794 (Thread-1): finished collecting timing info
2020-02-27 05:38:58,15556 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,15673 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_crosswalks"} */
drop view if exists "ge_tutorials"."public"."npi_with_crosswalks__dbt_tmp" cascade
2020-02-27 05:38:58,16000 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:58,18165 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,18323 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_crosswalks"} */
drop view if exists "ge_tutorials"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-27 05:38:58,18624 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:58,20017 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.npi_with_crosswalks"
2020-02-27 05:38:58,20499 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,20653 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: BEGIN
2020-02-27 05:38:58,20944 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:58,21083 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,21168 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_crosswalks"} */

  
  create view "ge_tutorials"."public"."npi_with_crosswalks__dbt_tmp" as (
    select 
	n.*,
	t.provider_taxonomy_description,
	s.state as state_name
from "ge_tutorials"."public"."stg_npi" n
left join "ge_tutorials"."public"."stg_taxonomy" t
	on n.taxonomy_code = t.provider_taxonomy_code
left join "ge_tutorials"."public"."stg_state_crosswalk" s
	on n.state = s.state_abbrev
  );

2020-02-27 05:38:58,22615 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 05:38:58,25037 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,25215 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_crosswalks"} */
alter table "ge_tutorials"."public"."npi_with_crosswalks__dbt_tmp" rename to "npi_with_crosswalks"
2020-02-27 05:38:58,25662 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 05:38:58,26556 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: COMMIT
2020-02-27 05:38:58,26682 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,26765 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: COMMIT
2020-02-27 05:38:58,27307 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:58,28984 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_crosswalks".
2020-02-27 05:38:58,29126 (Thread-1): On model.ge_tutorials.npi_with_crosswalks: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_crosswalks"} */
drop view if exists "ge_tutorials"."public"."npi_with_crosswalks__dbt_backup" cascade
2020-02-27 05:38:58,29401 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:58,31638 (Thread-1): finished collecting timing info
2020-02-27 05:38:58,32295 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0432b65a-edea-46fc-b791-cfc91efc069f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11de6e350>]}
2020-02-27 05:38:58,390295 (Thread-1): 21:38:58 | 4 of 5 OK created view model public.npi_with_crosswalks.............. [CREATE VIEW in 0.03s]
2020-02-27 05:38:58,390634 (Thread-1): Finished running node model.ge_tutorials.npi_with_crosswalks
2020-02-27 05:38:58,391277 (Thread-1): Began running node model.ge_tutorials.count_specialties
2020-02-27 05:38:58,391646 (Thread-1): 21:38:58 | 5 of 5 START view model public.count_specialties..................... [RUN]
2020-02-27 05:38:58,392291 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,392517 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.npi_with_crosswalks).
2020-02-27 05:38:58,392687 (Thread-1): Compiling model.ge_tutorials.count_specialties
2020-02-27 05:38:58,400198 (Thread-1): Writing injected SQL for node "model.ge_tutorials.count_specialties"
2020-02-27 05:38:58,400620 (Thread-1): finished collecting timing info
2020-02-27 05:38:58,406183 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,406282 (Thread-1): On model.ge_tutorials.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_specialties"} */
drop view if exists "ge_tutorials"."public"."count_specialties__dbt_tmp" cascade
2020-02-27 05:38:58,406618 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:58,408408 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,408499 (Thread-1): On model.ge_tutorials.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_specialties"} */
drop view if exists "ge_tutorials"."public"."count_specialties__dbt_backup" cascade
2020-02-27 05:38:58,408709 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:58,411588 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.count_specialties"
2020-02-27 05:38:58,412409 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,412685 (Thread-1): On model.ge_tutorials.count_specialties: BEGIN
2020-02-27 05:38:58,413058 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:58,413283 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,413402 (Thread-1): On model.ge_tutorials.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_specialties"} */

  
  create view "ge_tutorials"."public"."count_specialties__dbt_tmp" as (
    select 
	provider_taxonomy_description,
	state_name,
	count(distinct npi)
from "ge_tutorials"."public"."npi_with_crosswalks" n
group by 1, 2
  );

2020-02-27 05:38:58,414895 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 05:38:58,417055 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,417181 (Thread-1): On model.ge_tutorials.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_specialties"} */
alter table "ge_tutorials"."public"."count_specialties__dbt_tmp" rename to "count_specialties"
2020-02-27 05:38:58,417594 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 05:38:58,419782 (Thread-1): On model.ge_tutorials.count_specialties: COMMIT
2020-02-27 05:38:58,420130 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,420235 (Thread-1): On model.ge_tutorials.count_specialties: COMMIT
2020-02-27 05:38:58,420730 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:58,422458 (Thread-1): Using postgres connection "model.ge_tutorials.count_specialties".
2020-02-27 05:38:58,422595 (Thread-1): On model.ge_tutorials.count_specialties: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_specialties"} */
drop view if exists "ge_tutorials"."public"."count_specialties__dbt_backup" cascade
2020-02-27 05:38:58,423084 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 05:38:58,425883 (Thread-1): finished collecting timing info
2020-02-27 05:38:58,426675 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0432b65a-edea-46fc-b791-cfc91efc069f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11df969d0>]}
2020-02-27 05:38:58,801815 (Thread-1): 21:38:58 | 5 of 5 OK created view model public.count_specialties................ [CREATE VIEW in 0.03s]
2020-02-27 05:38:58,802157 (Thread-1): Finished running node model.ge_tutorials.count_specialties
2020-02-27 05:38:58,821569 (MainThread): Using postgres connection "master".
2020-02-27 05:38:58,821875 (MainThread): On master: BEGIN
2020-02-27 05:38:58,822390 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 05:38:58,822632 (MainThread): On master: COMMIT
2020-02-27 05:38:58,822805 (MainThread): Using postgres connection "master".
2020-02-27 05:38:58,822960 (MainThread): On master: COMMIT
2020-02-27 05:38:58,823389 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 05:38:58,823978 (MainThread): 21:38:58 | 
2020-02-27 05:38:58,824169 (MainThread): 21:38:58 | Finished running 5 view models in 2.24s.
2020-02-27 05:38:58,824332 (MainThread): Connection 'master' was left open.
2020-02-27 05:38:58,824452 (MainThread): On master: Close
2020-02-27 05:38:58,824599 (MainThread): Connection 'model.ge_tutorials.count_specialties' was left open.
2020-02-27 05:38:58,824711 (MainThread): On model.ge_tutorials.count_specialties: Close
2020-02-27 05:38:58,838615 (MainThread): 
2020-02-27 05:38:58,838801 (MainThread): Completed successfully
2020-02-27 05:38:58,838923 (MainThread): 
Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
2020-02-27 05:38:58,839147 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b7f5c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dfac310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11dfacb10>]}
2020-02-27 05:38:59,213204 (MainThread): Flushing usage events
2020-02-27 18:46:00,552996 (MainThread): Running with dbt=0.15.1
2020-02-27 18:46:00,624845 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 18:46:00,625670 (MainThread): Tracking: tracking
2020-02-27 18:46:00,643517 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128562490>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128562390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128562b10>]}
2020-02-27 18:46:01,473795 (MainThread): Partial parsing not enabled
2020-02-27 18:46:01,477021 (MainThread): Parsing macros/core.sql
2020-02-27 18:46:01,481011 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 18:46:01,486896 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 18:46:01,489672 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 18:46:01,503168 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 18:46:01,515766 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 18:46:01,527487 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 18:46:01,529029 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 18:46:01,533541 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 18:46:01,538094 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 18:46:01,542999 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 18:46:01,547067 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 18:46:01,550686 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 18:46:01,551851 (MainThread): Parsing macros/etc/query.sql
2020-02-27 18:46:01,552941 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 18:46:01,554428 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 18:46:01,556023 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 18:46:01,562062 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 18:46:01,563802 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 18:46:01,581266 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 18:46:01,582337 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 18:46:01,583323 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 18:46:01,584493 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 18:46:01,586333 (MainThread): Parsing macros/catalog.sql
2020-02-27 18:46:01,587763 (MainThread): Parsing macros/relations.sql
2020-02-27 18:46:01,589064 (MainThread): Parsing macros/adapters.sql
2020-02-27 18:46:01,595486 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 18:46:01,609990 (MainThread): Partial parsing not enabled
2020-02-27 18:46:01,619900 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:01,620010 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:01,631888 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:01,631994 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:01,636723 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,636808 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:01,640810 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:01,640888 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:01,685134 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 2 seed files, 0 sources
2020-02-27 18:46:01,688775 (MainThread): 
2020-02-27 18:46:01,689170 (MainThread): Acquiring new postgres connection "master".
2020-02-27 18:46:01,689265 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:01,764049 (MainThread): Using postgres connection "master".
2020-02-27 18:46:01,764189 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 18:46:01,843082 (MainThread): SQL status: SELECT 8 in 0.08 seconds
2020-02-27 18:46:01,867391 (MainThread): Using postgres connection "master".
2020-02-27 18:46:01,867552 (MainThread): On master: BEGIN
2020-02-27 18:46:01,867875 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:01,867956 (MainThread): Using postgres connection "master".
2020-02-27 18:46:01,868020 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'ge_tutorials' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ge_tutorials' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 18:46:01,869899 (MainThread): SQL status: SELECT 8 in 0.00 seconds
2020-02-27 18:46:01,893225 (MainThread): Using postgres connection "master".
2020-02-27 18:46:01,893351 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 18:46:01,901193 (MainThread): SQL status: SELECT 7 in 0.01 seconds
2020-02-27 18:46:01,908563 (MainThread): On master: ROLLBACK
2020-02-27 18:46:01,908817 (MainThread): Using postgres connection "master".
2020-02-27 18:46:01,908902 (MainThread): On master: BEGIN
2020-02-27 18:46:01,909158 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:01,909260 (MainThread): On master: COMMIT
2020-02-27 18:46:01,909340 (MainThread): Using postgres connection "master".
2020-02-27 18:46:01,909409 (MainThread): On master: COMMIT
2020-02-27 18:46:01,909559 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:01,909821 (MainThread): 10:46:01 | Concurrency: 1 threads (target='dev')
2020-02-27 18:46:01,909939 (MainThread): 10:46:01 | 
2020-02-27 18:46:01,911241 (Thread-1): Began running node model.ge_tutorials.stg_npi
2020-02-27 18:46:01,911401 (Thread-1): 10:46:01 | 1 of 4 START view model public.stg_npi............................... [RUN]
2020-02-27 18:46:01,911641 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,911725 (Thread-1): Opening a new connection, currently in state init
2020-02-27 18:46:01,911815 (Thread-1): Compiling model.ge_tutorials.stg_npi
2020-02-27 18:46:01,921255 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 18:46:01,921605 (Thread-1): finished collecting timing info
2020-02-27 18:46:01,948203 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,948377 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_tmp" cascade
2020-02-27 18:46:01,952509 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:01,954949 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,955053 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 18:46:01,955303 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:01,956471 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 18:46:01,956828 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,956908 (Thread-1): On model.ge_tutorials.stg_npi: BEGIN
2020-02-27 18:46:01,957086 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:01,957163 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,957226 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */

  
  create view "ge_tutorials"."public"."stg_npi__dbt_tmp" as (
    select 
	npi as npi,
	entity_type_code as entity_type_code,
	organization_name as organization_name,
	last_name as last_name,
	first_name as first_name,
	state as state_abbreviation,
	taxonomy_code as taxonomy_code
from "ge_tutorials"."public"."npi_small"
  );

2020-02-27 18:46:01,962715 (Thread-1): SQL status: CREATE VIEW in 0.01 seconds
2020-02-27 18:46:01,966205 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,966296 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-27 18:46:01,966614 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:01,968382 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,968467 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-27 18:46:01,968720 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:01,969348 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 18:46:01,969427 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,969491 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 18:46:01,970144 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:01,971689 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:01,971791 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 18:46:01,973158 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:01,975014 (Thread-1): finished collecting timing info
2020-02-27 18:46:01,975507 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60ad8472-8efa-48c3-ac01-2409e0afab4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1297289d0>]}
2020-02-27 18:46:02,733166 (Thread-1): 10:46:02 | 1 of 4 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.06s]
2020-02-27 18:46:02,733490 (Thread-1): Finished running node model.ge_tutorials.stg_npi
2020-02-27 18:46:02,734164 (Thread-1): Began running node model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:02,734838 (Thread-1): 10:46:02 | 2 of 4 START view model public.stg_state_abbreviations............... [RUN]
2020-02-27 18:46:02,735714 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,735922 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_npi).
2020-02-27 18:46:02,736070 (Thread-1): Compiling model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:02,743399 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_state_abbreviations"
2020-02-27 18:46:02,743864 (Thread-1): finished collecting timing info
2020-02-27 18:46:02,749460 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,749565 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" cascade
2020-02-27 18:46:02,749952 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:02,752151 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,752815 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_backup" cascade
2020-02-27 18:46:02,753932 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:02,755769 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_state_abbreviations"
2020-02-27 18:46:02,756303 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,756409 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: BEGIN
2020-02-27 18:46:02,756672 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:02,756774 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,756850 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */

  
  create view "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" as (
    select 
	name as state_name,
	abbreviation as state_abbreviation
from "ge_tutorials"."public"."state_abbreviations"
  );

2020-02-27 18:46:02,757493 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:02,760540 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,760633 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
alter table "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" rename to "stg_state_abbreviations"
2020-02-27 18:46:02,760962 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:02,761670 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: COMMIT
2020-02-27 18:46:02,761757 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,761828 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: COMMIT
2020-02-27 18:46:02,762202 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:02,763598 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:02,763682 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_backup" cascade
2020-02-27 18:46:02,764011 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:02,765874 (Thread-1): finished collecting timing info
2020-02-27 18:46:02,766355 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60ad8472-8efa-48c3-ac01-2409e0afab4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1298414d0>]}
2020-02-27 18:46:03,428378 (Thread-1): 10:46:03 | 2 of 4 OK created view model public.stg_state_abbreviations.......... [CREATE VIEW in 0.03s]
2020-02-27 18:46:03,428724 (Thread-1): Finished running node model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:03,429131 (Thread-1): Began running node model.ge_tutorials.npi_with_state
2020-02-27 18:46:03,429323 (Thread-1): 10:46:03 | 3 of 4 START view model public.npi_with_state........................ [RUN]
2020-02-27 18:46:03,429731 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:03,429851 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_state_abbreviations).
2020-02-27 18:46:03,429970 (Thread-1): Compiling model.ge_tutorials.npi_with_state
2020-02-27 18:46:03,438705 (Thread-1): Writing injected SQL for node "model.ge_tutorials.npi_with_state"
2020-02-27 18:46:03,439222 (Thread-1): finished collecting timing info
2020-02-27 18:46:03,445817 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:03,445933 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_tmp" cascade
2020-02-27 18:46:03,446352 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:03,450239 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:03,450534 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_backup" cascade
2020-02-27 18:46:03,451079 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:03,452811 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.npi_with_state"
2020-02-27 18:46:03,453306 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:03,453411 (Thread-1): On model.ge_tutorials.npi_with_state: BEGIN
2020-02-27 18:46:03,453598 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:03,453694 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:03,453774 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */

  
  create view "ge_tutorials"."public"."npi_with_state__dbt_tmp" as (
    select 
	n.npi,
	n.entity_type_code,
	n.organization_name,
	n.last_name,
	n.first_name,
	n.state,
	n.taxonomy_code,
	s.state_name
from "ge_tutorials"."public"."stg_npi" n
left join "ge_tutorials"."public"."stg_state_abbreviations" s
	on n.state_abbreviation = s.state_abbreviation
  );

2020-02-27 18:46:03,454368 (Thread-1): Postgres error: column n.state does not exist
LINE 11:  n.state,
          ^

2020-02-27 18:46:03,454497 (Thread-1): On model.ge_tutorials.npi_with_state: ROLLBACK
2020-02-27 18:46:03,454713 (Thread-1): finished collecting timing info
2020-02-27 18:46:03,455128 (Thread-1): Database Error in model npi_with_state (models/npi_with_state.sql)
  column n.state does not exist
  LINE 11:  n.state,
            ^
  compiled SQL at target/run/ge_tutorials/npi_with_state.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.UndefinedColumn: column n.state does not exist
LINE 11:  n.state,
          ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model npi_with_state (models/npi_with_state.sql)
  column n.state does not exist
  LINE 11:  n.state,
            ^
  compiled SQL at target/run/ge_tutorials/npi_with_state.sql
2020-02-27 18:46:03,462877 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '60ad8472-8efa-48c3-ac01-2409e0afab4b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129b05910>]}
2020-02-27 18:46:03,828278 (Thread-1): 10:46:03 | 3 of 4 ERROR creating view model public.npi_with_state............... [ERROR in 0.03s]
2020-02-27 18:46:03,828591 (Thread-1): Finished running node model.ge_tutorials.npi_with_state
2020-02-27 18:46:03,829368 (Thread-1): Began running node model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:03,829732 (Thread-1): 10:46:03 | 4 of 4 SKIP relation public.count_providers_by_state................. [SKIP]
2020-02-27 18:46:03,830033 (Thread-1): Finished running node model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:03,854527 (MainThread): Using postgres connection "master".
2020-02-27 18:46:03,854789 (MainThread): On master: BEGIN
2020-02-27 18:46:03,855139 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:03,855288 (MainThread): On master: COMMIT
2020-02-27 18:46:03,855403 (MainThread): Using postgres connection "master".
2020-02-27 18:46:03,855508 (MainThread): On master: COMMIT
2020-02-27 18:46:03,855807 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:03,856189 (MainThread): 10:46:03 | 
2020-02-27 18:46:03,856337 (MainThread): 10:46:03 | Finished running 4 view models in 2.17s.
2020-02-27 18:46:03,856460 (MainThread): Connection 'master' was left open.
2020-02-27 18:46:03,856551 (MainThread): On master: Close
2020-02-27 18:46:03,856662 (MainThread): Connection 'model.ge_tutorials.npi_with_state' was left open.
2020-02-27 18:46:03,856747 (MainThread): On model.ge_tutorials.npi_with_state: Close
2020-02-27 18:46:03,865761 (MainThread): 
2020-02-27 18:46:03,865931 (MainThread): Completed with 1 error and 0 warnings:
2020-02-27 18:46:03,866112 (MainThread): 
2020-02-27 18:46:03,866326 (MainThread): Database Error in model npi_with_state (models/npi_with_state.sql)
2020-02-27 18:46:03,866463 (MainThread):   column n.state does not exist
2020-02-27 18:46:03,866570 (MainThread):   LINE 11:  n.state,
2020-02-27 18:46:03,866661 (MainThread):             ^
2020-02-27 18:46:03,866744 (MainThread):   compiled SQL at target/run/ge_tutorials/npi_with_state.sql
2020-02-27 18:46:03,866847 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2020-02-27 18:46:03,867170 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1ac850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1298a2150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129883ed0>]}
2020-02-27 18:46:04,240288 (MainThread): Flushing usage events
2020-02-27 18:46:25,748882 (MainThread): Running with dbt=0.15.1
2020-02-27 18:46:25,811292 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 18:46:25,811820 (MainThread): Tracking: tracking
2020-02-27 18:46:25,824898 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11adabfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b2f3910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ae24110>]}
2020-02-27 18:46:26,232042 (MainThread): Partial parsing not enabled
2020-02-27 18:46:26,233759 (MainThread): Parsing macros/core.sql
2020-02-27 18:46:26,237006 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 18:46:26,241870 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 18:46:26,243059 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 18:46:26,253886 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 18:46:26,266469 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 18:46:26,277976 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 18:46:26,279223 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 18:46:26,283250 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 18:46:26,287522 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 18:46:26,291243 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 18:46:26,295390 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 18:46:26,298401 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 18:46:26,299035 (MainThread): Parsing macros/etc/query.sql
2020-02-27 18:46:26,299776 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 18:46:26,300880 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 18:46:26,302172 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 18:46:26,307713 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 18:46:26,309036 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 18:46:26,325589 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 18:46:26,326367 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 18:46:26,327005 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 18:46:26,327733 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 18:46:26,329157 (MainThread): Parsing macros/catalog.sql
2020-02-27 18:46:26,330317 (MainThread): Parsing macros/relations.sql
2020-02-27 18:46:26,331333 (MainThread): Parsing macros/adapters.sql
2020-02-27 18:46:26,337925 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 18:46:26,351043 (MainThread): Partial parsing not enabled
2020-02-27 18:46:26,360465 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:26,360550 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:26,372326 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:26,372426 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:26,376731 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,376826 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:26,380679 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:26,380751 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:26,424782 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 2 seed files, 0 sources
2020-02-27 18:46:26,428166 (MainThread): 
2020-02-27 18:46:26,428611 (MainThread): Acquiring new postgres connection "master".
2020-02-27 18:46:26,428737 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:26,500592 (MainThread): Using postgres connection "master".
2020-02-27 18:46:26,500759 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 18:46:26,546063 (MainThread): SQL status: SELECT 8 in 0.05 seconds
2020-02-27 18:46:26,570614 (MainThread): Using postgres connection "master".
2020-02-27 18:46:26,570765 (MainThread): On master: BEGIN
2020-02-27 18:46:26,571088 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:26,571165 (MainThread): Using postgres connection "master".
2020-02-27 18:46:26,571241 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'ge_tutorials' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ge_tutorials' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 18:46:26,573042 (MainThread): SQL status: SELECT 7 in 0.00 seconds
2020-02-27 18:46:26,594836 (MainThread): Using postgres connection "master".
2020-02-27 18:46:26,594939 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 18:46:26,601854 (MainThread): SQL status: SELECT 4 in 0.01 seconds
2020-02-27 18:46:26,606505 (MainThread): On master: ROLLBACK
2020-02-27 18:46:26,606751 (MainThread): Using postgres connection "master".
2020-02-27 18:46:26,606836 (MainThread): On master: BEGIN
2020-02-27 18:46:26,607119 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:26,607221 (MainThread): On master: COMMIT
2020-02-27 18:46:26,607301 (MainThread): Using postgres connection "master".
2020-02-27 18:46:26,607371 (MainThread): On master: COMMIT
2020-02-27 18:46:26,607522 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:26,607785 (MainThread): 10:46:26 | Concurrency: 1 threads (target='dev')
2020-02-27 18:46:26,607904 (MainThread): 10:46:26 | 
2020-02-27 18:46:26,609609 (Thread-1): Began running node model.ge_tutorials.stg_npi
2020-02-27 18:46:26,610367 (Thread-1): 10:46:26 | 1 of 4 START view model public.stg_npi............................... [RUN]
2020-02-27 18:46:26,611157 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,611362 (Thread-1): Opening a new connection, currently in state init
2020-02-27 18:46:26,611462 (Thread-1): Compiling model.ge_tutorials.stg_npi
2020-02-27 18:46:26,621341 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 18:46:26,623195 (Thread-1): finished collecting timing info
2020-02-27 18:46:26,652966 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,653111 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_tmp" cascade
2020-02-27 18:46:26,656232 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:26,658174 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,658260 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 18:46:26,658468 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:26,659594 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 18:46:26,659938 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,660024 (Thread-1): On model.ge_tutorials.stg_npi: BEGIN
2020-02-27 18:46:26,660207 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:26,660285 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,660350 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */

  
  create view "ge_tutorials"."public"."stg_npi__dbt_tmp" as (
    select 
	npi as npi,
	entity_type_code as entity_type_code,
	organization_name as organization_name,
	last_name as last_name,
	first_name as first_name,
	state as state_abbreviation,
	taxonomy_code as taxonomy_code
from "ge_tutorials"."public"."npi_small"
  );

2020-02-27 18:46:26,661709 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:26,664765 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,664926 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-27 18:46:26,665461 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:26,667244 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,667328 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-27 18:46:26,667571 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:26,668262 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 18:46:26,668343 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,668412 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 18:46:26,668951 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:26,670265 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:26,670351 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 18:46:26,671540 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:26,673515 (Thread-1): finished collecting timing info
2020-02-27 18:46:26,674112 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf481ada-f302-45f1-8ee3-749caaa53e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c420c10>]}
2020-02-27 18:46:27,36096 (Thread-1): 10:46:27 | 1 of 4 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.06s]
2020-02-27 18:46:27,36437 (Thread-1): Finished running node model.ge_tutorials.stg_npi
2020-02-27 18:46:27,36770 (Thread-1): Began running node model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:27,37349 (Thread-1): 10:46:27 | 2 of 4 START view model public.stg_state_abbreviations............... [RUN]
2020-02-27 18:46:27,38003 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,38262 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_npi).
2020-02-27 18:46:27,38511 (Thread-1): Compiling model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:27,46171 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_state_abbreviations"
2020-02-27 18:46:27,46635 (Thread-1): finished collecting timing info
2020-02-27 18:46:27,52673 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,52780 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" cascade
2020-02-27 18:46:27,53099 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,55451 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,56136 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_backup" cascade
2020-02-27 18:46:27,57086 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,59109 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_state_abbreviations"
2020-02-27 18:46:27,59663 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,59785 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: BEGIN
2020-02-27 18:46:27,60087 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:27,60202 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,60291 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */

  
  create view "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" as (
    select 
	name as state_name,
	abbreviation as state_abbreviation
from "ge_tutorials"."public"."state_abbreviations"
  );

2020-02-27 18:46:27,64479 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:27,68854 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,69037 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
alter table "ge_tutorials"."public"."stg_state_abbreviations" rename to "stg_state_abbreviations__dbt_backup"
2020-02-27 18:46:27,69403 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:27,71309 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,71416 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
alter table "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" rename to "stg_state_abbreviations"
2020-02-27 18:46:27,71741 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:27,72418 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: COMMIT
2020-02-27 18:46:27,72503 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,72573 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: COMMIT
2020-02-27 18:46:27,73046 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:27,74658 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:27,74761 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_backup" cascade
2020-02-27 18:46:27,75451 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,77662 (Thread-1): finished collecting timing info
2020-02-27 18:46:27,78186 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf481ada-f302-45f1-8ee3-749caaa53e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c67cbd0>]}
2020-02-27 18:46:27,443207 (Thread-1): 10:46:27 | 2 of 4 OK created view model public.stg_state_abbreviations.......... [CREATE VIEW in 0.04s]
2020-02-27 18:46:27,443562 (Thread-1): Finished running node model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:27,444255 (Thread-1): Began running node model.ge_tutorials.npi_with_state
2020-02-27 18:46:27,444469 (Thread-1): 10:46:27 | 3 of 4 START view model public.npi_with_state........................ [RUN]
2020-02-27 18:46:27,444877 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,445003 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_state_abbreviations).
2020-02-27 18:46:27,445128 (Thread-1): Compiling model.ge_tutorials.npi_with_state
2020-02-27 18:46:27,453484 (Thread-1): Writing injected SQL for node "model.ge_tutorials.npi_with_state"
2020-02-27 18:46:27,453921 (Thread-1): finished collecting timing info
2020-02-27 18:46:27,459814 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,459922 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_tmp" cascade
2020-02-27 18:46:27,460331 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,462305 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,462413 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_backup" cascade
2020-02-27 18:46:27,462763 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,465054 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.npi_with_state"
2020-02-27 18:46:27,465770 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,465938 (Thread-1): On model.ge_tutorials.npi_with_state: BEGIN
2020-02-27 18:46:27,466173 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:27,466271 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,466348 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */

  
  create view "ge_tutorials"."public"."npi_with_state__dbt_tmp" as (
    select 
	n.npi,
	n.entity_type_code,
	n.organization_name,
	n.last_name,
	n.first_name,
	n.taxonomy_code,
	n.state_abbreviation,
	s.state_name
from "ge_tutorials"."public"."stg_npi" n
left join "ge_tutorials"."public"."stg_state_abbreviations" s
	on n.state_abbreviation = s.state_abbreviation
  );

2020-02-27 18:46:27,467513 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:27,469898 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,469994 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
alter table "ge_tutorials"."public"."npi_with_state__dbt_tmp" rename to "npi_with_state"
2020-02-27 18:46:27,470318 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:27,471077 (Thread-1): On model.ge_tutorials.npi_with_state: COMMIT
2020-02-27 18:46:27,471170 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,471246 (Thread-1): On model.ge_tutorials.npi_with_state: COMMIT
2020-02-27 18:46:27,471643 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:27,474114 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:27,474222 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_backup" cascade
2020-02-27 18:46:27,474450 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,476456 (Thread-1): finished collecting timing info
2020-02-27 18:46:27,476990 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf481ada-f302-45f1-8ee3-749caaa53e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c474150>]}
2020-02-27 18:46:27,834822 (Thread-1): 10:46:27 | 3 of 4 OK created view model public.npi_with_state................... [CREATE VIEW in 0.03s]
2020-02-27 18:46:27,835163 (Thread-1): Finished running node model.ge_tutorials.npi_with_state
2020-02-27 18:46:27,835712 (Thread-1): Began running node model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:27,835981 (Thread-1): 10:46:27 | 4 of 4 START view model public.count_providers_by_state.............. [RUN]
2020-02-27 18:46:27,836381 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:27,836505 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.npi_with_state).
2020-02-27 18:46:27,836628 (Thread-1): Compiling model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:27,843996 (Thread-1): Writing injected SQL for node "model.ge_tutorials.count_providers_by_state"
2020-02-27 18:46:27,844404 (Thread-1): finished collecting timing info
2020-02-27 18:46:27,850155 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:27,850256 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */
drop view if exists "ge_tutorials"."public"."count_providers_by_state__dbt_tmp" cascade
2020-02-27 18:46:27,850635 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,852483 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:27,852576 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */
drop view if exists "ge_tutorials"."public"."count_providers_by_state__dbt_backup" cascade
2020-02-27 18:46:27,852825 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:27,855831 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.count_providers_by_state"
2020-02-27 18:46:27,856406 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:27,856516 (Thread-1): On model.ge_tutorials.count_providers_by_state: BEGIN
2020-02-27 18:46:27,856796 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:27,856906 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:27,856988 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */

  
  create view "ge_tutorials"."public"."count_providers_by_state__dbt_tmp" as (
    select 
	state_name,
	count(distinct npi)
from "ge_tutorials"."public"."npi_with_state" n
group by 1, 2
  );

2020-02-27 18:46:27,857761 (Thread-1): Postgres error: aggregate functions are not allowed in GROUP BY
LINE 7:  count(distinct npi)
         ^

2020-02-27 18:46:27,857871 (Thread-1): On model.ge_tutorials.count_providers_by_state: ROLLBACK
2020-02-27 18:46:27,858097 (Thread-1): finished collecting timing info
2020-02-27 18:46:27,858575 (Thread-1): Database Error in model count_providers_by_state (models/count_providers_by_state.sql)
  aggregate functions are not allowed in GROUP BY
  LINE 7:  count(distinct npi)
           ^
  compiled SQL at target/run/ge_tutorials/count_providers_by_state.sql
Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 44, in exception_handler
    yield
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 74, in add_query
    cursor.execute(sql, bindings)
psycopg2.errors.GroupingError: aggregate functions are not allowed in GROUP BY
LINE 7:  count(distinct npi)
         ^


The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 218, in safe_run
    result = self.compile_and_execute(manifest, ctx)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 161, in compile_and_execute
    result = self.run(ctx.node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 260, in run
    return self.execute(compiled_node, manifest)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/node_runners.py", line 436, in execute
    result = materialization_macro.generator(context)()
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 59, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/clients/jinja.py", line 155, in call_macro
    return macro(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 570, in __call__
    return self._invoke(arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 574, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 40, in macro
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/sandbox.py", line 440, in call
    return __context.call(__obj, *args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/jinja2/runtime.py", line 262, in call
    return __obj(*args, **kwargs)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/base/impl.py", line 276, in execute
    fetch=fetch
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 116, in execute
    _, cursor = self.add_query(sql, auto_begin)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/sql/connections.py", line 82, in add_query
    return connection, cursor
  File "/opt/miniconda3/lib/python3.7/contextlib.py", line 130, in __exit__
    self.gen.throw(type, value, traceback)
  File "/opt/miniconda3/lib/python3.7/site-packages/dbt/adapters/postgres/connections.py", line 56, in exception_handler
    raise dbt.exceptions.DatabaseException(str(e).strip()) from e
dbt.exceptions.DatabaseException: Database Error in model count_providers_by_state (models/count_providers_by_state.sql)
  aggregate functions are not allowed in GROUP BY
  LINE 7:  count(distinct npi)
           ^
  compiled SQL at target/run/ge_tutorials/count_providers_by_state.sql
2020-02-27 18:46:27,860275 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cf481ada-f302-45f1-8ee3-749caaa53e2a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c482650>]}
2020-02-27 18:46:28,258181 (Thread-1): 10:46:28 | 4 of 4 ERROR creating view model public.count_providers_by_state..... [ERROR in 0.02s]
2020-02-27 18:46:28,258531 (Thread-1): Finished running node model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:28,361068 (MainThread): Using postgres connection "master".
2020-02-27 18:46:28,361464 (MainThread): On master: BEGIN
2020-02-27 18:46:28,362135 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:28,362483 (MainThread): On master: COMMIT
2020-02-27 18:46:28,362738 (MainThread): Using postgres connection "master".
2020-02-27 18:46:28,362967 (MainThread): On master: COMMIT
2020-02-27 18:46:28,363571 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:28,364343 (MainThread): 10:46:28 | 
2020-02-27 18:46:28,364704 (MainThread): 10:46:28 | Finished running 4 view models in 1.94s.
2020-02-27 18:46:28,365016 (MainThread): Connection 'master' was left open.
2020-02-27 18:46:28,365171 (MainThread): On master: Close
2020-02-27 18:46:28,365361 (MainThread): Connection 'model.ge_tutorials.count_providers_by_state' was left open.
2020-02-27 18:46:28,365509 (MainThread): On model.ge_tutorials.count_providers_by_state: Close
2020-02-27 18:46:28,376721 (MainThread): 
2020-02-27 18:46:28,376897 (MainThread): Completed with 1 error and 0 warnings:
2020-02-27 18:46:28,377130 (MainThread): 
2020-02-27 18:46:28,377408 (MainThread): Database Error in model count_providers_by_state (models/count_providers_by_state.sql)
2020-02-27 18:46:28,377602 (MainThread):   aggregate functions are not allowed in GROUP BY
2020-02-27 18:46:28,377732 (MainThread):   LINE 7:  count(distinct npi)
2020-02-27 18:46:28,377828 (MainThread):            ^
2020-02-27 18:46:28,377923 (MainThread):   compiled SQL at target/run/ge_tutorials/count_providers_by_state.sql
2020-02-27 18:46:28,378060 (MainThread): 
Done. PASS=3 WARN=0 ERROR=1 SKIP=0 TOTAL=4
2020-02-27 18:46:28,378700 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c52fd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c656610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c6aca10>]}
2020-02-27 18:46:28,745241 (MainThread): Flushing usage events
2020-02-27 18:46:53,123177 (MainThread): Running with dbt=0.15.1
2020-02-27 18:46:53,185530 (MainThread): running dbt with arguments Namespace(cls=<class 'dbt.task.run.RunTask'>, debug=False, exclude=None, full_refresh=False, log_cache_events=False, log_format='default', models=None, partial_parse=None, profile=None, profiles_dir='/Users/sam/.dbt', project_dir=None, record_timing_info=None, rpc_method='run', single_threaded=False, strict=False, target=None, test_new_parser=False, threads=None, use_cache=True, vars='{}', version_check=True, warn_error=False, which='run', write_json=True)
2020-02-27 18:46:53,185936 (MainThread): Tracking: tracking
2020-02-27 18:46:53,198395 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1235ebf10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1235ebcd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1235ebb90>]}
2020-02-27 18:46:53,597652 (MainThread): Partial parsing not enabled
2020-02-27 18:46:53,599214 (MainThread): Parsing macros/core.sql
2020-02-27 18:46:53,602094 (MainThread): Parsing macros/materializations/helpers.sql
2020-02-27 18:46:53,606729 (MainThread): Parsing macros/materializations/snapshot/snapshot_merge.sql
2020-02-27 18:46:53,607890 (MainThread): Parsing macros/materializations/snapshot/strategies.sql
2020-02-27 18:46:53,618724 (MainThread): Parsing macros/materializations/snapshot/snapshot.sql
2020-02-27 18:46:53,631209 (MainThread): Parsing macros/materializations/seed/seed.sql
2020-02-27 18:46:53,642440 (MainThread): Parsing macros/materializations/incremental/helpers.sql
2020-02-27 18:46:53,643650 (MainThread): Parsing macros/materializations/incremental/incremental.sql
2020-02-27 18:46:53,647692 (MainThread): Parsing macros/materializations/common/merge.sql
2020-02-27 18:46:53,652003 (MainThread): Parsing macros/materializations/table/table.sql
2020-02-27 18:46:53,656061 (MainThread): Parsing macros/materializations/view/view.sql
2020-02-27 18:46:53,659933 (MainThread): Parsing macros/materializations/view/create_or_replace_view.sql
2020-02-27 18:46:53,663011 (MainThread): Parsing macros/etc/get_custom_alias.sql
2020-02-27 18:46:53,663649 (MainThread): Parsing macros/etc/query.sql
2020-02-27 18:46:53,664509 (MainThread): Parsing macros/etc/is_incremental.sql
2020-02-27 18:46:53,665630 (MainThread): Parsing macros/etc/get_relation_comment.sql
2020-02-27 18:46:53,666972 (MainThread): Parsing macros/etc/datetime.sql
2020-02-27 18:46:53,672788 (MainThread): Parsing macros/etc/get_custom_schema.sql
2020-02-27 18:46:53,674064 (MainThread): Parsing macros/adapters/common.sql
2020-02-27 18:46:53,691497 (MainThread): Parsing macros/schema_tests/relationships.sql
2020-02-27 18:46:53,692368 (MainThread): Parsing macros/schema_tests/not_null.sql
2020-02-27 18:46:53,693066 (MainThread): Parsing macros/schema_tests/unique.sql
2020-02-27 18:46:53,693861 (MainThread): Parsing macros/schema_tests/accepted_values.sql
2020-02-27 18:46:53,695962 (MainThread): Parsing macros/catalog.sql
2020-02-27 18:46:53,697164 (MainThread): Parsing macros/relations.sql
2020-02-27 18:46:53,698189 (MainThread): Parsing macros/adapters.sql
2020-02-27 18:46:53,704473 (MainThread): Parsing macros/materializations/snapshot_merge.sql
2020-02-27 18:46:53,717773 (MainThread): Partial parsing not enabled
2020-02-27 18:46:53,727220 (MainThread): Acquiring new postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:53,727302 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:53,738694 (MainThread): Acquiring new postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:53,738774 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:53,743118 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:53,743195 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:53,748576 (MainThread): Acquiring new postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:53,748757 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:53,793765 (MainThread): Found 4 models, 0 tests, 0 snapshots, 0 analyses, 125 macros, 0 operations, 2 seed files, 0 sources
2020-02-27 18:46:53,797317 (MainThread): 
2020-02-27 18:46:53,797631 (MainThread): Acquiring new postgres connection "master".
2020-02-27 18:46:53,797715 (MainThread): Opening a new connection, currently in state init
2020-02-27 18:46:53,870700 (MainThread): Using postgres connection "master".
2020-02-27 18:46:53,870866 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */

    select distinct nspname from pg_namespace
  
2020-02-27 18:46:53,917010 (MainThread): SQL status: SELECT 8 in 0.05 seconds
2020-02-27 18:46:53,942553 (MainThread): Using postgres connection "master".
2020-02-27 18:46:53,942727 (MainThread): On master: BEGIN
2020-02-27 18:46:53,943068 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:53,943160 (MainThread): Using postgres connection "master".
2020-02-27 18:46:53,943229 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
select
      'ge_tutorials' as database,
      tablename as name,
      schemaname as schema,
      'table' as type
    from pg_tables
    where schemaname ilike 'public'
    union all
    select
      'ge_tutorials' as database,
      viewname as name,
      schemaname as schema,
      'view' as type
    from pg_views
    where schemaname ilike 'public'
  
2020-02-27 18:46:53,945019 (MainThread): SQL status: SELECT 8 in 0.00 seconds
2020-02-27 18:46:53,968047 (MainThread): Using postgres connection "master".
2020-02-27 18:46:53,968160 (MainThread): On master: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "connection_name": "master"} */
with relation as (
        select
            pg_rewrite.ev_class as class,
            pg_rewrite.oid as id
        from pg_rewrite
    ),
    class as (
        select
            oid as id,
            relname as name,
            relnamespace as schema,
            relkind as kind
        from pg_class
    ),
    dependency as (
        select
            pg_depend.objid as id,
            pg_depend.refobjid as ref
        from pg_depend
    ),
    schema as (
        select
            pg_namespace.oid as id,
            pg_namespace.nspname as name
        from pg_namespace
        where nspname != 'information_schema' and nspname not like 'pg\_%'
    ),
    referenced as (
        select
            relation.id AS id,
            referenced_class.name ,
            referenced_class.schema ,
            referenced_class.kind
        from relation
        join class as referenced_class on relation.class=referenced_class.id
        where referenced_class.kind in ('r', 'v')
    ),
    relationships as (
        select
            referenced.name as referenced_name,
            referenced.schema as referenced_schema_id,
            dependent_class.name as dependent_name,
            dependent_class.schema as dependent_schema_id,
            referenced.kind as kind
        from referenced
        join dependency on referenced.id=dependency.id
        join class as dependent_class on dependency.ref=dependent_class.id
        where
            (referenced.name != dependent_class.name or
             referenced.schema != dependent_class.schema)
    )

    select
        referenced_schema.name as referenced_schema,
        relationships.referenced_name as referenced_name,
        dependent_schema.name as dependent_schema,
        relationships.dependent_name as dependent_name
    from relationships
    join schema as dependent_schema on relationships.dependent_schema_id=dependent_schema.id
    join schema as referenced_schema on relationships.referenced_schema_id=referenced_schema.id
    group by referenced_schema, referenced_name, dependent_schema, dependent_name
    order by referenced_schema, referenced_name, dependent_schema, dependent_name;
2020-02-27 18:46:53,976732 (MainThread): SQL status: SELECT 6 in 0.01 seconds
2020-02-27 18:46:53,983286 (MainThread): On master: ROLLBACK
2020-02-27 18:46:53,983591 (MainThread): Using postgres connection "master".
2020-02-27 18:46:53,983684 (MainThread): On master: BEGIN
2020-02-27 18:46:53,983970 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:53,984075 (MainThread): On master: COMMIT
2020-02-27 18:46:53,984157 (MainThread): Using postgres connection "master".
2020-02-27 18:46:53,984227 (MainThread): On master: COMMIT
2020-02-27 18:46:53,984380 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:53,984668 (MainThread): 10:46:53 | Concurrency: 1 threads (target='dev')
2020-02-27 18:46:53,984778 (MainThread): 10:46:53 | 
2020-02-27 18:46:53,986043 (Thread-1): Began running node model.ge_tutorials.stg_npi
2020-02-27 18:46:53,986183 (Thread-1): 10:46:53 | 1 of 4 START view model public.stg_npi............................... [RUN]
2020-02-27 18:46:53,986404 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:53,986478 (Thread-1): Opening a new connection, currently in state init
2020-02-27 18:46:53,986558 (Thread-1): Compiling model.ge_tutorials.stg_npi
2020-02-27 18:46:53,995465 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 18:46:53,995786 (Thread-1): finished collecting timing info
2020-02-27 18:46:54,22853 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,23119 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_tmp" cascade
2020-02-27 18:46:54,27625 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,29943 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,30032 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 18:46:54,30263 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,31368 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_npi"
2020-02-27 18:46:54,31705 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,31785 (Thread-1): On model.ge_tutorials.stg_npi: BEGIN
2020-02-27 18:46:54,31959 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:54,32036 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,32099 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */

  
  create view "ge_tutorials"."public"."stg_npi__dbt_tmp" as (
    select 
	npi as npi,
	entity_type_code as entity_type_code,
	organization_name as organization_name,
	last_name as last_name,
	first_name as first_name,
	state as state_abbreviation,
	taxonomy_code as taxonomy_code
from "ge_tutorials"."public"."npi_small"
  );

2020-02-27 18:46:54,33562 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:54,36436 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,36529 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi" rename to "stg_npi__dbt_backup"
2020-02-27 18:46:54,36915 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:54,38593 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,38675 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
alter table "ge_tutorials"."public"."stg_npi__dbt_tmp" rename to "stg_npi"
2020-02-27 18:46:54,38931 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:54,39557 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 18:46:54,39640 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,39707 (Thread-1): On model.ge_tutorials.stg_npi: COMMIT
2020-02-27 18:46:54,40435 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:54,42356 (Thread-1): Using postgres connection "model.ge_tutorials.stg_npi".
2020-02-27 18:46:54,42476 (Thread-1): On model.ge_tutorials.stg_npi: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_npi"} */
drop view if exists "ge_tutorials"."public"."stg_npi__dbt_backup" cascade
2020-02-27 18:46:54,43814 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,46110 (Thread-1): finished collecting timing info
2020-02-27 18:46:54,46720 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6185b00d-bb52-42ba-9dd6-f14f171a0b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1248dca50>]}
2020-02-27 18:46:54,421185 (Thread-1): 10:46:54 | 1 of 4 OK created view model public.stg_npi.......................... [CREATE VIEW in 0.06s]
2020-02-27 18:46:54,421530 (Thread-1): Finished running node model.ge_tutorials.stg_npi
2020-02-27 18:46:54,421899 (Thread-1): Began running node model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:54,422387 (Thread-1): 10:46:54 | 2 of 4 START view model public.stg_state_abbreviations............... [RUN]
2020-02-27 18:46:54,423042 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,423284 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_npi).
2020-02-27 18:46:54,423435 (Thread-1): Compiling model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:54,431014 (Thread-1): Writing injected SQL for node "model.ge_tutorials.stg_state_abbreviations"
2020-02-27 18:46:54,431484 (Thread-1): finished collecting timing info
2020-02-27 18:46:54,437905 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,438027 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" cascade
2020-02-27 18:46:54,438460 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,443073 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,443278 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_backup" cascade
2020-02-27 18:46:54,443657 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,445220 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.stg_state_abbreviations"
2020-02-27 18:46:54,445634 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,445728 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: BEGIN
2020-02-27 18:46:54,445893 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:54,446002 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,446085 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */

  
  create view "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" as (
    select 
	name as state_name,
	abbreviation as state_abbreviation
from "ge_tutorials"."public"."state_abbreviations"
  );

2020-02-27 18:46:54,446692 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:54,451116 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,451293 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
alter table "ge_tutorials"."public"."stg_state_abbreviations" rename to "stg_state_abbreviations__dbt_backup"
2020-02-27 18:46:54,451742 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:54,453664 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,453752 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
alter table "ge_tutorials"."public"."stg_state_abbreviations__dbt_tmp" rename to "stg_state_abbreviations"
2020-02-27 18:46:54,454066 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:54,454744 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: COMMIT
2020-02-27 18:46:54,454832 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,454903 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: COMMIT
2020-02-27 18:46:54,455398 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:54,457003 (Thread-1): Using postgres connection "model.ge_tutorials.stg_state_abbreviations".
2020-02-27 18:46:54,457097 (Thread-1): On model.ge_tutorials.stg_state_abbreviations: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.stg_state_abbreviations"} */
drop view if exists "ge_tutorials"."public"."stg_state_abbreviations__dbt_backup" cascade
2020-02-27 18:46:54,457755 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,459751 (Thread-1): finished collecting timing info
2020-02-27 18:46:54,460268 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6185b00d-bb52-42ba-9dd6-f14f171a0b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12496cc10>]}
2020-02-27 18:46:54,836358 (Thread-1): 10:46:54 | 2 of 4 OK created view model public.stg_state_abbreviations.......... [CREATE VIEW in 0.04s]
2020-02-27 18:46:54,836672 (Thread-1): Finished running node model.ge_tutorials.stg_state_abbreviations
2020-02-27 18:46:54,837252 (Thread-1): Began running node model.ge_tutorials.npi_with_state
2020-02-27 18:46:54,837529 (Thread-1): 10:46:54 | 3 of 4 START view model public.npi_with_state........................ [RUN]
2020-02-27 18:46:54,837998 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,838125 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.stg_state_abbreviations).
2020-02-27 18:46:54,838245 (Thread-1): Compiling model.ge_tutorials.npi_with_state
2020-02-27 18:46:54,846865 (Thread-1): Writing injected SQL for node "model.ge_tutorials.npi_with_state"
2020-02-27 18:46:54,847263 (Thread-1): finished collecting timing info
2020-02-27 18:46:54,853259 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,853363 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_tmp" cascade
2020-02-27 18:46:54,853854 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,857545 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,857762 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_backup" cascade
2020-02-27 18:46:54,858207 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,859745 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.npi_with_state"
2020-02-27 18:46:54,860149 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,860297 (Thread-1): On model.ge_tutorials.npi_with_state: BEGIN
2020-02-27 18:46:54,860516 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:54,860618 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,860696 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */

  
  create view "ge_tutorials"."public"."npi_with_state__dbt_tmp" as (
    select 
	n.npi,
	n.entity_type_code,
	n.organization_name,
	n.last_name,
	n.first_name,
	n.taxonomy_code,
	n.state_abbreviation,
	s.state_name
from "ge_tutorials"."public"."stg_npi" n
left join "ge_tutorials"."public"."stg_state_abbreviations" s
	on n.state_abbreviation = s.state_abbreviation
  );

2020-02-27 18:46:54,861649 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:54,863726 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,863817 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
alter table "ge_tutorials"."public"."npi_with_state__dbt_tmp" rename to "npi_with_state"
2020-02-27 18:46:54,864098 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:54,864838 (Thread-1): On model.ge_tutorials.npi_with_state: COMMIT
2020-02-27 18:46:54,864926 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,864998 (Thread-1): On model.ge_tutorials.npi_with_state: COMMIT
2020-02-27 18:46:54,865361 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:54,867657 (Thread-1): Using postgres connection "model.ge_tutorials.npi_with_state".
2020-02-27 18:46:54,867757 (Thread-1): On model.ge_tutorials.npi_with_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.npi_with_state"} */
drop view if exists "ge_tutorials"."public"."npi_with_state__dbt_backup" cascade
2020-02-27 18:46:54,868001 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:54,869890 (Thread-1): finished collecting timing info
2020-02-27 18:46:54,870466 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6185b00d-bb52-42ba-9dd6-f14f171a0b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124bc7950>]}
2020-02-27 18:46:55,241115 (Thread-1): 10:46:55 | 3 of 4 OK created view model public.npi_with_state................... [CREATE VIEW in 0.03s]
2020-02-27 18:46:55,241443 (Thread-1): Finished running node model.ge_tutorials.npi_with_state
2020-02-27 18:46:55,242188 (Thread-1): Began running node model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:55,242512 (Thread-1): 10:46:55 | 4 of 4 START view model public.count_providers_by_state.............. [RUN]
2020-02-27 18:46:55,243193 (Thread-1): Acquiring new postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,243385 (Thread-1): Re-using an available connection from the pool (formerly model.ge_tutorials.npi_with_state).
2020-02-27 18:46:55,243522 (Thread-1): Compiling model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:55,250964 (Thread-1): Writing injected SQL for node "model.ge_tutorials.count_providers_by_state"
2020-02-27 18:46:55,251411 (Thread-1): finished collecting timing info
2020-02-27 18:46:55,257536 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,257653 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */
drop view if exists "ge_tutorials"."public"."count_providers_by_state__dbt_tmp" cascade
2020-02-27 18:46:55,258021 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:55,260016 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,260459 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */
drop view if exists "ge_tutorials"."public"."count_providers_by_state__dbt_backup" cascade
2020-02-27 18:46:55,261672 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:55,264561 (Thread-1): Writing runtime SQL for node "model.ge_tutorials.count_providers_by_state"
2020-02-27 18:46:55,265147 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,265264 (Thread-1): On model.ge_tutorials.count_providers_by_state: BEGIN
2020-02-27 18:46:55,265544 (Thread-1): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:55,265661 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,265742 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */

  
  create view "ge_tutorials"."public"."count_providers_by_state__dbt_tmp" as (
    select 
	state_name,
	count(distinct npi) as count_providers
from "ge_tutorials"."public"."npi_with_state" n
group by state_name
  );

2020-02-27 18:46:55,266864 (Thread-1): SQL status: CREATE VIEW in 0.00 seconds
2020-02-27 18:46:55,269126 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,269226 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */
alter table "ge_tutorials"."public"."count_providers_by_state__dbt_tmp" rename to "count_providers_by_state"
2020-02-27 18:46:55,269599 (Thread-1): SQL status: ALTER TABLE in 0.00 seconds
2020-02-27 18:46:55,270338 (Thread-1): On model.ge_tutorials.count_providers_by_state: COMMIT
2020-02-27 18:46:55,270430 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,270517 (Thread-1): On model.ge_tutorials.count_providers_by_state: COMMIT
2020-02-27 18:46:55,270891 (Thread-1): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:55,272285 (Thread-1): Using postgres connection "model.ge_tutorials.count_providers_by_state".
2020-02-27 18:46:55,272375 (Thread-1): On model.ge_tutorials.count_providers_by_state: /* {"app": "dbt", "dbt_version": "0.15.1", "profile_name": "ge_tutorials", "target_name": "dev", "node_id": "model.ge_tutorials.count_providers_by_state"} */
drop view if exists "ge_tutorials"."public"."count_providers_by_state__dbt_backup" cascade
2020-02-27 18:46:55,272625 (Thread-1): SQL status: DROP VIEW in 0.00 seconds
2020-02-27 18:46:55,274674 (Thread-1): finished collecting timing info
2020-02-27 18:46:55,275191 (Thread-1): Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6185b00d-bb52-42ba-9dd6-f14f171a0b83', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1236fe210>]}
2020-02-27 18:46:55,638488 (Thread-1): 10:46:55 | 4 of 4 OK created view model public.count_providers_by_state......... [CREATE VIEW in 0.03s]
2020-02-27 18:46:55,638757 (Thread-1): Finished running node model.ge_tutorials.count_providers_by_state
2020-02-27 18:46:55,737565 (MainThread): Using postgres connection "master".
2020-02-27 18:46:55,737949 (MainThread): On master: BEGIN
2020-02-27 18:46:55,738627 (MainThread): SQL status: BEGIN in 0.00 seconds
2020-02-27 18:46:55,738970 (MainThread): On master: COMMIT
2020-02-27 18:46:55,739222 (MainThread): Using postgres connection "master".
2020-02-27 18:46:55,739445 (MainThread): On master: COMMIT
2020-02-27 18:46:55,740034 (MainThread): SQL status: COMMIT in 0.00 seconds
2020-02-27 18:46:55,740824 (MainThread): 10:46:55 | 
2020-02-27 18:46:55,741174 (MainThread): 10:46:55 | Finished running 4 view models in 1.94s.
2020-02-27 18:46:55,741474 (MainThread): Connection 'master' was left open.
2020-02-27 18:46:55,741696 (MainThread): On master: Close
2020-02-27 18:46:55,741967 (MainThread): Connection 'model.ge_tutorials.count_providers_by_state' was left open.
2020-02-27 18:46:55,742182 (MainThread): On model.ge_tutorials.count_providers_by_state: Close
2020-02-27 18:46:55,754437 (MainThread): 
2020-02-27 18:46:55,754583 (MainThread): Completed successfully
2020-02-27 18:46:55,754698 (MainThread): 
Done. PASS=4 WARN=0 ERROR=0 SKIP=0 TOTAL=4
2020-02-27 18:46:55,754992 (MainThread): Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1230f1750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1236fbc10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1248bfe50>]}
2020-02-27 18:46:56,128288 (MainThread): Flushing usage events
